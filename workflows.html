<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="true"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-efcb3c938269e030.js" defer=""></script><script src="/_next/static/chunks/pages/_app-9b7900e166242538.js" defer=""></script><script src="/_next/static/chunks/pages/workflows-767f7d96c64f295e.js" defer=""></script><script src="/_next/static/P93EmBG6Sh8IwFrfGAo9y/_buildManifest.js" defer=""></script><script src="/_next/static/P93EmBG6Sh8IwFrfGAo9y/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.eWdALT{display:none;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:44px;height:34px;padding:6px;border-radius:5px;border:none;background:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);cursor:pointer;margin-left:auto;}/*!sc*/
@media (max-width:920px){.eWdALT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.eWdALT div{width:22px;height:2px;background:#fff;-webkit-transform-origin:1px;-ms-transform-origin:1px;transform-origin:1px;-webkit-transition:all 0.3s linear;transition:all 0.3s linear;}/*!sc*/
data-styled.g1[id="sc-46d6b9d9-0"]{content:"eWdALT,"}/*!sc*/
.gdllpa{position:relative;max-width:1440px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;}/*!sc*/
@media (max-width:1130px){.gdllpa{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.gdllpa{padding-left:15px;padding-right:15px;}}/*!sc*/
data-styled.g2[id="sc-bc0cd3d0-0"]{content:"gdllpa,"}/*!sc*/
.jTcDmc{-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;overflow:hidden;position:absolute;white-space:nowrap;width:1px;}/*!sc*/
data-styled.g3[id="sc-cdea7863-0"]{content:"jTcDmc,"}/*!sc*/
.kzEZXJ{position:fixed;top:0;left:0;width:100%;height:80px;z-index:5;background:#fff;box-shadow:0px 4px 10px 4px rgba(0,0,0,0.04);}/*!sc*/
data-styled.g4[id="sc-f2146ecb-0"]{content:"kzEZXJ,"}/*!sc*/
.fBPfPh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;}/*!sc*/
.fBPfPh .img-logo{width:115px;margin-top:18px;}/*!sc*/
data-styled.g5[id="sc-f2146ecb-1"]{content:"fBPfPh,"}/*!sc*/
.uyBkV{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.uyBkV{display:block;position:absolute;top:80px;left:0;width:100%;z-index:1;padding:0 30px 30px;background-color:#fff;opacity:0;z-index:-9999;pointer-events:none;-webkit-transition:opacity 0.3s ease;transition:opacity 0.3s ease;box-shadow:0 4px 10px -1px rgba(0,0,0,0.04);}}/*!sc*/
@media (max-width:720px){.uyBkV{padding:0 15px 15px;}}/*!sc*/
data-styled.g6[id="sc-f2146ecb-2"]{content:"uyBkV,"}/*!sc*/
.hdARHE{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.hdARHE{display:block;margin-bottom:15px;}}/*!sc*/
.hdARHE li + li{margin-left:26px;}/*!sc*/
@media (max-width:920px){.hdARHE li + li{margin-left:0;}}/*!sc*/
.hdARHE a{display:inline-block;font-size:1.25rem;line-height:1;color:#000000;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color 0.3s;transition:color 0.3s;}/*!sc*/
.hdARHE a:hover{color:#FE7A00;}/*!sc*/
@media (max-width:920px){.hdARHE a{padding:8px 0;}}/*!sc*/
data-styled.g7[id="sc-f2146ecb-3"]{content:"hdARHE,"}/*!sc*/
.dJsZoP{position:relative;width:160px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;margin-left:26px;}/*!sc*/
@media (max-width:920px){.dJsZoP{width:auto;margin-left:0;}}/*!sc*/
data-styled.g8[id="sc-f2146ecb-4"]{content:"dJsZoP,"}/*!sc*/
.liGudk{display:inline-block;position:absolute;top:0;right:42px;width:calc(100% - 42px);height:100%;font-size:16px;line-height:1.25;padding:10px 13px;background:#fff;border-radius:5px 0px 0px 5px;border:1px solid #D9D9D9;border-right:none;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;}/*!sc*/
@media (max-width:920px){.liGudk{display:none;}}/*!sc*/
.liGudk::-webkit-input-placeholder{color:#D9D9D9;}/*!sc*/
.liGudk::-moz-placeholder{color:#D9D9D9;}/*!sc*/
.liGudk:-ms-input-placeholder{color:#D9D9D9;}/*!sc*/
.liGudk::placeholder{color:#D9D9D9;}/*!sc*/
data-styled.g9[id="sc-f2146ecb-5"]{content:"liGudk,"}/*!sc*/
.dfDKLD{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;color:#fff;margin-left:auto;-webkit-flex:0 0 42px;-ms-flex:0 0 42px;flex:0 0 42px;height:41px;border:1px solid #474747;border-radius:0px 5px 5px 0px;background-color:#474747;}/*!sc*/
@media (max-width:920px){.dfDKLD{margin-left:0;}}/*!sc*/
data-styled.g10[id="sc-f2146ecb-6"]{content:"dfDKLD,"}/*!sc*/
*,*:before,*:after{box-sizing:border-box;}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
html{font-family:'Source Sans Pro',sans-serif;font-weight:400;color:#000000;}/*!sc*/
body{background:#fff;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
main{padding-top:80px;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
figure{margin:0;}/*!sc*/
img,video{display:block;max-width:100%;height:auto;}/*!sc*/
a{color:unset;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
a:hover{color:unset;}/*!sc*/
strong{font-weight:600;}/*!sc*/
::selection{background-color:#FE7A00;color:#fff;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g11[id="sc-global-hnVSQk1"]{content:"sc-global-hnVSQk1,"}/*!sc*/
.kjpNuC{padding:4px;border:1px solid #ccc;cursor:pointer;background:#fff;}/*!sc*/
data-styled.g26[id="sc-e6721719-0"]{content:"kjpNuC,"}/*!sc*/
.jyGgHl{padding:100px 38px;}/*!sc*/
data-styled.g27[id="sc-f7b1bdfb-0"]{content:"jyGgHl,"}/*!sc*/
.eCGIQa{padding:38px 0;}/*!sc*/
.sc-f7b1bdfb-1 + .sc-f7b1bdfb-1{border-top:1px solid #ccc;}/*!sc*/
.eCGIQa img{width:250px;}/*!sc*/
data-styled.g28[id="sc-f7b1bdfb-1"]{content:"eCGIQa,"}/*!sc*/
</style><style data-href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@400;600;700&display=swap">@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3aPA.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rAkw.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vAkw.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNa7lujVj9_mf.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qPK7lujVj9_mf.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNK7lujVj9_mf.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qO67lujVj9_mf.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qN67lujVj9_mf.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNq7lujVj9_mf.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7lujVj9w.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmhdu3cOWxy40.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwkxdu3cOWxy40.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmxdu3cOWxy40.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmRdu3cOWxy40.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlxdu3cOWxw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmhdu3cOWxy40.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwkxdu3cOWxy40.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmxdu3cOWxy40.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmRdu3cOWxy40.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlxdu3cOWxw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><nav class="sc-f2146ecb-0 kzEZXJ"><div class="sc-bc0cd3d0-0 gdllpa"><div class="sc-f2146ecb-1 fBPfPh"><a href="/"><img alt="Orange Logo" src="/_next/static/media/logo-orange.4f24b038.svg" width="115" height="33" decoding="async" data-nimg="1" class="img-logo" loading="lazy" style="color:transparent"/></a><div><button aria-label="Toggle navigation" class="sc-46d6b9d9-0 eWdALT"><div></div><div></div><div></div></button><div class="sc-f2146ecb-2 uyBkV"><ul class="sc-f2146ecb-3 hdARHE"><li><a href="/workflows">Workflows</a></li><li><a href="/downloads">Downloads</a></li><li><a href="/blog">Blog</a></li><li><a href="/docs">Docs</a></li><li><a href="/workshops">Workshops</a></li></ul><form class="sc-f2146ecb-4 dJsZoP"><input type="text" placeholder="Search" class="sc-f2146ecb-5 liGudk" value=""/><button type="submit" class="sc-f2146ecb-6 dfDKLD"><img alt="Icon for search" src="/_next/static/media/icon-search.459b2665.svg" width="18" height="17" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><span class="sc-cdea7863-0 jTcDmc">Search through page</span></button></form></div></div></div></div></nav><main><div class="sc-f7b1bdfb-0 jyGgHl"><h1>Workflows</h1><div><button class="sc-e6721719-0 kjpNuC">Survival Analysis</button><button class="sc-e6721719-0 kjpNuC">Cox Regression</button><button class="sc-e6721719-0 kjpNuC">Concordance Index</button><button class="sc-e6721719-0 kjpNuC">Cross Validation</button><button class="sc-e6721719-0 kjpNuC">Clustering</button><button class="sc-e6721719-0 kjpNuC">Hierarchical Clustering</button><button class="sc-e6721719-0 kjpNuC">Box Plot</button><button class="sc-e6721719-0 kjpNuC">Kaplan-Meier</button><button class="sc-e6721719-0 kjpNuC">Predictive models</button><button class="sc-e6721719-0 kjpNuC">Classification</button><button class="sc-e6721719-0 kjpNuC">Data Sampler</button><button class="sc-e6721719-0 kjpNuC">Scatter Plot</button><button class="sc-e6721719-0 kjpNuC">Visualization</button><button class="sc-e6721719-0 kjpNuC">Feature Ranking</button><button class="sc-e6721719-0 kjpNuC">Feature Selection</button><button class="sc-e6721719-0 kjpNuC">Data Table</button><button class="sc-e6721719-0 kjpNuC">Data Loading</button><button class="sc-e6721719-0 kjpNuC">mental health</button><button class="sc-e6721719-0 kjpNuC">survey</button><button class="sc-e6721719-0 kjpNuC">Silhouette</button><button class="sc-e6721719-0 kjpNuC">Outliers</button><button class="sc-e6721719-0 kjpNuC">Data</button><button class="sc-e6721719-0 kjpNuC">Pivot Table</button><button class="sc-e6721719-0 kjpNuC">PCA</button><button class="sc-e6721719-0 kjpNuC">Dimensionality Reduction</button><button class="sc-e6721719-0 kjpNuC">Text Mining</button><button class="sc-e6721719-0 kjpNuC">Timeseries</button><button class="sc-e6721719-0 kjpNuC">Sentiment Analysis</button><button class="sc-e6721719-0 kjpNuC">Nomogram</button><button class="sc-e6721719-0 kjpNuC">Bag of Words</button><button class="sc-e6721719-0 kjpNuC">Tokenization</button><button class="sc-e6721719-0 kjpNuC">Preprocessing</button><button class="sc-e6721719-0 kjpNuC">Classification Tree</button><button class="sc-e6721719-0 kjpNuC">Twitter</button><button class="sc-e6721719-0 kjpNuC">Topic Modeling</button><button class="sc-e6721719-0 kjpNuC">Confusion Matrix</button></div><ul><li class="sc-f7b1bdfb-1 eCGIQa"><div>Cross Validation for Survival Models</div><img alt="" src="/workflows/c-index-cross-validation/730_c_index_cross_validation.webp" width="487" height="343" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Survival Analysis</button><button class="sc-e6721719-0 kjpNuC">Cox Regression</button><button class="sc-e6721719-0 kjpNuC">Concordance Index</button><button class="sc-e6721719-0 kjpNuC">Cross Validation</button></div><p>Orange built-in methods for testing and scoring the predictive models now support survival-related models like Cox regression. Here we demonstrate cross-validation to estimate the concordance index for the Cox regression model trained on data instances from selected features.</p><a href="https://download.biolab.si/download/files/workflows/orange/730_c_index_cross_validation.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Cluster Inspection</div><img alt="" src="/workflows/cluster-inspection/cluster-inspection.webp" width="1380" height="840" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Clustering</button><button class="sc-e6721719-0 kjpNuC">Hierarchical Clustering</button><button class="sc-e6721719-0 kjpNuC">Box Plot</button></div><p>We use the zoo data set in combination with Hierarchical Clustering to discover groups of animals. Now that we have the clusters we want to find out what is significant for each cluster! Pass the clusters to Box Plot and use &#x27;Order by relevance&#x27; to discover what defines a cluster. Seems like they are well-separated by the type, even though the clustering was unaware of the class label!</p><a href="https://download.biolab.si/download/files/workflows/orange/315-cluster-inspection.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Cohort Construction and Validation</div><img alt="" src="/workflows/cohort-construction-and-validation/720_cohort_construction_and_validation.webp" width="1796" height="686" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Survival Analysis</button><button class="sc-e6721719-0 kjpNuC">Kaplan-Meier</button><button class="sc-e6721719-0 kjpNuC">Cox Regression</button></div><p>Stratification of patients into low and high-risk groups is a common task in survival analysis to identify clinical and biological factors that contribute to survival. One approach to stratification is by computing risk score values based on the Cox regression model. With the clever use of Orange widgets, we can split the data into training and validation sets and then interactively generate risk score models on training data to observe the difference in cohorts&#x27; survival rate on training and validation samples side-by-side. Read more on how <a href="blog/why-you-should-use-apply-domain">Apply domain</a> enables this kind of workflows.</p><a href="https://download.biolab.si/download/files/workflows/orange/720_cohort_construction_and_validation.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Cross Validation</div><img alt="" src="/workflows/cross-validation/cross-validation.webp" width="1135" height="691" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Cross Validation</button><button class="sc-e6721719-0 kjpNuC">Predictive models</button><button class="sc-e6721719-0 kjpNuC">Classification</button></div><p>How good are supervised data mining methods on your classification dataset? Here&#x27;s a workflow that scores various classification techniques on a dataset from medicine. The central widget here is the one for testing and scoring, which is given the data and a set of learners, does cross-validation and scores predictive accuracy, and outputs the scores for further examination.</p><a href="https://download.biolab.si/download/files/workflows/orange/450-cross-validation.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Train and Test Data</div><img alt="" src="/workflows/data-sampler/data-sampler.webp" width="1637" height="997" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Classification</button><button class="sc-e6721719-0 kjpNuC">Data Sampler</button><button class="sc-e6721719-0 kjpNuC">Predictive models</button></div><p>In building predictive models it is important to have a separate train and test data sets in order to avoid overfitting and to properly score the models. Here we use Data Sampler to split the data into training and test data, use training data for building a model and, finally, test on test data. Try several other classifiers to see how the scores change.</p><a href="https://download.biolab.si/download/files/workflows/orange/420-data-sampler.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Visalization of Data Subsets</div><img alt="" src="/workflows/data-subsets/scatterplot-visualize-subset.webp" width="1316" height="801" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Scatter Plot</button><button class="sc-e6721719-0 kjpNuC">Visualization</button></div><p>Some visualization widget, like Scatter Plot and several data projection widgets, can expose the data instances in the data subset. In this workflow, Scatter Plot visualizes the data from the input data file, but also marks the data points that have been selected in the Data Table (selected rows).</p><a href="https://download.biolab.si/download/files/workflows/orange/130-scatterplot-visualize-subset.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Explore Subpopulations with Distinct Risk Profiles</div><img alt="" src="/workflows/explore-subpopulations-with-distinct-risk-profiles/740_hierarhical_clustering.webp" width="647" height="419" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Survival Analysis</button><button class="sc-e6721719-0 kjpNuC">Clustering</button><button class="sc-e6721719-0 kjpNuC">Hierarchical Clustering</button><button class="sc-e6721719-0 kjpNuC">Box Plot</button></div><p>We can visualize the difference in subpopulations of breast cancer patients in the METABRIC dataset through clustering, that is, by identifying groups of data instances similar to each other. We can observe the difference in survival rate between clusters with Kaplan-Meier Plot and explore features that characterize patients of each cluster with the Box Plot widget.</p><a href="https://download.biolab.si/download/files/workflows/orange/740_hierarhical_clustering.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Exploring Survival Features</div><img alt="" src="/workflows/exploring-survival-features/710_survival_features.webp" width="621" height="343" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Survival Analysis</button><button class="sc-e6721719-0 kjpNuC">Cox Regression</button></div><p>In the workflow, we show how to find and analyze variables related to survival. We start with variables ranked by univariate Cox regression analysis, where we can select the feature of interest. The Distribution widget shows its distribution and allows us to choose interactively a group of patients related to its values. We compare the survival of this group to all other patients in the Kaplan-Meier plot widget.</p><a href="https://download.biolab.si/download/files/workflows/orange/710_survival_features.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Feature Ranking</div><img alt="" src="/workflows/feature-ranking/feature-ranking.webp" width="1196" height="728" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Feature Ranking</button><button class="sc-e6721719-0 kjpNuC">Feature Selection</button></div><p>For supervised problems, where data instances are annotated with class labels, we would like to know which are the most informative features. Rank widget provides a table of features and their informativity scores, and supports manual feature selection. In the workflow, we used it to find the best two features (of initial 79 from brown-selected dataset) and display its scatter plot.</p><a href="https://download.biolab.si/download/files/workflows/orange/410-feature-ranking.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>File and Data Table</div><img alt="" src="/workflows/file-and-data-table-widget/file-and-data-table-widget.webp" width="1380" height="840" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Data Table</button><button class="sc-e6721719-0 kjpNuC">Data Loading</button></div><p>The basic data mining units in Orange are called widgets. In this workflow, the File widget reads the data. File widget communicates this data to Data Table widget that shows the data in a spreadsheet. The output of File is connected to the input of Data Table.</p><a href="https://download.biolab.si/download/files/workflows/orange/110-file-and-data-table-widget.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Hierarchical Clustering</div><img alt="" src="/workflows/hierarchical-clustering/hierarchical-clustering.webp" width="1610" height="980" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Hierarchical Clustering</button><button class="sc-e6721719-0 kjpNuC">Clustering</button></div><p>The workflow clusters the data items in iris dataset by first examining the distances between data instances. Distance matrix is passed to Hierarchical Clustering, which renders the dendrogram. Select different parts of the dendrogram to further analyze the corresponding data.</p><a href="https://download.biolab.si/download/files/workflows/orange/310-clustering.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Mental health of tech employees in times of COVID-19</div><img alt="" src="/workflows/mental-health/mental-health.webp" width="1372" height="850" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">mental health</button><button class="sc-e6721719-0 kjpNuC">survey</button><button class="sc-e6721719-0 kjpNuC">Hierarchical Clustering</button></div><p>The COVID-19 pandemic brought about many societal changes, including a serious effect on mental health. The Open Sourcing Mental Health 2021 survey measures attitudes towards mental health in the tech workplace and examines the frequency of mental health disorders among tech workers. The workflow presents how to uncover different types of tech employees based on their responses. The procedure is fully described in the <a href="https://ocean.sagepub.com/blog/mental-health-of-tech-employees-in-times-of-covid-19">SAGE Ocean blog</a>.</p><a href="https://download.biolab.si/download/files/workflows/orange/900_mental-health.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Inspecting Outliers with Silhouette</div><img alt="" src="/workflows/outliers/silhouette.webp" width="1329" height="809" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Silhouette</button><button class="sc-e6721719-0 kjpNuC">Outliers</button><button class="sc-e6721719-0 kjpNuC">Visualization</button></div><p>Silhouette Plot shows how &#x27;well-centered&#x27; each data instance is with respect to its cluster or class label. In this workflow we use iris&#x27; class labels to observe which flowers are typical representatives of their class and which are the outliers. Select instances left of zero in the plot and observe which flowers are these. Try connecting the selection with the Scatter Plot to highlight the outliers.</p><a href="https://download.biolab.si/download/files/workflows/orange/260-outliers.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Pivot Table</div><img alt="" src="/workflows/pivot-table/pivot-table.webp" width="1592" height="969" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Data</button><button class="sc-e6721719-0 kjpNuC">Pivot Table</button></div><p>Pivot Table can help us aggregate and transform the data. This workflow takes Kickstarter projects and aggregates them by month. We can inspect the frequency of the published projects per month and observe the difference between funded and non-funded projects. Try constructing several tables with pivot and experiment with different aggregation methods.</p><a href="https://download.biolab.si/download/files/workflows/orange/140-pivot-table.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Principal Component Analysis</div><img alt="" src="/workflows/principal-component-analysis/pca.webp" width="1167" height="711" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">PCA</button><button class="sc-e6721719-0 kjpNuC">Dimensionality Reduction</button></div><p>PCA transforms the data into a dataset with uncorrelated variables, also called principal components. PCA widget displays a graph (scree diagram) showing a degree of explained variance by best principal components and allows to interactively set the number of components to be included in the output dataset. In this workflow, we can observe the transformation in the Data Table and in Scatter Plot.</p><a href="https://download.biolab.si/download/files/workflows/orange/305-pca.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Interactive Visualizations</div><img alt="" src="/workflows/scatterplot-data-table/scatterplot-data-table.webp" width="1241" height="763" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Scatter Plot</button><button class="sc-e6721719-0 kjpNuC">Visualization</button></div><p>Most visualizations in Orange are interactive. Scatter Plot for example. Double click its icon to open it and click-and-drag to select a few data points from the plot. Selected data will automatically propagate to Data Table. Double click it to check which data was selected. Change selection and observe the change in the Data Table. This works best if both widgets are open.</p><a href="https://download.biolab.si/download/files/workflows/orange/120-scatterplot-data-table.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Story Arcs</div><img alt="" src="/workflows/story-arcs/story-arcs.webp" width="1278" height="778" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button><button class="sc-e6721719-0 kjpNuC">Timeseries</button><button class="sc-e6721719-0 kjpNuC">Sentiment Analysis</button></div><p>In this workflow we explore story arcs in the Little Match Seller story. First we select the story from the corpus of Andersen tales. Then we create a table, where each sentence of the tale is a separate row. We use sentiment analysis to compute the sentiment of each sentence, then observe the emotional arcs through the story. We also inspect sentences with similar scores in the Heat Map and Corpus Viewer.</p><a href="https://download.biolab.si/download/files/workflows/orange/650-story-arcs.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div></div><hr/>
<h2>title: &quot;Survival Curve Estimation&quot;
images: [&quot;700_survival_curve_estimation.webp&quot;]
type: &quot;workflows&quot;
blog: &quot;&quot;
video: &quot;&quot;
download: &quot;700_survival_curve_estimation.ows&quot;
workflows: [&quot;Survival Analysis&quot;]
weight: 700</h2>
<p>One of the primary objectives of survival analysis is to estimate the survival probability from observed survival times of different patients. The workflow plots the Kaplan-Meier approximation of the survival curve for the investigated population in the German breast cancer study group. The Kaplan-Meier plot is interactive; we select the longest-surviving patients and use Box Plot to analyze features that best characterize them.</p><a href="https://download.biolab.si/download/files/workflows/orange/undefined">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Document Map Annotation</div><img alt="" src="/workflows/text-annotator/text-annotator.webp" width="1606" height="590" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button></div><p>Documents maps can be enhanced with the keywords annotations. This workflow embeds documents in vector space, computes a t-SNE document map and annotates it. The Annotator widget identifies clusters on the map and annotates them with keywords representing a cluster.</p><a href="https://download.biolab.si/download/files/workflows/orange/text-annotator.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Text Classification</div><img alt="" src="/workflows/text-classification/text-classification.webp" width="1748" height="1064" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button><button class="sc-e6721719-0 kjpNuC">Classification</button><button class="sc-e6721719-0 kjpNuC">Nomogram</button><button class="sc-e6721719-0 kjpNuC">Bag of Words</button></div><p>We can use predictive models to classify documents by authorship, their type, sentiment and so on. In this workflow we classify documents by their Aarne-Thompshon-Uther index, that is the defining topic of the tale. We use two simple learners, Logistic Regression and Naive Bayes, both of which can be inspected in the Nomogram.</p><a href="https://download.biolab.si/download/files/workflows/orange/630-text-classification.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Text Clustering</div><img alt="" src="/workflows/text-clustering/text-clustering.webp" width="1518" height="924" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button><button class="sc-e6721719-0 kjpNuC">Clustering</button><button class="sc-e6721719-0 kjpNuC">Tokenization</button></div><p>The workflow clusters Grimm&#x27;s tales corpus. We start by preprocessing the data and constructing the bag of words matrix. Then we compute cosine distances between documents and use Hierarchical Clustering, which displays the dendrogram. We observe how well the type of the tale corresponds to the cluster in the MDS.</p><a href="https://download.biolab.si/download/files/workflows/orange/620-text-clustering.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Corpus and Word Maps</div><img alt="" src="/workflows/text-corpus-and-word-map/text-corpus-and-word-map.webp" width="2226" height="892" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button></div><p>This workflow shows how to extract the most common words from the documents and observe clusters of semantically similar words with Hierarchical Clustering. We select a group of words (connected to the traffic and roads) and use them to score documents according to selection with the Score Documents widget. The scores are visualized in the document map by the Self-Organizing Maps widget.</p><a href="https://download.biolab.si/download/files/workflows/orange/text-corpus-and-word-map.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Keyword-Based Text Document Scoring</div><img alt="" src="/workflows/text-keyword-based-scoring/text-keyword-based-scoring.webp" width="796" height="392" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button></div><p>We can score the text documents based on a list of keywords, say, to find the documents which include the keywords or are semantically related to the list of keywords. This workflow shows the Score Documents widget for scoring and the Word List widget to compose a list of keywords. The scores are visualized in the t-SNE document map.</p><a href="https://download.biolab.si/download/files/workflows/orange/text-keyword-based-scoring.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Keyword Extraction from a Set of Text Documents</div><img alt="" src="/workflows/text-keyword-extraction/text-keyword-extraction.webp" width="587" height="336" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button></div><p>The Extract Keywords widget can characterize a set of textual documents. In this workflow, we load the documents from the server, preprocess them and embed them in the vector space, and display a semantic document map in the t-SNE widget. In this widget, we can select a set of similar documents and then characterize them through keyword extraction. Extract keywords support different inference techniques, including TF-IDF and deep network-based characterization.</p><a href="https://download.biolab.si/download/files/workflows/orange/text-keyword-extraction.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Load Text Corpus from the Server Repository</div><img alt="" src="/workflows/text-loading-from-repository/text-loading-from-repository.webp" width="553" height="319" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button></div><p>The workflow loads the corpus from the <a href="http://file.biolab.si/text-semantics/data/predlogi-vladi-1k/">text repository on the server</a>. The repository contains documents with raw text and associated YAML files with meta-features. We here use some pre-processing and then display the most frequent words in a word cloud. This workflow could work on your repository: just change the URL in the Import Documents widget.</p><a href="https://download.biolab.si/download/files/workflows/orange/text-loading-from-repository.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Ontology Generation from Keywords</div><img alt="" src="/workflows/text-ontology/text-ontology.webp" width="1438" height="534" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button></div><p>We can automatically build the otology from the set of words. In the workflow, we select a group of documents with similar content. From the selected documents, we extract keywords and generate a new ontology from the subset of keywords with the Ontology widget.</p><a href="https://download.biolab.si/download/files/workflows/orange/text-ontology.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Text Preprocessing</div><img alt="" src="/workflows/text-preprocessing/text-preprocessing.webp" width="1271" height="774" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button><button class="sc-e6721719-0 kjpNuC">Preprocessing</button><button class="sc-e6721719-0 kjpNuC">Tokenization</button></div><p>Text mining requires careful preprocessing. Here&#x27;s a workflow that uses simple preprocessing for creating tokens from documents. First, it applies lowercase, then splits text into words, and finally, it removes frequent stopwords. Preprocessing is language specific, so change the language to the language of texts where required. Results of preprocessing can be observe in a Word Cloud.</p><a href="https://download.biolab.si/download/files/workflows/orange/610-text-preprocessing.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Semantic Document Map</div><img alt="" src="/workflows/text-semantic-document-map/text-semantic-document-map.webp" width="671" height="329" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button></div><p>Document maps may reveal clusters of documents with semantically similar content. Here we show a workflow that loads the corpus, performs some text preprocessing and embeds the documents in the vector space using the fastText deep model. The t-SNE widget reveals the document map, where we can select a set of documents and then explore them in Corpus Viewer or characterize them in the display of the most frequent words in the Word Cloud.</p><a href="https://download.biolab.si/download/files/workflows/orange/text-semantic-word-map.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Semantic Word Map</div><img alt="" src="/workflows/text-semantic-word-map/text-semantic-word-map.webp" width="701" height="395" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><img alt="" src="/workflows/text-semantic-word-map/text-semantic-word-map-tsne.webp" width="758" height="581" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button></div><p>We can find clusters of semantically related words either by hierarchical clustering or t-SNE visualizations. Here, we show a workflow that loads the documents, extracts frequent words, embeds them in a vector space, and explores word clusters.</p><a href="https://download.biolab.si/download/files/workflows/orange/text-semantic-word-map.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Classification Tree</div><img alt="" src="/workflows/tree-scatterplot/tree-scatterplot.webp" width="1437" height="875" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Classification Tree</button><button class="sc-e6721719-0 kjpNuC">Classification</button></div><p>This workflow combines the interface and visualization of classification trees with scatter plot. When both the tree viewer and the scatter plot are open, selection of any node of the tree sends the related data instances to scatter plot. In the workflow, the selected data is treated as a subset of the entire dataset and is highlighted in the scatter plot. With simple combination of widgets we have constructed an interactive classification tree browser.</p><a href="https://download.biolab.si/download/files/workflows/orange/250-tree-scatterplot.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Twitter Data Analysis</div><img alt="" src="/workflows/twitter/twitter.webp" width="1326" height="807" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Text Mining</button><button class="sc-e6721719-0 kjpNuC">Twitter</button><button class="sc-e6721719-0 kjpNuC">Topic Modeling</button></div><p>Tweets are a valuable source of information, for social scientists, marketing managers, linguists, economists, and so on. In this workflow we retrieve data from Twitter, preprocess it, and uncover latent topics with topic modeling. We observe the topics in a Heat Map.</p><a href="https://download.biolab.si/download/files/workflows/orange/640-twitter.ows">Download</a></li><li class="sc-f7b1bdfb-1 eCGIQa"><div>Where Are Misclassifications</div><img alt="" src="/workflows/where-are-misclassifications/misclassifications.webp" width="1079" height="657" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><div><button class="sc-e6721719-0 kjpNuC">Confusion Matrix</button><button class="sc-e6721719-0 kjpNuC">Classification</button><button class="sc-e6721719-0 kjpNuC">Scatter Plot</button></div><p>Cross-validation of, say, logistic regression can expose the data instances which were misclassified. There are six such instances for iris dataset and ridge-regularized logistic regression. We can select different types of misclassification in Confusion Matrix and highlight them in the Scatter Plot. No surprise: the misclassified instances are close to the class-bordering regions in the scatter plot projection.</p><a href="https://download.biolab.si/download/files/workflows/orange/470-misclassification-scatterplot.ows">Download</a></li></ul></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"title":"Workflows"},"workflows":[{"title":"Cross Validation for Survival Models","images":[{"width":487,"height":343,"src":"/workflows/c-index-cross-validation/730_c_index_cross_validation.webp"}],"type":"workflows","blog":"","video":"","download":"730_c_index_cross_validation.ows","workflows":["Survival Analysis","Cox Regression","Concordance Index","Cross Validation"],"weight":730,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"Orange built-in methods for testing and scoring the predictive models now support survival-related models like Cox regression. Here we demonstrate cross-validation to estimate the concordance index for the Cox regression model trained on data instances from selected features.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Cluster Inspection","images":[{"width":1380,"height":840,"src":"/workflows/cluster-inspection/cluster-inspection.webp"}],"type":"workflows","blog_link":"","video":"","download":"315-cluster-inspection.ows","workflows":["Clustering","Hierarchical Clustering","Box Plot"],"weight":315,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"We use the zoo data set in combination with Hierarchical Clustering to discover groups of animals. Now that we have the clusters we want to find out what is significant for each cluster! Pass the clusters to Box Plot and use 'Order by relevance' to discover what defines a cluster. Seems like they are well-separated by the type, even though the clustering was unaware of the class label!\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Cohort Construction and Validation","images":[{"width":1796,"height":686,"src":"/workflows/cohort-construction-and-validation/720_cohort_construction_and_validation.webp"}],"type":"workflows","blog":"","video":"","download":"720_cohort_construction_and_validation.ows","workflows":["Survival Analysis","Kaplan-Meier","Cox Regression"],"weight":720,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_components.p, {\n    children: [\"Stratification of patients into low and high-risk groups is a common task in survival analysis to identify clinical and biological factors that contribute to survival. One approach to stratification is by computing risk score values based on the Cox regression model. With the clever use of Orange widgets, we can split the data into training and validation sets and then interactively generate risk score models on training data to observe the difference in cohorts' survival rate on training and validation samples side-by-side. Read more on how \", _jsx(_components.a, {\n      href: \"blog/why-you-should-use-apply-domain\",\n      children: \"Apply domain\"\n    }), \" enables this kind of workflows.\"]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Cross Validation","images":[{"width":1135,"height":691,"src":"/workflows/cross-validation/cross-validation.webp"}],"type":"workflows","blog_link":"","video":"","download":"450-cross-validation.ows","workflows":["Cross Validation","Predictive models","Classification"],"weight":450,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"How good are supervised data mining methods on your classification dataset? Here's a workflow that scores various classification techniques on a dataset from medicine. The central widget here is the one for testing and scoring, which is given the data and a set of learners, does cross-validation and scores predictive accuracy, and outputs the scores for further examination.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Train and Test Data","images":[{"width":1637,"height":997,"src":"/workflows/data-sampler/data-sampler.webp"}],"type":"workflows","blog_link":"","video":"","download":"420-data-sampler.ows","workflows":["Classification","Data Sampler","Predictive models"],"weight":420,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"In building predictive models it is important to have a separate train and test data sets in order to avoid overfitting and to properly score the models. Here we use Data Sampler to split the data into training and test data, use training data for building a model and, finally, test on test data. Try several other classifiers to see how the scores change.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Visalization of Data Subsets","images":[{"width":1316,"height":801,"src":"/workflows/data-subsets/scatterplot-visualize-subset.webp"}],"type":"workflows","blog_link":"","video":"","download":"130-scatterplot-visualize-subset.ows","workflows":["Scatter Plot","Visualization"],"weight":130,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"Some visualization widget, like Scatter Plot and several data projection widgets, can expose the data instances in the data subset. In this workflow, Scatter Plot visualizes the data from the input data file, but also marks the data points that have been selected in the Data Table (selected rows).\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Explore Subpopulations with Distinct Risk Profiles","images":[{"width":647,"height":419,"src":"/workflows/explore-subpopulations-with-distinct-risk-profiles/740_hierarhical_clustering.webp"}],"type":"workflows","blog":"","video":"","download":"740_hierarhical_clustering.ows","workflows":["Survival Analysis","Clustering","Hierarchical Clustering","Box Plot"],"weight":740,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"We can visualize the difference in subpopulations of breast cancer patients in the METABRIC dataset through clustering, that is, by identifying groups of data instances similar to each other. We can observe the difference in survival rate between clusters with Kaplan-Meier Plot and explore features that characterize patients of each cluster with the Box Plot widget.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Exploring Survival Features","images":[{"width":621,"height":343,"src":"/workflows/exploring-survival-features/710_survival_features.webp"}],"type":"workflows","blog":"","video":"","download":"710_survival_features.ows","workflows":["Survival Analysis","Cox Regression"],"weight":710,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"In the workflow, we show how to find and analyze variables related to survival. We start with variables ranked by univariate Cox regression analysis, where we can select the feature of interest. The Distribution widget shows its distribution and allows us to choose interactively a group of patients related to its values. We compare the survival of this group to all other patients in the Kaplan-Meier plot widget.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Feature Ranking","images":[{"width":1196,"height":728,"src":"/workflows/feature-ranking/feature-ranking.webp"}],"type":"workflows","blog_link":"","video":"","download":"410-feature-ranking.ows","workflows":["Feature Ranking","Feature Selection"],"weight":410,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"For supervised problems, where data instances are annotated with class labels, we would like to know which are the most informative features. Rank widget provides a table of features and their informativity scores, and supports manual feature selection. In the workflow, we used it to find the best two features (of initial 79 from brown-selected dataset) and display its scatter plot.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"File and Data Table","images":[{"width":1380,"height":840,"src":"/workflows/file-and-data-table-widget/file-and-data-table-widget.webp"}],"type":"workflows","blog_link":"","video":"","download":"110-file-and-data-table-widget.ows","workflows":["Data Table","Data Loading"],"weight":120,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"The basic data mining units in Orange are called widgets. In this workflow, the File widget reads the data. File widget communicates this data to Data Table widget that shows the data in a spreadsheet. The output of File is connected to the input of Data Table.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Hierarchical Clustering","images":[{"width":1610,"height":980,"src":"/workflows/hierarchical-clustering/hierarchical-clustering.webp"}],"type":"workflows","blog_link":"","video":"","download":"310-clustering.ows","workflows":["Hierarchical Clustering","Clustering"],"weight":310,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"The workflow clusters the data items in iris dataset by first examining the distances between data instances. Distance matrix is passed to Hierarchical Clustering, which renders the dendrogram. Select different parts of the dendrogram to further analyze the corresponding data.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Mental health of tech employees in times of COVID-19","images":[{"width":1372,"height":850,"src":"/workflows/mental-health/mental-health.webp"}],"type":"workflows","blog_link":"https://ocean.sagepub.com/blog/mental-health-of-tech-employees-in-times-of-covid-19","video":"","download":"900_mental-health.ows","workflows":["mental health","survey","Hierarchical Clustering"],"weight":900,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_components.p, {\n    children: [\"The COVID-19 pandemic brought about many societal changes, including a serious effect on mental health. The Open Sourcing Mental Health 2021 survey measures attitudes towards mental health in the tech workplace and examines the frequency of mental health disorders among tech workers. The workflow presents how to uncover different types of tech employees based on their responses. The procedure is fully described in the \", _jsx(_components.a, {\n      href: \"https://ocean.sagepub.com/blog/mental-health-of-tech-employees-in-times-of-covid-19\",\n      children: \"SAGE Ocean blog\"\n    }), \".\"]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Inspecting Outliers with Silhouette","images":[{"width":1329,"height":809,"src":"/workflows/outliers/silhouette.webp"}],"type":"workflows","blog_link":"","video":"","download":"260-outliers.ows","workflows":["Silhouette","Outliers","Visualization"],"weight":260,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"Silhouette Plot shows how 'well-centered' each data instance is with respect to its cluster or class label. In this workflow we use iris' class labels to observe which flowers are typical representatives of their class and which are the outliers. Select instances left of zero in the plot and observe which flowers are these. Try connecting the selection with the Scatter Plot to highlight the outliers.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Pivot Table","images":[{"width":1592,"height":969,"src":"/workflows/pivot-table/pivot-table.webp"}],"type":"workflows","blog_link":"","video":"","download":"140-pivot-table.ows","workflows":["Data","Pivot Table"],"weight":140,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"Pivot Table can help us aggregate and transform the data. This workflow takes Kickstarter projects and aggregates them by month. We can inspect the frequency of the published projects per month and observe the difference between funded and non-funded projects. Try constructing several tables with pivot and experiment with different aggregation methods.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Principal Component Analysis","images":[{"width":1167,"height":711,"src":"/workflows/principal-component-analysis/pca.webp"}],"type":"workflows","blog_link":"","video":"","download":"305-pca.ows","workflows":["PCA","Dimensionality Reduction"],"weight":305,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"PCA transforms the data into a dataset with uncorrelated variables, also called principal components. PCA widget displays a graph (scree diagram) showing a degree of explained variance by best principal components and allows to interactively set the number of components to be included in the output dataset. In this workflow, we can observe the transformation in the Data Table and in Scatter Plot.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Interactive Visualizations","images":[{"width":1241,"height":763,"src":"/workflows/scatterplot-data-table/scatterplot-data-table.webp"}],"type":"workflows","blog_link":"","video":"","download":"120-scatterplot-data-table.ows","workflows":["Scatter Plot","Visualization"],"weight":120,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"Most visualizations in Orange are interactive. Scatter Plot for example. Double click its icon to open it and click-and-drag to select a few data points from the plot. Selected data will automatically propagate to Data Table. Double click it to check which data was selected. Change selection and observe the change in the Data Table. This works best if both widgets are open.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Story Arcs","images":[{"width":1278,"height":778,"src":"/workflows/story-arcs/story-arcs.webp"}],"type":"workflows","blog_link":"2020/2020-07-27-story-arcs/","video":"","download":"650-story-arcs.ows","workflows":["Text Mining","Timeseries","Sentiment Analysis"],"weight":649,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"In this workflow we explore story arcs in the Little Match Seller story. First we select the story from the corpus of Andersen tales. Then we create a table, where each sentence of the tale is a separate row. We use sentiment analysis to compute the sentiment of each sentence, then observe the emotional arcs through the story. We also inspect sentences with similar scores in the Heat Map and Corpus Viewer.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"images":[],"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    hr: \"hr\",\n    h2: \"h2\",\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.hr, {}), \"\\n\", _jsx(_components.h2, {\n      children: \"title: \\\"Survival Curve Estimation\\\"\\nimages: [\\\"700_survival_curve_estimation.webp\\\"]\\ntype: \\\"workflows\\\"\\nblog: \\\"\\\"\\nvideo: \\\"\\\"\\ndownload: \\\"700_survival_curve_estimation.ows\\\"\\nworkflows: [\\\"Survival Analysis\\\"]\\nweight: 700\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"One of the primary objectives of survival analysis is to estimate the survival probability from observed survival times of different patients. The workflow plots the Kaplan-Meier approximation of the survival curve for the investigated population in the German breast cancer study group. The Kaplan-Meier plot is interactive; we select the longest-surviving patients and use Box Plot to analyze features that best characterize them.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Document Map Annotation","images":[{"width":1606,"height":590,"src":"/workflows/text-annotator/text-annotator.webp"}],"type":"workflows","blog_link":"","video":"","download":"text-annotator.ows","workflows":["Text Mining"],"weight":664,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"Documents maps can be enhanced with the keywords annotations. This workflow embeds documents in vector space, computes a t-SNE document map and annotates it. The Annotator widget identifies clusters on the map and annotates them with keywords representing a cluster.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Text Classification","images":[{"width":1748,"height":1064,"src":"/workflows/text-classification/text-classification.webp"}],"type":"workflows","blog_link":"","video":"https://youtu.be/zO_zwKZCULo","download":"630-text-classification.ows","workflows":["Text Mining","Classification","Nomogram","Bag of Words"],"weight":630,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"We can use predictive models to classify documents by authorship, their type, sentiment and so on. In this workflow we classify documents by their Aarne-Thompshon-Uther index, that is the defining topic of the tale. We use two simple learners, Logistic Regression and Naive Bayes, both of which can be inspected in the Nomogram.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Text Clustering","images":[{"width":1518,"height":924,"src":"/workflows/text-clustering/text-clustering.webp"}],"type":"workflows","blog_link":"","video":"https://youtu.be/rH_vQxQL6oM","download":"620-text-clustering.ows","workflows":["Text Mining","Clustering","Tokenization"],"weight":620,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"The workflow clusters Grimm's tales corpus. We start by preprocessing the data and constructing the bag of words matrix. Then we compute cosine distances between documents and use Hierarchical Clustering, which displays the dendrogram. We observe how well the type of the tale corresponds to the cluster in the MDS.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Corpus and Word Maps","images":[{"width":2226,"height":892,"src":"/workflows/text-corpus-and-word-map/text-corpus-and-word-map.webp"}],"type":"workflows","blog_link":"","video":"","download":"text-corpus-and-word-map.ows","workflows":["Text Mining"],"weight":660,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"This workflow shows how to extract the most common words from the documents and observe clusters of semantically similar words with Hierarchical Clustering. We select a group of words (connected to the traffic and roads) and use them to score documents according to selection with the Score Documents widget. The scores are visualized in the document map by the Self-Organizing Maps widget.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Keyword-Based Text Document Scoring","images":[{"width":796,"height":392,"src":"/workflows/text-keyword-based-scoring/text-keyword-based-scoring.webp"}],"type":"workflows","blog_link":"","video":"","download":"text-keyword-based-scoring.ows","workflows":["Text Mining"],"weight":658,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"We can score the text documents based on a list of keywords, say, to find the documents which include the keywords or are semantically related to the list of keywords. This workflow shows the Score Documents widget for scoring and the Word List widget to compose a list of keywords. The scores are visualized in the t-SNE document map.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Keyword Extraction from a Set of Text Documents","images":[{"width":587,"height":336,"src":"/workflows/text-keyword-extraction/text-keyword-extraction.webp"}],"type":"workflows","blog_link":"","video":"","download":"text-keyword-extraction.ows","workflows":["Text Mining"],"weight":656,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"The Extract Keywords widget can characterize a set of textual documents. In this workflow, we load the documents from the server, preprocess them and embed them in the vector space, and display a semantic document map in the t-SNE widget. In this widget, we can select a set of similar documents and then characterize them through keyword extraction. Extract keywords support different inference techniques, including TF-IDF and deep network-based characterization.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Load Text Corpus from the Server Repository","images":[{"width":553,"height":319,"src":"/workflows/text-loading-from-repository/text-loading-from-repository.webp"}],"type":"workflows","blog_link":"","video":"","download":"text-loading-from-repository.ows","workflows":["Text Mining"],"weight":650,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_components.p, {\n    children: [\"The workflow loads the corpus from the \", _jsx(_components.a, {\n      href: \"http://file.biolab.si/text-semantics/data/predlogi-vladi-1k/\",\n      children: \"text repository on the server\"\n    }), \". The repository contains documents with raw text and associated YAML files with meta-features. We here use some pre-processing and then display the most frequent words in a word cloud. This workflow could work on your repository: just change the URL in the Import Documents widget.\"]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Ontology Generation from Keywords","images":[{"width":1438,"height":534,"src":"/workflows/text-ontology/text-ontology.webp"}],"type":"workflows","blog_link":"","video":"","download":"text-ontology.ows","workflows":["Text Mining"],"weight":668,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"We can automatically build the otology from the set of words. In the workflow, we select a group of documents with similar content. From the selected documents, we extract keywords and generate a new ontology from the subset of keywords with the Ontology widget.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Text Preprocessing","images":[{"width":1271,"height":774,"src":"/workflows/text-preprocessing/text-preprocessing.webp"}],"type":"workflows","blog_link":"2017/06/19/text-preprocessing/","video":"https://youtu.be/V70UwJZWkZ8","download":"610-text-preprocessing.ows","workflows":["Text Mining","Preprocessing","Tokenization"],"weight":610,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"Text mining requires careful preprocessing. Here's a workflow that uses simple preprocessing for creating tokens from documents. First, it applies lowercase, then splits text into words, and finally, it removes frequent stopwords. Preprocessing is language specific, so change the language to the language of texts where required. Results of preprocessing can be observe in a Word Cloud.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Semantic Document Map","images":[{"width":671,"height":329,"src":"/workflows/text-semantic-document-map/text-semantic-document-map.webp"}],"type":"workflows","blog_link":"","video":"","download":"text-semantic-word-map.ows","workflows":["Text Mining"],"weight":652,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"Document maps may reveal clusters of documents with semantically similar content. Here we show a workflow that loads the corpus, performs some text preprocessing and embeds the documents in the vector space using the fastText deep model. The t-SNE widget reveals the document map, where we can select a set of documents and then explore them in Corpus Viewer or characterize them in the display of the most frequent words in the Word Cloud.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Semantic Word Map","images":[{"width":701,"height":395,"src":"/workflows/text-semantic-word-map/text-semantic-word-map.webp"},{"width":758,"height":581,"src":"/workflows/text-semantic-word-map/text-semantic-word-map-tsne.webp"}],"type":"workflows","blog_link":"","video":"","download":"text-semantic-word-map.ows","workflows":["Text Mining"],"weight":654,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"We can find clusters of semantically related words either by hierarchical clustering or t-SNE visualizations. Here, we show a workflow that loads the documents, extracts frequent words, embeds them in a vector space, and explores word clusters.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Classification Tree","images":[{"width":1437,"height":875,"src":"/workflows/tree-scatterplot/tree-scatterplot.webp"}],"type":"workflows","blog_link":"","video":"","download":"250-tree-scatterplot.ows","workflows":["Classification Tree","Classification"],"weight":250,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"This workflow combines the interface and visualization of classification trees with scatter plot. When both the tree viewer and the scatter plot are open, selection of any node of the tree sends the related data instances to scatter plot. In the workflow, the selected data is treated as a subset of the entire dataset and is highlighted in the scatter plot. With simple combination of widgets we have constructed an interactive classification tree browser.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Twitter Data Analysis","images":[{"width":1326,"height":807,"src":"/workflows/twitter/twitter.webp"}],"type":"workflows","blog_link":"","video":"https://youtu.be/HDkI6G4slzQ","download":"640-twitter.ows","workflows":["Text Mining","Twitter","Topic Modeling"],"weight":640,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"Tweets are a valuable source of information, for social scientists, marketing managers, linguists, economists, and so on. In this workflow we retrieve data from Twitter, preprocess it, and uncover latent topics with topic modeling. We observe the topics in a Heat Map.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},{"title":"Where Are Misclassifications","images":[{"width":1079,"height":657,"src":"/workflows/where-are-misclassifications/misclassifications.webp"}],"type":"workflows","blog_link":"","video":"","download":"470-misclassification-scatterplot.ows","workflows":["Confusion Matrix","Classification","Scatter Plot"],"weight":470,"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\"\n  }, _provideComponents(), props.components);\n  return _jsx(_components.p, {\n    children: \"Cross-validation of, say, logistic regression can expose the data instances which were misclassified. There are six such instances for iris dataset and ridge-regularized logistic regression. We can select different types of misclassification in Confusion Matrix and highlight them in the Scatter Plot. No surprise: the misclassified instances are close to the class-bordering regions in the scatter plot projection.\"\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}}],"tags":["Survival Analysis","Cox Regression","Concordance Index","Cross Validation","Clustering","Hierarchical Clustering","Box Plot","Kaplan-Meier","Predictive models","Classification","Data Sampler","Scatter Plot","Visualization","Feature Ranking","Feature Selection","Data Table","Data Loading","mental health","survey","Silhouette","Outliers","Data","Pivot Table","PCA","Dimensionality Reduction","Text Mining","Timeseries","Sentiment Analysis","Nomogram","Bag of Words","Tokenization","Preprocessing","Classification Tree","Twitter","Topic Modeling","Confusion Matrix"]},"__N_SSG":true},"page":"/workflows","query":{},"buildId":"P93EmBG6Sh8IwFrfGAo9y","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>