{"pageProps":{"frontmatter":{"author":"AJDA","date":"2015-10-16 08:32:43+00:00","draft":false,"title":"Learners in Python","type":"blog","blog":["classification","examples","orange3","python","scripting"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    strong: \"strong\",\n    pre: \"pre\",\n    code: \"code\",\n    em: \"em\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"We've already written about \", _jsx(_components.a, {\n        href: \"/blog/2015/08/14/classifying-instances-with-orange-in-python/\",\n        children: \"classifying instances in Python\"\n      }), \". However, it's always nice to have a comprehensive list of classifiers and a step-by-step procedure at hand.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.strong, {\n        children: \"TRAINING THE CLASSIFIER\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We start with simply importing Orange module into Python and loading our data set.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    >>>> import Orange\\n    >>>> data = Orange.data.Table(\\\"titanic\\\")\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We are using 'titanic.tab' data. You can load any data set you want, but it does have to have a categorical class variable (for numeric targets use regression). Now we want to train our classifier.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    >>>> learner = Orange.classification.LogisticRegressionLearner()\\n    >>>> classifier = learner(data)\\n    >>>> classifier(data[0])\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Python returns the index of the value, as usual.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    array[0.]\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To check what's in the class variable we print:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    >>>>print(\\\"Name of the variable: \\\", data.domain.class_var.name)\\n    >>>>print(\\\"Class values: \\\", data.domain.class_var.values)\\n    >>>>print(\\\"Value of our instance: \\\", data.domain.class_var.values[0])\\n    \\n    Name of the variable: survived\\n    Class values: no, yes\\n    Value of our instance: no\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.strong, {\n        children: \"PREDICTIONS\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If you want to get predictions for the entire data set, just give the classifier the entire data set.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    >>>> classifier(data)\\n    \\n    array[0, 0, 0, ..., 1, 1, 1]\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If we want to append predictions to the data table, first use classifier on the data, then create a new domain with an additional meta attribute and finally form a new data table with appended predictions:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    svm = classifier(data)\\n    \\n    new_domain = Orange.data.Domain(data.domain.attributes, data.domain.class_vars, [data.domain.class_var])\\n    \\n    table2 = Orange.data.Table(new_domain, data.X, data.Y, svm.reshape(-1, 1))\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We use .reshape to transform vector data into a reshaped array. Then we print out the data.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    print(table2)\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.strong, {\n        children: \"PARAMETERS\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Want to use another classifier? The procedure is the same, simply use:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    Orange.classification.<algorithm-name>()\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For most classifiers, you can set a whole range of parameters. Logistic Regression, for example, uses the following:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    learner = Orange.classification.LogisticRegressionLearner(**penalty**='l2', **dual**=False, **tol**=0.0001, **C**=1.0, **fit_intercept**=True, **intercept_scaling**=1, **class_weight**=None, **random_state**=None **preprocessors**=None)\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To check the parameters for the classifier, use:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    print(Orange.classification.SVMLearner())\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.strong, {\n        children: \"PROBABILITIES\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Another thing you can check with classifiers are the probabilities.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    classifier(data[0], Orange.classification.Model.ValueProbs)\\n    \\n    >>>(array([ 0.]), array([[ 1.,  0.]]))\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The first array is the value for your selected instance (data[0]), while the second array contains probabilities for class values (probability for ‘no’ is 1 and for ‘yes’ 0).\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.strong, {\n        children: \"CLASSIFIERS\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"And because we care about you, we’re giving you here a full list of classifier names:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"LogisticRegressionLearner()\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"NaiveBayesLearner()\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"KNNLearner()\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"TreeLearner()\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"MajorityLearner()\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"RandomForestLearner()\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"SVMLearner()\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"For other learners, you can find all the parameters and descriptions \", _jsx(_components.a, {\n        href: \"https://docs.biolab.si/orange/3/data-mining-library/tutorial/classification.html\",\n        children: \"in the documentation\"\n      }), \".\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true}