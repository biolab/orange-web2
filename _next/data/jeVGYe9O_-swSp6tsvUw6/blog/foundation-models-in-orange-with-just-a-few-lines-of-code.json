{"pageProps":{"frontmatter":{"author":"Martin Špendl","date":"2025-01-20","draft":false,"title":"Foundation models in Orange with just a few lines of code","thumbImage":"ESM2-thumb.png","frontPageImage":"ESM2-thumb.png","blog":["analysis","bioinformatics","Foundation Models"],"shortExcerpt":"Foundation models can be used in Orange in just a few lines of code. Python Script can unlock every model from Hugging Face if you are brave enough.","longExcerpt":"Hugging Face foundation models can be used in Orange. With a few lines of code in the Python Script widget, you can download and run any model from the Hugging Face repository and unlock new levels of analysis in your Workflows."},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    h2: \"h2\",\n    strong: \"strong\",\n    em: \"em\",\n    h3: \"h3\",\n    a: \"a\",\n    pre: \"pre\",\n    code: \"code\",\n    span: \"span\"\n  }, _provideComponents(), props.components), {WindowScreenshot} = _components;\n  if (!WindowScreenshot) _missingMdxReference(\"WindowScreenshot\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Foundation models are becoming a necessary addition to our toolbox, especially in fields like biomedicine. A large community of researchers is developing these models, so you don’t have to! Improved versions of models are uploaded almost by the minute on repositories like Hugging Face. The following blog/tutorial will show you how to use models from Hugging Face in Orange with just a bit of coding. Fear not; you will be only required to write a few lines in the Python Script widget, and you will unlock the full power of foundation models. Let’s begin!\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"What You’ll Need\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Before we get started, make sure you’ve got Orange installed on your computer. You’ll also need two Python packages: \", _jsx(_components.strong, {\n        children: \"torch\"\n      }), \" and \", _jsx(_components.strong, {\n        children: \"transformers\"\n      }), \". To install these packages, open Orange, navigate to Options and select Add-ons. In the upper right corner, click \", _jsx(_components.em, {\n        children: \"Add more…\"\n      }), \" and type torch. Once you can see the package in the list of add-ons, check the square and press OK on the bottom left corner of the window. This procedure will install the package torch  in your Orange application. Use the same procedure for the transformers package. You will only have to do this once. You can quickly check if your installation was successful by opening the Python Script widget, typing in the console: \", _jsx(_components.em, {\n        children: \"import transformers\"\n      }), \", and pressing Enter. If there is no error, the installation was successful.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2025-01-bio-foundation-models/install-dep.png\",\n      width: \"621\",\n      height: \"566\",\n      src: \"/blog/2025-01-bio-foundation-models/__optimized-images__/install-dep.png\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"A Biology Problem: Grouping Proteins by Their Structure\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Proteins are long chains of amino acids that fold into 3D structures, determining their function. These protein stuctures can vary from small and globular (Cathepsin K), highly structured (transmembrane beta barrel), to large and multimeric structures, for example Spike protein of SARS-CoV-2. Determining their structure was, until recently, a very tedious task and sometimes even nearly impossible. Nowadays, large foundation models can infer protein structure from just their amino acid sequence, and we will use one of those models in our analysis.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2025-01-bio-foundation-models/spike_cathepsin_beta.png\",\n      width: \"1132\",\n      height: \"795\",\n      src: \"/blog/2025-01-bio-foundation-models/__optimized-images__/spike_cathepsin_beta.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Our goal here is to group human proteins with similar structures—without comparing their actual structure! We’ll turn protein sequences into numbers (embeddings) using the ESM-2 model from Hugging Face. These embeddings capture patterns hinting at structural similarities and are thus easier to compare than structures. Later, we will try to identify groups of proteins with similar structures.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Step 1: Creating ESM-2 Embeddings\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We will work with a subset of 5000 human proteins downloaded from the \", _jsx(_components.a, {\n        href: \"https://www.uniprot.org/proteomes/UP000005640\",\n        children: \"UniProt\"\n      }), \". You can download this \", _jsx(_components.a, {\n        href: \"/blog/2025-01-bio-foundation-models/human_proteins.csv\",\n        children: \"CSV file\"\n      }), \", where we processed the downloaded FASTA file. We kept 5000 random proteins with sequence lengths between 100 and 1500 amino acids. The longer the sequence, the more computation resources the model will require. We can easily load this file into Orange with the File widget. The Data Table widget shows that aminoacid sequences are stored in the \\\"sequence\\\" column.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We will now use a protein foundation model from Meta called ESM-2. Visit the Hugging Face website to inspect the model. ESM-2 comes in different sizes, from 8M to 15B parameters. We will use the smallest version to save computation time, but feel free to upgrade the model. To find foundation models in general, you can search through Hugging Face. Copy the model’s name on the top of the page (e.g., \\\"facebook/esm2_t6_8M_UR50D\\\") and return to Orange.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Open a Python Script widget and copy the code below inside the python_script function. Let’s quickly go through what it does. First, it imports the necessary packages like \", _jsx(_components.em, {\n        children: \"numpy\"\n      }), \" and \", _jsx(_components.em, {\n        children: \"torch\"\n      }), \". Then, we fetch sequences from our in_data, which is a DataTable on the input of the Python Script widget. The next three lines are where we define our foundation model, in our case, the \\\"facebook/esm2_t6_8M_UR50D\\\". Tokenizer is used to transform our sequence into tokens, the language of the model. Lastly, we define the model itself with the EsmModel class. Note that if you use another foundation model (e.g., DNABert), you only need to change the variable ‘model_name.’ In the following steps, we iterate through sequences, using the tokenizer and the model to extract the protein embedding on the output. The last for loop goes through protein embeddings and appends each column to our data table. Finally, we output the resulting table with protein embeddings as columns.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-python\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# import necessary packages and classes\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Feel free to use ChatGPT to explain this code in furher detail\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" numpy \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"as\"\n        }), \" np\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" torch\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" Orange.data \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" ContinuousVariable\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" transformers \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" AutoTokenizer, AutoModel\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# we extract the column sequences from our data table\"\n        }), \"\\nout_data = in_data.copy()\\nsequences = out_data.get_column(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"sequence\\\"\"\n        }), \")\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# we define model_name, while AutoTokenizer and EsmModel download the foundation model\"\n        }), \"\\nmodel_name = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"facebook/esm2_t6_8M_UR50D\\\"\"\n        }), \"\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\nmodel = AutoModel.from_pretrained(model_name)\\n\\nembeddings = []\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"for\"\n        }), \" i \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"in\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"range\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"len\"\n        }), \"(sequences)):\\n    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# First, we have to transform each sequence into tokens\"\n        }), \"\\n    inputs = tokenizer(sequences[i], return_tensors=\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"pt\\\"\"\n        }), \")\\n    \\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"with\"\n        }), \" torch.no_grad():\\n        \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Then, we calculate the embeddings of the sequence with ESM-2 model\"\n        }), \"\\n        outputs = model(**inputs)\\n\\n    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Importantly, we use .detach() to reduce the memory load\"\n        }), \"\\n    embeddings.append(outputs.last_hidden_state[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"][\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"].detach().numpy())\\nembeddings = np.array(embeddings)\\n\\nEMB_DIM = embeddings.shape[-\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1\"\n        }), \"]\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"for\"\n        }), \" i \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"in\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"range\"\n        }), \"(EMB_DIM):\\n    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Lastly, we append each column of embeddings to our data as a Continuous variable\"\n        }), \"\\n    out_data = out_data.add_column(ContinuousVariable(\", _jsxs(_components.span, {\n          className: \"hljs-string\",\n          children: [\"f\\\"ESM-emb-\", _jsx(_components.span, {\n            className: \"hljs-subst\",\n            children: \"{i}\"\n          }), \"\\\"\"]\n        }), \"), embeddings[:, i])\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"NOTE: Executing this code might take a few minutes up to an hour depending on your computational resources!\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2025-01-bio-foundation-models/query-ESM-2.png\",\n      width: \"1430\",\n      height: \"615\",\n      src: \"/blog/2025-01-bio-foundation-models/__optimized-images__/query-ESM-2.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let’s inspect what does our table look like now. In addition to our protein data, there are 320 columns representing the embedding. These values do now have meaning on their own, but we will see how to extract some information out of them shortly. Since the computation of embeddings took quite a few time, let’s store the data first, before doing any further analysis.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Step 2: Visualizing Embeddings with t-SNE\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now that we have the embeddings, let’s make sense of them visually. Using a t-SNE plot, we’ll turn these high-dimensional numbers into a simple 2D scatter plot. This makes it easy to spot clusters of proteins with similar structures. Even proteins without known structures can find their place in these clusters, helping us discover hidden relationships between them. If you want to inspect any of these groups, select them on the plot while holding the Shift key. We can inspect proteins in each group in the DataTable and change their group label to something more meaningful. Lastly, we can see different groups of proteins with respect to their structures, eventhough we did not have to compare any structures at all. Isn’t that amazing.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2025-01-bio-foundation-models/analyse-ESM-2-embeddings.png\",\n      width: \"1354\",\n      height: \"912\",\n      src: \"/blog/2025-01-bio-foundation-models/__optimized-images__/analyse-ESM-2-embeddings.png\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Wrapping Up\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Foundation models paired with tools like Orange open up a world of possibilities on how to analyze complex data. This post is meant to introduce you to how we can use Hugging Face foundation models using a Python Script widget. It might seem a bit involved at first, but with a bit of help from ChatGPT, you can be using the latest cutting edge foundation models in no time.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}},"thumbImage":{"width":804,"height":443,"src":"/blog/2025-01-bio-foundation-models/__optimized-images__/ESM2-thumb.png"}},"__N_SSG":true}