{"pageProps":{"frontmatter":{"author":"Ajda Pretnar","date":"2021-09-15","draft":false,"title":"New in Orange: Support for CONLL-U files","type":"blog","thumbImage":"2021-09-15-conllu.png","frontPageImage":"2021-09-15-conllu.png","blog":["conllu","text mining","corpus","lemma"],"shortExcerpt":"Orange can now work with CONLL-U files!","longExcerpt":"Orange can now work with CONLL-U files, including its lemmas, POS tags, and named entities.","x2images":true},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    pre: \"pre\",\n    code: \"code\"\n  }, _provideComponents(), props.components), {WindowScreenshot} = _components;\n  if (!WindowScreenshot) _missingMdxReference(\"WindowScreenshot\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [_jsx(_components.a, {\n        href: \"https://universaldependencies.org/format.html\",\n        children: \"CONLL-U\"\n      }), \" files are ubiquitous in text mining and natural language processing. They can hold a great deal of linguistic data, specifically sentence boundaries, word lemmas, universal POS tags, language specific POS tag, morphological features, dependency relations, named entities, and so on. This is how a typical CONLL-U file looks like.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    # sent_id = ParlaMint-GB_2021-01-05-lords.seg2.2\\n    # text = The Hybrid Sitting of the House will now begin.\\n    1 The   the   DET   DT   Definite=Def|PronType=Art   2   det   _   NER=O\\n    2 Hybrid    hybrid   NOUN   NN   Number=Sing   9   nsubj   _   NER=O\\n    3 Sitting   sit   VERB   VBG   VerbForm=Ger   2   acl   _   NER=O\\n    4 of    of   ADP   IN   _   6   case   _   NER=O\\n    5 the   the   DET   DT   Definite=Def|PronType=Art   6   det   _   NER=O\\n    6 House House   PROPN   NNP   Number=Sing   3   obl   _   NER=B-ORG\\n    7 will  will   VERB   MD   VerbForm=Fin   9   aux   _   NER=O\\n    8 now   now   ADV   RB   _   9   advmod   _   NER=O\\n    9 begin begin   VERB   VB   VerbForm=Inf   0   root   _   NER=O|SpaceAfter=No\\n    10 .    .   PUNCT   .   _   9   punct   _   NER=O\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Since the release of Text v. 1.5.0, Orange can import CONNL-U files and its textual information. Specifically, Orange will import each utterance as a separate text entity. If selected in import options, it will append lemmas as tokens, POS tags as POS tags, and named entities as a separate text column. It will also add meta information to the imported corpus, if present in the folder.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Here's an example. We are using \", _jsx(_components.a, {\n        href: \"https://www.clarin.si/repository/xmlui/handle/11356/1431\",\n        children: \"ParlaMint-GB v2.1 data\"\n      }), \" from CLARIN repository, which contains annotated parliament speeches. Using Import Documents widget, we will import all the sessions for the year 2021.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-connlu-files/2021-09-15-import-documents.png\",\n      width: \"611\",\n      height: \"396\",\n      src: \"/blog/2021-09-connlu-files/__webp-images__/2021-09-15-import-documents.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In the widget, we can set which parts of the CONLL-U file will be imported. Let us go with lemmas and POS tags. With this, we don't need preprocessing as usual, as lemmas will be automatically considered downstream (for example in bag of words or topic modeling).\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"However, the new release of Text also enables us to filter on POS tags. Say we wish to keep only nouns and verbs. We can use Preprocess Text to keep only the specified tags. Remember to remove the default preprocessors as they will override the pre-set tokens.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-connlu-files/2021-09-15-preprocess-text.png\",\n      width: \"1150\",\n      height: \"520\",\n      src: \"/blog/2021-09-connlu-files/__webp-images__/2021-09-15-preprocess-text.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Looking at the Word Cloud, we can see that indeed only verbs and nouns were kept after preprocessing. And not only that! As we have selected to import lemmas, our words will already be normalized. Most of the preprocessing work is done for us! Now you can play with downstream analysis - for example, try to determine which words are significant for which MP using Word Enrichment!\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-connlu-files/2021-09-15-word-cloud.png\",\n      width: \"1188\",\n      height: \"697\",\n      src: \"/blog/2021-09-connlu-files/__webp-images__/2021-09-15-word-cloud.webp\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-connlu-files/2021-09-15-workflow.png\",\n      width: \"500\",\n      height: \"124\",\n      src: \"/blog/2021-09-connlu-files/__webp-images__/2021-09-15-workflow.webp\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}}},"__N_SSG":true}