<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-9f90a364d66949ce.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8cfbd06f8ddd0b49.js" defer=""></script><script src="/_next/static/chunks/675-262430aa11afdf01.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-ba4a3f289f8ef3c5.js" defer=""></script><script src="/_next/static/GwUsIp3okGZ01glTrQqIW/_buildManifest.js" defer=""></script><script src="/_next/static/GwUsIp3okGZ01glTrQqIW/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.iBQlkL{background:coral;height:60px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.iBQlkL ul{display:none;}}/*!sc*/
data-styled.g1[id="sc-7295e4c-0"]{content:"iBQlkL,"}/*!sc*/
.bDMZDz{display:none;font-size:22px;margin-left:auto;}/*!sc*/
@media (max-width:920px){.bDMZDz{display:block;}}/*!sc*/
data-styled.g2[id="sc-7295e4c-1"]{content:"bDMZDz,"}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
body{background:#fff;}/*!sc*/
html{box-sizing:border-box;font-size:16px;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
img,video{max-width:100%;height:auto;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g3[id="sc-global-cqyaiF1"]{content:"sc-global-cqyaiF1,"}/*!sc*/
.cGDPDa{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g6[id="sc-f0e62130-0"]{content:"cGDPDa,"}/*!sc*/
</style></head><body><div id="__next"><nav class="sc-7295e4c-0 iBQlkL"><ul><a href="/blog">Blog</a></ul><button class="sc-7295e4c-1 bDMZDz">X</button></nav><main><div class="sc-f0e62130-0 cGDPDa"><h1>Viewing Images</h1><div class="lg-react-element "><p>I am lately having fun with Image Viewer. The widget has been recently updated and can display images stored locally or on the internet. But wait, what images? How on earth can Orange now display images if it can handle mere tabular or basket-based data?</p>
<p>Here&#x27;s an example. I have considered a subset of animals from the [download id=&quot;864&quot;] data set (comes with Orange installation), and for demonstration purposes selected only a handful of attributes. I have added a new string attribute (&quot;images&quot;) and declared that this is a meta attribute of the type &quot;image&quot;. The values of this attribute are links to images on the web:</p>
<a href="/blog/2014-04-viewing-images/animals-dataset_1.png__610x213_q95_crop_upscale.webp" data-gallery="true"><img alt="" srcSet="/blog/2014-04-viewing-images/animals-dataset_1.png__610x213_q95_crop_upscale.webp 1x, /blog/2014-04-viewing-images/animals-dataset_1.png__610x213_q95_crop_upscale.webp 2x" src="/blog/2014-04-viewing-images/animals-dataset_1.png__610x213_q95_crop_upscale.webp" width="610" height="213" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>Here is the resulting data set, [download id=&quot;859&quot;]. I have used this data set in a schema with hierarchical clustering, where upon selection of the part of the clustering tree I can display the associated images:</p>
<a href="/blog/2014-04-viewing-images/animals-schema.png__610x428_q95_crop_upscale.webp" data-gallery="true"><img alt="" srcSet="/blog/2014-04-viewing-images/animals-schema.png__610x428_q95_crop_upscale.webp 1x, /blog/2014-04-viewing-images/animals-schema.png__610x428_q95_crop_upscale.webp 2x" src="/blog/2014-04-viewing-images/animals-schema.png__610x428_q95_crop_upscale.webp" width="610" height="428" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>Typically and just like above, you would use a string meta attribute to store the link to images. Images can be referred to using a HTTP address, or, if stored locally, using a relative path from the data file location to the image files.</p>
<p>Here is another example, where all the images were local and we have associated them with a famous <a href="https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits">digits data set</a> ( <a href="/blog/2014-04-viewing-images/">download id=&quot;868&quot;</a> is a data set in the Orange format with the image files). The task for this data set is to classify handwritten digits based on their bitmap representation. In the schema below we wanted to find out which are the most frequent errors some classification algorithm would make, and how do the images of the misclassified digits look like. Turns out that SVM with RBF kernel most often misclassify the digit 9 and confuses it with a digit 3:</p>
<a href="/blog/2014-04-viewing-images/digits-schema.png__610x495_q95_crop_upscale.webp" data-gallery="true"><img alt="" srcSet="/blog/2014-04-viewing-images/digits-schema.png__610x495_q95_crop_upscale.webp 1x, /blog/2014-04-viewing-images/digits-schema.png__610x495_q95_crop_upscale.webp 2x" src="/blog/2014-04-viewing-images/digits-schema.png__610x495_q95_crop_upscale.webp" width="610" height="495" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"BIOLAB","date":"2014-04-29 21:28:00+00:00","draft":false,"title":"Viewing Images","type":"blog","blog":["clustering","images","visualization"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\",\n    a: \"a\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"I am lately having fun with Image Viewer. The widget has been recently updated and can display images stored locally or on the internet. But wait, what images? How on earth can Orange now display images if it can handle mere tabular or basket-based data?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Here's an example. I have considered a subset of animals from the [download id=\\\"864\\\"] data set (comes with Orange installation), and for demonstration purposes selected only a handful of attributes. I have added a new string attribute (\\\"images\\\") and declared that this is a meta attribute of the type \\\"image\\\". The values of this attribute are links to images on the web:\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2014-04-viewing-images/animals-dataset_1.png__610x213_q95_crop_upscale.webp\",\n      alt: \"\",\n      width: \"610\",\n      height: \"213\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Here is the resulting data set, [download id=\\\"859\\\"]. I have used this data set in a schema with hierarchical clustering, where upon selection of the part of the clustering tree I can display the associated images:\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2014-04-viewing-images/animals-schema.png__610x428_q95_crop_upscale.webp\",\n      alt: \"\",\n      width: \"610\",\n      height: \"428\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Typically and just like above, you would use a string meta attribute to store the link to images. Images can be referred to using a HTTP address, or, if stored locally, using a relative path from the data file location to the image files.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Here is another example, where all the images were local and we have associated them with a famous \", _jsx(_components.a, {\n        href: \"https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\",\n        children: \"digits data set\"\n      }), \" ( \", _jsx(_components.a, {\n        href: \"/blog/2014-04-viewing-images/\",\n        children: \"download id=\\\"868\\\"\"\n      }), \" is a data set in the Orange format with the image files). The task for this data set is to classify handwritten digits based on their bitmap representation. In the schema below we wanted to find out which are the most frequent errors some classification algorithm would make, and how do the images of the misclassified digits look like. Turns out that SVM with RBF kernel most often misclassify the digit 9 and confuses it with a digit 3:\"]\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2014-04-viewing-images/digits-schema.png__610x495_q95_crop_upscale.webp\",\n      alt: \"\",\n      width: \"610\",\n      height: \"495\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"viewing-images"},"buildId":"GwUsIp3okGZ01glTrQqIW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>