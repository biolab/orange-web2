<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-9f90a364d66949ce.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8cfbd06f8ddd0b49.js" defer=""></script><script src="/_next/static/chunks/675-262430aa11afdf01.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-9a1cb73998fd1a10.js" defer=""></script><script src="/_next/static/04VXD22onVkuW7PtxIiPd/_buildManifest.js" defer=""></script><script src="/_next/static/04VXD22onVkuW7PtxIiPd/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.iBQlkL{background:coral;height:60px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.iBQlkL ul{display:none;}}/*!sc*/
data-styled.g1[id="sc-7295e4c-0"]{content:"iBQlkL,"}/*!sc*/
.bDMZDz{display:none;font-size:22px;margin-left:auto;}/*!sc*/
@media (max-width:920px){.bDMZDz{display:block;}}/*!sc*/
data-styled.g2[id="sc-7295e4c-1"]{content:"bDMZDz,"}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
body{background:#fff;}/*!sc*/
html{box-sizing:border-box;font-size:16px;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
img,video{max-width:100%;height:auto;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g3[id="sc-global-cqyaiF1"]{content:"sc-global-cqyaiF1,"}/*!sc*/
.jjvzAY{display:block;margin-left:auto;margin-right:auto;}/*!sc*/
data-styled.g4[id="sc-e3044145-0"]{content:"jjvzAY,"}/*!sc*/
.cGDPDa{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g6[id="sc-f0e62130-0"]{content:"cGDPDa,"}/*!sc*/
</style></head><body><div id="__next"><nav class="sc-7295e4c-0 iBQlkL"><ul><a href="/blog">Blog</a></ul><button class="sc-7295e4c-1 bDMZDz">X</button></nav><main><div class="sc-f0e62130-0 cGDPDa"><h1>Explaining Predictive Models</h1><div class="lg-react-element "><p>It is easy to build powerful predictive models in Orange. But how does the model &quot;look like&quot;? Which attributes and which values of those attributes are important? And when making predictions, which attributes contributed to the decision? <strong>Orange&#x27;s new Explain add-on</strong> helps you answer all those questions.</p>
<p>Related: <a href="/blog/2019/2019-11-20-belgrade-workshop/" target="_blank">Explaining Models</a></p>
<p>Go to <strong>Options --&gt; Add-ons</strong> and install Explain add-on. Restart Orange for the add-on to appear. It only contains two widgets, but boy are they great!</p>
<p>Let us start with the attrition data set from the Datasets widget. We will go with <strong>Attrition - Train</strong>, which a data set on which employees resigned from the company and which stayed. The target variable is called Attrition, where <strong>No</strong> means that the employee stayed and <strong>Yes</strong> that the employee resigned. The other attributes describe the employee - her position, education, department, years since promotion, and so on.</p>
<a href="/blog/2021-02-explaining-models/2021-02-10-data-table.webp" data-gallery="true"><img srcSet="/blog/2021-02-explaining-models/2021-02-10-data-table.webp 1x, /blog/2021-02-explaining-models/2021-02-10-data-table.webp 2x" src="/blog/2021-02-explaining-models/2021-02-10-data-table.webp" width="1052" height="590" decoding="async" data-nimg="1" class="sc-e3044145-0 jjvzAY" loading="lazy" style="color:transparent"/></a>
<p>Next, we will build a simple logistic regression predictive model. If inspecting the model in Test and Score, we learn that the model has an AUC of 0.788 and 86 % CA. But what <em>kind</em> of a model is this? How does it makes its decisions?</p>
<p>Let us add Explain Model to Logistic Regression and add another connection passing the data. The workflow should look like this:</p>
<a href="/blog/2021-02-explaining-models/2021-02-10-model-workflow.webp" data-gallery="true"><img srcSet="/blog/2021-02-explaining-models/2021-02-10-model-workflow.webp 1x, /blog/2021-02-explaining-models/2021-02-10-model-workflow.webp 2x" src="/blog/2021-02-explaining-models/2021-02-10-model-workflow.webp" width="482" height="209" decoding="async" data-nimg="1" class="sc-e3044145-0 jjvzAY" loading="lazy" style="color:transparent"/></a>
<p>Now open Explain Model. The widget lists top ranked variables, which means they contribute the most to the selected target variable. As we are trying to understand why people leave the company, we have set the target variable to Yes.</p>
<p>The highest ranked variable is OverTime - this is the variable with the highest impact on the prediction. Having a value Yes in the categorical attribute OverTime (red dots on the right) means the employee is likely to quit. Also, having low job satisfaction contributes to attrition (blue values on the right). The visualization shows the values which have a high impact on the prediction of the selected class on the right and those which vote against the selected class on the left. The color of dot represents the value of the attribute (red for higher values and blue for lower).</p>
<a href="/blog/2021-02-explaining-models/2021-02-10-explain-model.webp" data-gallery="true"><img srcSet="/blog/2021-02-explaining-models/2021-02-10-explain-model.webp 1x, /blog/2021-02-explaining-models/2021-02-10-explain-model.webp 2x" src="/blog/2021-02-explaining-models/2021-02-10-explain-model.webp" width="996" height="763" decoding="async" data-nimg="1" class="sc-e3044145-0 jjvzAY" loading="lazy" style="color:transparent"/></a>
<p>Let us look at, for example, YearsAtCompany. How would we interpret this? The variable has more red dots on the left, which means high variable values contribute <em>against</em> the target value (against attrition, i.e. employees will stay). Red dots refer to the value of the attribute. So if the employee is with the company for a long time (high value == red dot), it means it is more likely she will stay (dots are on the left, while our target value is Yes).</p>
<p>Great, now we understand the model and we are ready to make some predictions. Let us load Attrition - Predict with another Dataset widget. We have three new employees, who are described with all the previous variables, but they are lacking Attrition - we do not know, who is more likely to leave.</p>
<a href="/blog/2021-02-explaining-models/2021-02-10-table-predict.webp" data-gallery="true"><img srcSet="/blog/2021-02-explaining-models/2021-02-10-table-predict.webp 1x, /blog/2021-02-explaining-models/2021-02-10-table-predict.webp 2x" src="/blog/2021-02-explaining-models/2021-02-10-table-predict.webp" width="775" height="223" decoding="async" data-nimg="1" class="sc-e3044145-0 jjvzAY" loading="lazy" style="color:transparent"/></a>
<p>Now pass the logistic regression model and the train data set to Explain Predictions. Then select John from the table and pass the selection to Explain Predictions. The widget requires three inputs: the model, training data, and the instance we are predicting (John).</p>
<a href="/blog/2021-02-explaining-models/2021-02-10-predict-workflow.webp" data-gallery="true"><img srcSet="/blog/2021-02-explaining-models/2021-02-10-predict-workflow.webp 1x, /blog/2021-02-explaining-models/2021-02-10-predict-workflow.webp 2x" src="/blog/2021-02-explaining-models/2021-02-10-predict-workflow.webp" width="524" height="340" decoding="async" data-nimg="1" class="sc-e3044145-0 jjvzAY" loading="lazy" style="color:transparent"/></a>
<p>Once again, we are interested in target value Yes. Variables in red increase the probability of the target value (conversely, blue decrease it). The size of the arrow corresponds to the <a href="https://shap.readthedocs.io/en/latest/index.html">SHAP value</a> - in other words, the larger the arrow the larger the variable&#x27;s contribution to the target value. The model also predicted that John will leave the job with 77 % probability.</p>
<a href="/blog/2021-02-explaining-models/2021-02-10-explain-prediction.webp" data-gallery="true"><img srcSet="/blog/2021-02-explaining-models/2021-02-10-explain-prediction.webp 1x, /blog/2021-02-explaining-models/2021-02-10-explain-prediction.webp 2x" src="/blog/2021-02-explaining-models/2021-02-10-explain-prediction.webp" width="751" height="770" decoding="async" data-nimg="1" class="sc-e3044145-0 jjvzAY" loading="lazy" style="color:transparent"/></a>
<p>As before, the most important variable for John is overtime. Him working overtime contributes a lot to the final prediction. Also, his job satisfaction is low (1 out of 5), making him likely to quit.</p>
<p>The results correspond very much to those of the model, but it might not always be the case. Some people might leave because they are very dissatisfied without working overtime. This would show in Explain Predictions. See how the results change for the other two employees, Rachel and Veronica. Or make up your own employee with Excel and see what would the prediction be.</p></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"Ajda Pretnar","date":"2021-02-10","draft":false,"title":"Explaining Predictive Models","type":"blog","thumbImage":"2021-02-10-explain-models-small.png","frontPageImage":"2021-02-10-explain-models-small.png","blog":["model explanation","explainable AI","explain","predictive modelling"],"shortExcerpt":"New Orange add-on for explaining predictive models.","longExcerpt":"New Orange Explain add-on for understanding predictions and predictive models.","x2images":false},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    strong: \"strong\",\n    em: \"em\",\n    a: \"a\"\n  }, _provideComponents(), props.components), {LinkNew, WorkflowScreenshot} = _components;\n  if (!LinkNew) _missingMdxReference(\"LinkNew\", true);\n  if (!WorkflowScreenshot) _missingMdxReference(\"WorkflowScreenshot\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"It is easy to build powerful predictive models in Orange. But how does the model \\\"look like\\\"? Which attributes and which values of those attributes are important? And when making predictions, which attributes contributed to the decision? \", _jsx(_components.strong, {\n        children: \"Orange's new Explain add-on\"\n      }), \" helps you answer all those questions.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Related: \", _jsx(LinkNew, {\n        url: \"/blog/2019/2019-11-20-belgrade-workshop/\",\n        name: \"Explaining Models\"\n      })]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Go to \", _jsx(_components.strong, {\n        children: \"Options --\u003e Add-ons\"\n      }), \" and install Explain add-on. Restart Orange for the add-on to appear. It only contains two widgets, but boy are they great!\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Let us start with the attrition data set from the Datasets widget. We will go with \", _jsx(_components.strong, {\n        children: \"Attrition - Train\"\n      }), \", which a data set on which employees resigned from the company and which stayed. The target variable is called Attrition, where \", _jsx(_components.strong, {\n        children: \"No\"\n      }), \" means that the employee stayed and \", _jsx(_components.strong, {\n        children: \"Yes\"\n      }), \" that the employee resigned. The other attributes describe the employee - her position, education, department, years since promotion, and so on.\"]\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-02-explaining-models/2021-02-10-data-table.png\",\n      width: \"1052\",\n      height: \"590\",\n      src: \"/blog/2021-02-explaining-models/2021-02-10-data-table.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Next, we will build a simple logistic regression predictive model. If inspecting the model in Test and Score, we learn that the model has an AUC of 0.788 and 86 % CA. But what \", _jsx(_components.em, {\n        children: \"kind\"\n      }), \" of a model is this? How does it makes its decisions?\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let us add Explain Model to Logistic Regression and add another connection passing the data. The workflow should look like this:\"\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-02-explaining-models/2021-02-10-model-workflow.png\",\n      width: \"482\",\n      height: \"209\",\n      src: \"/blog/2021-02-explaining-models/2021-02-10-model-workflow.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now open Explain Model. The widget lists top ranked variables, which means they contribute the most to the selected target variable. As we are trying to understand why people leave the company, we have set the target variable to Yes.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The highest ranked variable is OverTime - this is the variable with the highest impact on the prediction. Having a value Yes in the categorical attribute OverTime (red dots on the right) means the employee is likely to quit. Also, having low job satisfaction contributes to attrition (blue values on the right). The visualization shows the values which have a high impact on the prediction of the selected class on the right and those which vote against the selected class on the left. The color of dot represents the value of the attribute (red for higher values and blue for lower).\"\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-02-explaining-models/2021-02-10-explain-model.png\",\n      width: \"996\",\n      height: \"763\",\n      src: \"/blog/2021-02-explaining-models/2021-02-10-explain-model.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Let us look at, for example, YearsAtCompany. How would we interpret this? The variable has more red dots on the left, which means high variable values contribute \", _jsx(_components.em, {\n        children: \"against\"\n      }), \" the target value (against attrition, i.e. employees will stay). Red dots refer to the value of the attribute. So if the employee is with the company for a long time (high value == red dot), it means it is more likely she will stay (dots are on the left, while our target value is Yes).\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Great, now we understand the model and we are ready to make some predictions. Let us load Attrition - Predict with another Dataset widget. We have three new employees, who are described with all the previous variables, but they are lacking Attrition - we do not know, who is more likely to leave.\"\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-02-explaining-models/2021-02-10-table-predict.png\",\n      width: \"775\",\n      height: \"223\",\n      src: \"/blog/2021-02-explaining-models/2021-02-10-table-predict.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now pass the logistic regression model and the train data set to Explain Predictions. Then select John from the table and pass the selection to Explain Predictions. The widget requires three inputs: the model, training data, and the instance we are predicting (John).\"\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-02-explaining-models/2021-02-10-predict-workflow.png\",\n      width: \"524\",\n      height: \"340\",\n      src: \"/blog/2021-02-explaining-models/2021-02-10-predict-workflow.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Once again, we are interested in target value Yes. Variables in red increase the probability of the target value (conversely, blue decrease it). The size of the arrow corresponds to the \", _jsx(_components.a, {\n        href: \"https://shap.readthedocs.io/en/latest/index.html\",\n        children: \"SHAP value\"\n      }), \" - in other words, the larger the arrow the larger the variable's contribution to the target value. The model also predicted that John will leave the job with 77 % probability.\"]\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-02-explaining-models/2021-02-10-explain-prediction.png\",\n      width: \"751\",\n      height: \"770\",\n      src: \"/blog/2021-02-explaining-models/2021-02-10-explain-prediction.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"As before, the most important variable for John is overtime. Him working overtime contributes a lot to the final prediction. Also, his job satisfaction is low (1 out of 5), making him likely to quit.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The results correspond very much to those of the model, but it might not always be the case. Some people might leave because they are very dissatisfied without working overtime. This would show in Explain Predictions. See how the results change for the other two employees, Rachel and Veronica. Or make up your own employee with Excel and see what would the prediction be.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"explaining-predictive-models"},"buildId":"04VXD22onVkuW7PtxIiPd","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>