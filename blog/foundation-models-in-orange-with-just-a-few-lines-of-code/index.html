<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="description" content="Orange Data Mining Toolbox"/><meta property="og:url" content="https://orangedatamining.com"/><meta property="og:site_name" content="Orange Data Mining"/><meta name="author" content="Bioinformatics Laboratory, University of Ljubljana"/><title>Orange Data Mining - Foundation models in Orange with just a few lines of code</title><meta name="robots" content="index,follow"/><meta property="og:title" content="Orange Data Mining - Foundation models in Orange with just a few lines of code"/><meta property="og:description" content="Foundation models can be used in Orange in just a few lines of code. Python Script can unlock every model from Hugging Face if you are brave enough."/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-01-20"/><meta property="article:author" content="Martin Å pendl"/><meta property="article:tag" content="analysis"/><meta property="article:tag" content="bioinformatics"/><meta property="article:tag" content="Foundation Models"/><meta property="og:image" content="/blog/2025-01-bio-foundation-models/__optimized-images__/ESM2-thumb.png"/><meta property="og:image:width" content="804"/><meta property="og:image:height" content="443"/><meta name="next-head-count" content="19"/><link rel="preload" href="/_next/static/media/a9b61b60c2d733b4-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/2fbd8d191ccf221f.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/2fbd8d191ccf221f.css" crossorigin="" data-n-g=""/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" crossorigin="" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-21c828b96ad33382.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-0c7baedefba6b077.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-61a1de8ce4711ed8.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-a646f1579d13d30b.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/690-eebe7c6b2c5b12a7.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-f211bd4808f46605.js" defer="" crossorigin=""></script><script src="/_next/static/jeVGYe9O_-swSp6tsvUw6/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/jeVGYe9O_-swSp6tsvUw6/_ssgManifest.js" defer="" crossorigin=""></script><style data-styled="" data-styled-version="5.3.6">.eVggRJ{max-width:1296px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;box-sizing:content-box;}/*!sc*/
@media (max-width:1130px){.eVggRJ{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.eVggRJ{padding-left:15px;padding-right:15px;}}/*!sc*/
.CVQuR{max-width:1296px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;box-sizing:content-box;margin-bottom:80px;max-width:714px;}/*!sc*/
@media (max-width:1130px){.CVQuR{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.CVQuR{padding-left:15px;padding-right:15px;}}/*!sc*/
@media (max-width:920px){.CVQuR{margin-bottom:60px;}}/*!sc*/
data-styled.g1[id="sc-61db3aea-0"]{content:"eVggRJ,CVQuR,"}/*!sc*/
.jyxOJT{position:relative;display:inline-block;max-width:100%;font-size:20px;line-height:1.25;font-weight:600;-webkit-text-decoration:none;text-decoration:none;color:#fff;padding:10px 15px;border-radius:5px;background-image:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);background-size:100%;cursor:pointer;z-index:2;}/*!sc*/
@media (max-width:720px){.jyxOJT{font-size:18px;}}/*!sc*/
.jyxOJT:before{content:"";display:block;position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;background-image:linear-gradient(180deg,#ffbc44 100%,#FE7A00 100%);opacity:0;z-index:-100;-webkit-transition:opacity 0.45s;transition:opacity 0.45s;}/*!sc*/
.jyxOJT:hover{color:#fff;}/*!sc*/
.jyxOJT:hover:before{opacity:1;}/*!sc*/
data-styled.g2[id="sc-b6ea565a-0"]{content:"jyxOJT,"}/*!sc*/
.ioIxRn{background:#1F1F1F;padding:38px 0 25px;color:#fff;}/*!sc*/
data-styled.g3[id="sc-3419d6b6-0"]{content:"ioIxRn,"}/*!sc*/
.iYFXoP{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-column-gap:80px;column-gap:80px;row-gap:40px;margin-bottom:40px;}/*!sc*/
@media (max-width:720px){.iYFXoP{display:grid;grid-template-columns:1fr 1fr;-webkit-column-gap:20px;column-gap:20px;}}/*!sc*/
.iYFXoP h3{font-size:16px;font-weight:600;margin-bottom:12px;}/*!sc*/
.iYFXoP li + li{margin-top:12px;}/*!sc*/
data-styled.g4[id="sc-3419d6b6-1"]{content:"iYFXoP,"}/*!sc*/
.eWdALT{display:none;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:44px;height:34px;padding:6px;border-radius:5px;border:none;background:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);cursor:pointer;margin-left:auto;}/*!sc*/
@media (max-width:920px){.eWdALT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.eWdALT div{width:22px;height:2px;background:#fff;-webkit-transform-origin:1px;-ms-transform-origin:1px;transform-origin:1px;-webkit-transition:all 0.3s linear;transition:all 0.3s linear;}/*!sc*/
data-styled.g5[id="sc-46d6b9d9-0"]{content:"eWdALT,"}/*!sc*/
.jTcDmc{-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;overflow:hidden;position:absolute;white-space:nowrap;width:1px;}/*!sc*/
data-styled.g6[id="sc-cdea7863-0"]{content:"jTcDmc,"}/*!sc*/
.dAXQuQ{z-index:100;height:80px;background:#fff;box-shadow:0px 4px 10px 4px rgba(0,0,0,0.04);}/*!sc*/
data-styled.g7[id="sc-a026f25c-0"]{content:"dAXQuQ,"}/*!sc*/
.gUFsBX{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;}/*!sc*/
.gUFsBX .img-logo{width:115px;}/*!sc*/
data-styled.g8[id="sc-a026f25c-1"]{content:"gUFsBX,"}/*!sc*/
.bcvGIl{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.bcvGIl{display:block;position:absolute;top:80px;left:0;width:100%;z-index:1;padding:0 30px 30px;background-color:#fff;opacity:0;z-index:-9999;pointer-events:none;-webkit-transition:opacity 0.3s ease;transition:opacity 0.3s ease;box-shadow:0 4px 10px -1px rgba(0,0,0,0.04);}}/*!sc*/
@media (max-width:720px){.bcvGIl{padding:0 15px 15px;}}/*!sc*/
data-styled.g9[id="sc-a026f25c-2"]{content:"bcvGIl,"}/*!sc*/
.jjIqRA{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.jjIqRA{display:block;margin-bottom:15px;}}/*!sc*/
.jjIqRA li + li{margin-left:26px;}/*!sc*/
@media (max-width:920px){.jjIqRA li + li{margin-left:0;}}/*!sc*/
.jjIqRA a{display:inline-block;font-size:1.25rem;line-height:1;color:#000000;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color 0.3s;transition:color 0.3s;}/*!sc*/
.jjIqRA a:hover{color:#FE7A00;}/*!sc*/
@media (max-width:920px){.jjIqRA a{padding:8px 0;}}/*!sc*/
data-styled.g10[id="sc-a026f25c-3"]{content:"jjIqRA,"}/*!sc*/
.eLPewT{position:relative;width:142px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;margin-left:26px;}/*!sc*/
@media (max-width:920px){.eLPewT{width:auto;margin-left:0;}}/*!sc*/
data-styled.g11[id="sc-a026f25c-4"]{content:"eLPewT,"}/*!sc*/
.ipGgXV{display:inline-block;position:absolute;top:0;right:42px;width:calc(100% - 42px);height:100%;font-size:16px;line-height:1.25;padding:10px 13px;background:#fff;border-radius:5px 0px 0px 5px;border:1px solid #D9D9D9;border-right:none;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;}/*!sc*/
@media (max-width:920px){.ipGgXV{display:none;}}/*!sc*/
.ipGgXV::-webkit-input-placeholder{color:#D9D9D9;}/*!sc*/
.ipGgXV::-moz-placeholder{color:#D9D9D9;}/*!sc*/
.ipGgXV:-ms-input-placeholder{color:#D9D9D9;}/*!sc*/
.ipGgXV::placeholder{color:#D9D9D9;}/*!sc*/
data-styled.g12[id="sc-a026f25c-5"]{content:"ipGgXV,"}/*!sc*/
.iFVURz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;color:#fff;margin-left:auto;-webkit-flex:0 0 42px;-ms-flex:0 0 42px;flex:0 0 42px;height:41px;border:1px solid #474747;border-radius:0px 5px 5px 0px;background-color:#474747;}/*!sc*/
@media (max-width:920px){.iFVURz{margin-left:0;}}/*!sc*/
data-styled.g13[id="sc-a026f25c-6"]{content:"iFVURz,"}/*!sc*/
.kOMJoa{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:12px;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}/*!sc*/
data-styled.g18[id="sc-7e1621ad-0"]{content:"kOMJoa,"}/*!sc*/
.kkwPib{position:fixed;bottom:20px;right:20px;padding:20px;z-index:999;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background:#1F1F1F;color:#fff;border-radius:5px;border:1px solid #D9D9D9;box-shadow:0px 6px 20px 0px rgba(0,0,0,0.06);-webkit-transform:translateY(calc(100% + 100px));-ms-transform:translateY(calc(100% + 100px));transform:translateY(calc(100% + 100px));-webkit-transition:-webkit-transform 0.5s ease-in-out;-webkit-transition:transform 0.5s ease-in-out;transition:transform 0.5s ease-in-out;}/*!sc*/
@media (max-width:720px){.kkwPib{left:10px;right:10px;bottom:10px;}}/*!sc*/
.kkwPib p{margin-bottom:11px;font-size:17px;}/*!sc*/
data-styled.g19[id="sc-7e1621ad-1"]{content:"kkwPib,"}/*!sc*/
.fkWelF{font-size:15px;padding:9px 12px;border-radius:8px;cursor:pointer;background:#1F1F1F;color:#fff;border:1px solid #fff;}/*!sc*/
.dsztgy{font-size:15px;padding:9px 12px;border-radius:8px;cursor:pointer;background:#fff;color:#1F1F1F;border:1px solid #fff;padding-left:22px;padding-right:22px;}/*!sc*/
data-styled.g20[id="sc-7e1621ad-2"]{content:"fkWelF,dsztgy,"}/*!sc*/
.eWBvvS{min-height:100vh;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
data-styled.g21[id="sc-b34fb00f-0"]{content:"eWBvvS,"}/*!sc*/
*,*:before,*:after{box-sizing:border-box;-webkit-font-smoothing:antialiased;}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
html{font-family:'Source Sans Pro',sans-serif;font-weight:400;color:#000000;}/*!sc*/
body{background:#fff;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
main{-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
figure{margin:0;}/*!sc*/
img,video{display:block;max-width:100%;height:auto;}/*!sc*/
a{color:unset;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
a:hover{color:unset;}/*!sc*/
strong{font-weight:600;}/*!sc*/
pre{display:block;padding:15px;margin:0 0 10px;font-size:14px;word-break:break-all;word-wrap:break-word;color:#000;border:1px solid #ebebeb;border-radius:5px;overflow-x:auto;word-wrap:normal;}/*!sc*/
pre code{padding:0 !important;font-size:inherit;color:inherit;white-space:pre-wrap;background-color:transparent;border-radius:0;border:none;line-height:1.35;}/*!sc*/
code{padding:2px 3px;background:#f7f7f7;border:1px solid #ededed;border-radius:0.375rem;display:inline-block;line-height:1.2;margin:0;font-size:78%;}/*!sc*/
::selection{background-color:#FE7A00;color:#fff;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
pre code.hljs{display:block;overflow-x:auto;padding:1em;}/*!sc*/
code.hljs{padding:3px 5px;}/*!sc*/
.hljs{color:#24292e;background:#fff;}/*!sc*/
.hljs-doctag,.hljs-keyword,.hljs-meta .hljs-keyword,.hljs-template-tag,.hljs-template-variable,.hljs-type,.hljs-variable.language_{color:#d73a49;}/*!sc*/
.hljs-title,.hljs-title.class_,.hljs-title.class_.inherited__,.hljs-title.function_{color:#6f42c1;}/*!sc*/
.hljs-attr,.hljs-attribute,.hljs-literal,.hljs-meta,.hljs-number,.hljs-operator,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-variable{color:#005cc5;}/*!sc*/
.hljs-meta .hljs-string,.hljs-regexp,.hljs-string{color:#032f62;}/*!sc*/
.hljs-built_in,.hljs-symbol{color:#e36209;}/*!sc*/
.hljs-code,.hljs-comment,.hljs-formula{color:#6a737d;}/*!sc*/
.hljs-name,.hljs-quote,.hljs-selector-pseudo,.hljs-selector-tag{color:#22863a;}/*!sc*/
.hljs-subst{color:#24292e;}/*!sc*/
.hljs-section{color:#005cc5;font-weight:700;}/*!sc*/
.hljs-bullet{color:#735c0f;}/*!sc*/
.hljs-emphasis{color:#24292e;font-style:italic;}/*!sc*/
.hljs-strong{color:#24292e;font-weight:700;}/*!sc*/
.hljs-addition{color:#22863a;background-color:#f0fff4;}/*!sc*/
.hljs-deletion{color:#b31d28;background-color:#ffeef0;}/*!sc*/
data-styled.g22[id="sc-global-ehweHW1"]{content:"sc-global-ehweHW1,"}/*!sc*/
.dpPsin h1{font-size:44px;line-height:1.13;font-weight:700;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.dpPsin h1{font-size:38px;}}/*!sc*/
@media (max-width:720px){.dpPsin h1{font-size:32px;}}/*!sc*/
.dpPsin h2{font-size:33px;line-height:1.13;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.dpPsin h2{font-size:30px;}}/*!sc*/
@media (max-width:720px){.dpPsin h2{font-size:26px;}}/*!sc*/
.dpPsin h3{font-size:28px;line-height:1.18;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.dpPsin h3{font-size:26px;}}/*!sc*/
@media (max-width:720px){.dpPsin h3{font-size:24px;}}/*!sc*/
.dpPsin h4{font-size:22px;line-height:1.18;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:720px){.dpPsin h4{font-size:20px;}}/*!sc*/
.dpPsin p{font-size:20px;line-height:1.4;color:#1F1F1F;}/*!sc*/
@media (max-width:1130px){.dpPsin p{font-size:20px;}}/*!sc*/
@media (max-width:920px){.dpPsin p{font-size:18px;}}/*!sc*/
.dpPsin ul,.dpPsin ol{padding-left:40px;}/*!sc*/
.dpPsin ul li,.dpPsin ol li{font-size:20px;line-height:1.4;color:#1F1F1F;}/*!sc*/
@media (max-width:1130px){.dpPsin ul li,.dpPsin ol li{font-size:20px;}}/*!sc*/
@media (max-width:920px){.dpPsin ul li,.dpPsin ol li{font-size:18px;}}/*!sc*/
.dpPsin ul li + li,.dpPsin ol li + li{margin-top:4px;}/*!sc*/
.dpPsin ul{list-style:disc;}/*!sc*/
.dpPsin ol{list-style:decimal;}/*!sc*/
.dpPsin p a,.dpPsin li a{color:#FE7A00;}/*!sc*/
.dpPsin p a:hover,.dpPsin li a:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.dpPsin * + *:not(li,a,code){margin-top:20px;}/*!sc*/
.dpPsin * + a[data-gallery],.dpPsin * + video{margin-top:40px;}/*!sc*/
.dpPsin a[data-gallery]{display:block;margin-bottom:40px;}/*!sc*/
.dpPsin iframe,.dpPsin video{margin-bottom:40px;}/*!sc*/
data-styled.g47[id="sc-8f0614a2-0"]{content:"dpPsin,"}/*!sc*/
.cHIhER{display:block;margin-left:auto;margin-right:auto;}/*!sc*/
data-styled.g48[id="sc-8f0614a2-1"]{content:"cHIhER,"}/*!sc*/
.loxVcf{font-size:62px;line-height:1.04;font-weight:700;color:#fff;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.loxVcf{font-size:50px;}}/*!sc*/
@media (max-width:720px){.loxVcf{font-size:42px;}}/*!sc*/
data-styled.g56[id="sc-c67a4900-0"]{content:"loxVcf,"}/*!sc*/
.cyZFCR{padding:80px 0;}/*!sc*/
@media (max-width:920px){.cyZFCR{padding:60px 0;}}/*!sc*/
@media (max-width:720px){.cyZFCR{padding:40px 0;}}/*!sc*/
data-styled.g85[id="sc-b9a2839b-0"]{content:"cyZFCR,"}/*!sc*/
.cIBHvM{margin-bottom:30px;}/*!sc*/
data-styled.g86[id="sc-b9a2839b-1"]{content:"cIBHvM,"}/*!sc*/
.kBOXgB{position:relative;}/*!sc*/
data-styled.g87[id="sc-b9a2839b-2"]{content:"kBOXgB,"}/*!sc*/
.fMPIzd{position:absolute;top:0;right:100%;width:200px;margin-right:50px;text-align:right;}/*!sc*/
@media (max-width:1130px){.fMPIzd{position:unset;width:auto;text-align:left;margin:0 0 30px 0;}}/*!sc*/
data-styled.g88[id="sc-b9a2839b-3"]{content:"fMPIzd,"}/*!sc*/
.cdlBoX{font-size:20px;line-height:1.25;color:#1F1F1F;text-transform:capitalize;color:#5651EC;}/*!sc*/
@media (max-width:920px){.cdlBoX{font-size:18px;}}/*!sc*/
.ehbERY{font-size:20px;line-height:1.25;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.ehbERY{font-size:18px;}}/*!sc*/
data-styled.g89[id="sc-b9a2839b-4"]{content:"cdlBoX,ehbERY,"}/*!sc*/
</style></head><body><div id="__next"><div class="sc-b34fb00f-0 eWBvvS __className_87c83e"><nav class="sc-a026f25c-0 dAXQuQ"><div class="sc-61db3aea-0 eVggRJ"><div class="sc-a026f25c-1 gUFsBX"><a href="/"><img alt="Orange Logo" loading="lazy" width="120" height="35" decoding="async" data-nimg="1" class="img-logo" style="color:transparent" src="/_next/static/media/logo-orange.faff1861.svg"/></a><div><button aria-label="Toggle navigation" class="sc-46d6b9d9-0 eWdALT"><div></div><div></div><div></div></button><div class="sc-a026f25c-2 bcvGIl"><ul class="sc-a026f25c-3 jjIqRA"><li><a href="/screenshots/">Screenshots</a></li><li><a href="/download/">Download</a></li><li><a href="/blog/">Blog</a></li><li><a href="/docs/">Docs</a></li><li><a href="/workshops/">Workshops</a></li><li><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=A76TAX87ZVR3J">Donate</a></li></ul><form class="sc-a026f25c-4 eLPewT"><div class="sc-a026f25c-5 ipGgXV">Search</div><button class="sc-a026f25c-6 iFVURz"><img alt="Icon for search" loading="lazy" width="18" height="17" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/icon-search.459b2665.svg"/><span class="sc-cdea7863-0 jTcDmc">Search through page</span></button></form></div></div></div></div></nav><main><div class="sc-b9a2839b-0 cyZFCR"><div class="sc-61db3aea-0 CVQuR"><div class="sc-b9a2839b-1 cIBHvM"><p class="sc-b9a2839b-4 cdlBoX"><strong>analysis, bioinformatics, Foundation Models</strong></p><h1 class="sc-c67a4900-0 loxVcf">Foundation models in Orange with just a few lines of code</h1></div><div class="sc-b9a2839b-2 kBOXgB"><div class="sc-b9a2839b-3 fMPIzd"><p class="sc-b9a2839b-4 ehbERY"><strong>Martin Å pendl</strong></p><p class="sc-b9a2839b-4 ehbERY">Jan 20, 2025</p></div><div class="sc-8f0614a2-0 dpPsin"><div class="lg-react-element "><p>Foundation models are becoming a necessary addition to our toolbox, especially in fields like biomedicine. A large community of researchers is developing these models, so you donât have to! Improved versions of models are uploaded almost by the minute on repositories like Hugging Face. The following blog/tutorial will show you how to use models from Hugging Face in Orange with just a bit of coding. Fear not; you will be only required to write a few lines in the Python Script widget, and you will unlock the full power of foundation models. Letâs begin!</p>
<h2>What Youâll Need</h2>
<p>Before we get started, make sure youâve got Orange installed on your computer. Youâll also need two Python packages: <strong>torch</strong> and <strong>transformers</strong>. To install these packages, open Orange, navigate to Options and select Add-ons. In the upper right corner, click <em>Add moreâ¦</em> and type torch. Once you can see the package in the list of add-ons, check the square and press OK on the bottom left corner of the window. This procedure will install the package torch  in your Orange application. Use the same procedure for the transformers package. You will only have to do this once. You can quickly check if your installation was successful by opening the Python Script widget, typing in the console: <em>import transformers</em>, and pressing Enter. If there is no error, the installation was successful.</p>
<a href="/blog/2025-01-bio-foundation-models/__optimized-images__/install-dep.png" data-gallery="true"><img alt="" loading="lazy" width="621" height="566" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2025-01-bio-foundation-models/__optimized-images__/install-dep.png"/></a>
<h2>A Biology Problem: Grouping Proteins by Their Structure</h2>
<p>Proteins are long chains of amino acids that fold into 3D structures, determining their function. These protein stuctures can vary from small and globular (Cathepsin K), highly structured (transmembrane beta barrel), to large and multimeric structures, for example Spike protein of SARS-CoV-2. Determining their structure was, until recently, a very tedious task and sometimes even nearly impossible. Nowadays, large foundation models can infer protein structure from just their amino acid sequence, and we will use one of those models in our analysis.</p>
<a href="/blog/2025-01-bio-foundation-models/__optimized-images__/spike_cathepsin_beta.png" data-gallery="true"><img alt="" loading="lazy" width="1132" height="795" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2025-01-bio-foundation-models/__optimized-images__/spike_cathepsin_beta.png"/></a>
<p>Our goal here is to group human proteins with similar structuresâwithout comparing their actual structure! Weâll turn protein sequences into numbers (embeddings) using the ESM-2 model from Hugging Face. These embeddings capture patterns hinting at structural similarities and are thus easier to compare than structures. Later, we will try to identify groups of proteins with similar structures.</p>
<h3>Step 1: Creating ESM-2 Embeddings</h3>
<p>We will work with a subset of 5000 human proteins downloaded from the <a href="https://www.uniprot.org/proteomes/UP000005640">UniProt</a>. You can download this <a href="/blog/2025-01-bio-foundation-models/human_proteins.csv">CSV file</a>, where we processed the downloaded FASTA file. We kept 5000 random proteins with sequence lengths between 100 and 1500 amino acids. The longer the sequence, the more computation resources the model will require. We can easily load this file into Orange with the File widget. The Data Table widget shows that aminoacid sequences are stored in the &quot;sequence&quot; column.</p>
<p>We will now use a protein foundation model from Meta called ESM-2. Visit the Hugging Face website to inspect the model. ESM-2 comes in different sizes, from 8M to 15B parameters. We will use the smallest version to save computation time, but feel free to upgrade the model. To find foundation models in general, you can search through Hugging Face. Copy the modelâs name on the top of the page (e.g., &quot;facebook/esm2_t6_8M_UR50D&quot;) and return to Orange.</p>
<p>Open a Python Script widget and copy the code below inside the python_script function. Letâs quickly go through what it does. First, it imports the necessary packages like <em>numpy</em> and <em>torch</em>. Then, we fetch sequences from our in_data, which is a DataTable on the input of the Python Script widget. The next three lines are where we define our foundation model, in our case, the &quot;facebook/esm2_t6_8M_UR50D&quot;. Tokenizer is used to transform our sequence into tokens, the language of the model. Lastly, we define the model itself with the EsmModel class. Note that if you use another foundation model (e.g., DNABert), you only need to change the variable âmodel_name.â In the following steps, we iterate through sequences, using the tokenizer and the model to extract the protein embedding on the output. The last for loop goes through protein embeddings and appends each column to our data table. Finally, we output the resulting table with protein embeddings as columns.</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># import necessary packages and classes</span>
<span class="hljs-comment"># Feel free to use ChatGPT to explain this code in furher detail</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> Orange.data <span class="hljs-keyword">import</span> ContinuousVariable
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

<span class="hljs-comment"># we extract the column sequences from our data table</span>
out_data = in_data.copy()
sequences = out_data.get_column(<span class="hljs-string">&quot;sequence&quot;</span>)

<span class="hljs-comment"># we define model_name, while AutoTokenizer and EsmModel download the foundation model</span>
model_name = <span class="hljs-string">&quot;facebook/esm2_t6_8M_UR50D&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

embeddings = []
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequences)):
    <span class="hljs-comment"># First, we have to transform each sequence into tokens</span>
    inputs = tokenizer(sequences[i], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
    
    <span class="hljs-keyword">with</span> torch.no_grad():
        <span class="hljs-comment"># Then, we calculate the embeddings of the sequence with ESM-2 model</span>
        outputs = model(**inputs)

    <span class="hljs-comment"># Importantly, we use .detach() to reduce the memory load</span>
    embeddings.append(outputs.last_hidden_state[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].detach().numpy())
embeddings = np.array(embeddings)

EMB_DIM = embeddings.shape[-<span class="hljs-number">1</span>]
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(EMB_DIM):
    <span class="hljs-comment"># Lastly, we append each column of embeddings to our data as a Continuous variable</span>
    out_data = out_data.add_column(ContinuousVariable(<span class="hljs-string">f&quot;ESM-emb-<span class="hljs-subst">{i}</span>&quot;</span>), embeddings[:, i])
</code></pre>
<p>NOTE: Executing this code might take a few minutes up to an hour depending on your computational resources!</p>
<a href="/blog/2025-01-bio-foundation-models/__optimized-images__/query-ESM-2.png" data-gallery="true"><img alt="" loading="lazy" width="1430" height="615" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2025-01-bio-foundation-models/__optimized-images__/query-ESM-2.png"/></a>
<p>Letâs inspect what does our table look like now. In addition to our protein data, there are 320 columns representing the embedding. These values do now have meaning on their own, but we will see how to extract some information out of them shortly. Since the computation of embeddings took quite a few time, letâs store the data first, before doing any further analysis.</p>
<h3>Step 2: Visualizing Embeddings with t-SNE</h3>
<p>Now that we have the embeddings, letâs make sense of them visually. Using a t-SNE plot, weâll turn these high-dimensional numbers into a simple 2D scatter plot. This makes it easy to spot clusters of proteins with similar structures. Even proteins without known structures can find their place in these clusters, helping us discover hidden relationships between them. If you want to inspect any of these groups, select them on the plot while holding the Shift key. We can inspect proteins in each group in the DataTable and change their group label to something more meaningful. Lastly, we can see different groups of proteins with respect to their structures, eventhough we did not have to compare any structures at all. Isnât that amazing.</p>
<a href="/blog/2025-01-bio-foundation-models/__optimized-images__/analyse-ESM-2-embeddings.png" data-gallery="true"><img alt="" loading="lazy" width="1354" height="912" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2025-01-bio-foundation-models/__optimized-images__/analyse-ESM-2-embeddings.png"/></a>
<h2>Wrapping Up</h2>
<p>Foundation models paired with tools like Orange open up a world of possibilities on how to analyze complex data. This post is meant to introduce you to how we can use Hugging Face foundation models using a Python Script widget. It might seem a bit involved at first, but with a bit of help from ChatGPT, you can be using the latest cutting edge foundation models in no time.</p></div></div></div></div></div></main><footer class="sc-3419d6b6-0 ioIxRn"><div class="sc-61db3aea-0 eVggRJ"><div class="sc-3419d6b6-1 iYFXoP"><div><h3>Orange</h3><ul><li><a href="/faq/">FAQ</a></li><li><a href="/license/">License</a></li><li><a href="/privacy/">Privacy</a></li><li><a href="/citation/">Citation</a></li><li><a href="/contact/">Contact</a></li></ul></div><div><h3><a href="/download/">Download</a></h3><ul><li><a href="/download/#win">Windows</a></li><li><a href="/download/#mac">Mac OS</a></li><li><a href="/download/#other">Other platforms</a></li></ul></div><div><h3>Community</h3><ul><li><a href="https://twitter.com/OrangeDataMiner">Twitter</a></li><li><a href="https://www.facebook.com/orangedatamining">Facebook</a></li><li><a href="https://datascience.stackexchange.com/questions/tagged/orange">Stack Exchange</a></li><li><a href="https://www.youtube.com/channel/UClKKWBe2SCAEyv7ZNGhIe4g">YouTube</a></li><li><a href="https://discord.com/invite/FWrfeXV">Discord</a></li></ul></div><div><h3><a href="/docs/">Documentation</a></h3><ul><li><a href="/getting-started/">Get started</a></li><li><a href="https://www.youtube.com/channel/UClKKWBe2SCAEyv7ZNGhIe4g">YouTube tutorials</a></li><li><a href="/examples/">Example workflows</a></li><li><a href="/widget-catalog/">Widgets</a></li><li><a href="https://orange3.readthedocs.io/projects/orange-data-mining-library/en/latest/">Scripting</a></li></ul></div><div><h3>Developers</h3><ul><li><a href="https://github.com/biolab/orange3">GitHub</a></li><li><a href="http://docs.biolab.si/3/development/">Getting started</a></li></ul></div><div><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=A76TAX87ZVR3J" target="_blank" rel="noreferrer" class="sc-b6ea565a-0 jyxOJT">Donate to Orange</a></div></div><p>Copyright Â© University of Ljubljana</p></div></footer><div class="sc-7e1621ad-1 kkwPib"><div><p>This site uses cookies to improve your experience.</p><div class="sc-7e1621ad-0 kOMJoa"><button class="sc-7e1621ad-2 fkWelF">Details</button><button class="sc-7e1621ad-2 dsztgy">Understand</button></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"frontmatter":{"author":"Martin Å pendl","date":"2025-01-20","draft":false,"title":"Foundation models in Orange with just a few lines of code","thumbImage":"ESM2-thumb.png","frontPageImage":"ESM2-thumb.png","blog":["analysis","bioinformatics","Foundation Models"],"shortExcerpt":"Foundation models can be used in Orange in just a few lines of code. Python Script can unlock every model from Hugging Face if you are brave enough.","longExcerpt":"Hugging Face foundation models can be used in Orange. With a few lines of code in the Python Script widget, you can download and run any model from the Hugging Face repository and unlock new levels of analysis in your Workflows."},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    h2: \"h2\",\n    strong: \"strong\",\n    em: \"em\",\n    h3: \"h3\",\n    a: \"a\",\n    pre: \"pre\",\n    code: \"code\",\n    span: \"span\"\n  }, _provideComponents(), props.components), {WindowScreenshot} = _components;\n  if (!WindowScreenshot) _missingMdxReference(\"WindowScreenshot\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Foundation models are becoming a necessary addition to our toolbox, especially in fields like biomedicine. A large community of researchers is developing these models, so you donât have to! Improved versions of models are uploaded almost by the minute on repositories like Hugging Face. The following blog/tutorial will show you how to use models from Hugging Face in Orange with just a bit of coding. Fear not; you will be only required to write a few lines in the Python Script widget, and you will unlock the full power of foundation models. Letâs begin!\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"What Youâll Need\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Before we get started, make sure youâve got Orange installed on your computer. Youâll also need two Python packages: \", _jsx(_components.strong, {\n        children: \"torch\"\n      }), \" and \", _jsx(_components.strong, {\n        children: \"transformers\"\n      }), \". To install these packages, open Orange, navigate to Options and select Add-ons. In the upper right corner, click \", _jsx(_components.em, {\n        children: \"Add moreâ¦\"\n      }), \" and type torch. Once you can see the package in the list of add-ons, check the square and press OK on the bottom left corner of the window. This procedure will install the package torch  in your Orange application. Use the same procedure for the transformers package. You will only have to do this once. You can quickly check if your installation was successful by opening the Python Script widget, typing in the console: \", _jsx(_components.em, {\n        children: \"import transformers\"\n      }), \", and pressing Enter. If there is no error, the installation was successful.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2025-01-bio-foundation-models/install-dep.png\",\n      width: \"621\",\n      height: \"566\",\n      src: \"/blog/2025-01-bio-foundation-models/__optimized-images__/install-dep.png\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"A Biology Problem: Grouping Proteins by Their Structure\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Proteins are long chains of amino acids that fold into 3D structures, determining their function. These protein stuctures can vary from small and globular (Cathepsin K), highly structured (transmembrane beta barrel), to large and multimeric structures, for example Spike protein of SARS-CoV-2. Determining their structure was, until recently, a very tedious task and sometimes even nearly impossible. Nowadays, large foundation models can infer protein structure from just their amino acid sequence, and we will use one of those models in our analysis.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2025-01-bio-foundation-models/spike_cathepsin_beta.png\",\n      width: \"1132\",\n      height: \"795\",\n      src: \"/blog/2025-01-bio-foundation-models/__optimized-images__/spike_cathepsin_beta.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Our goal here is to group human proteins with similar structuresâwithout comparing their actual structure! Weâll turn protein sequences into numbers (embeddings) using the ESM-2 model from Hugging Face. These embeddings capture patterns hinting at structural similarities and are thus easier to compare than structures. Later, we will try to identify groups of proteins with similar structures.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Step 1: Creating ESM-2 Embeddings\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We will work with a subset of 5000 human proteins downloaded from the \", _jsx(_components.a, {\n        href: \"https://www.uniprot.org/proteomes/UP000005640\",\n        children: \"UniProt\"\n      }), \". You can download this \", _jsx(_components.a, {\n        href: \"/blog/2025-01-bio-foundation-models/human_proteins.csv\",\n        children: \"CSV file\"\n      }), \", where we processed the downloaded FASTA file. We kept 5000 random proteins with sequence lengths between 100 and 1500 amino acids. The longer the sequence, the more computation resources the model will require. We can easily load this file into Orange with the File widget. The Data Table widget shows that aminoacid sequences are stored in the \\\"sequence\\\" column.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We will now use a protein foundation model from Meta called ESM-2. Visit the Hugging Face website to inspect the model. ESM-2 comes in different sizes, from 8M to 15B parameters. We will use the smallest version to save computation time, but feel free to upgrade the model. To find foundation models in general, you can search through Hugging Face. Copy the modelâs name on the top of the page (e.g., \\\"facebook/esm2_t6_8M_UR50D\\\") and return to Orange.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Open a Python Script widget and copy the code below inside the python_script function. Letâs quickly go through what it does. First, it imports the necessary packages like \", _jsx(_components.em, {\n        children: \"numpy\"\n      }), \" and \", _jsx(_components.em, {\n        children: \"torch\"\n      }), \". Then, we fetch sequences from our in_data, which is a DataTable on the input of the Python Script widget. The next three lines are where we define our foundation model, in our case, the \\\"facebook/esm2_t6_8M_UR50D\\\". Tokenizer is used to transform our sequence into tokens, the language of the model. Lastly, we define the model itself with the EsmModel class. Note that if you use another foundation model (e.g., DNABert), you only need to change the variable âmodel_name.â In the following steps, we iterate through sequences, using the tokenizer and the model to extract the protein embedding on the output. The last for loop goes through protein embeddings and appends each column to our data table. Finally, we output the resulting table with protein embeddings as columns.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-python\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# import necessary packages and classes\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Feel free to use ChatGPT to explain this code in furher detail\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" numpy \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"as\"\n        }), \" np\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" torch\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" Orange.data \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" ContinuousVariable\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" transformers \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" AutoTokenizer, AutoModel\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# we extract the column sequences from our data table\"\n        }), \"\\nout_data = in_data.copy()\\nsequences = out_data.get_column(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"sequence\\\"\"\n        }), \")\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# we define model_name, while AutoTokenizer and EsmModel download the foundation model\"\n        }), \"\\nmodel_name = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"facebook/esm2_t6_8M_UR50D\\\"\"\n        }), \"\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\nmodel = AutoModel.from_pretrained(model_name)\\n\\nembeddings = []\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"for\"\n        }), \" i \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"in\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"range\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"len\"\n        }), \"(sequences)):\\n    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# First, we have to transform each sequence into tokens\"\n        }), \"\\n    inputs = tokenizer(sequences[i], return_tensors=\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"pt\\\"\"\n        }), \")\\n    \\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"with\"\n        }), \" torch.no_grad():\\n        \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Then, we calculate the embeddings of the sequence with ESM-2 model\"\n        }), \"\\n        outputs = model(**inputs)\\n\\n    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Importantly, we use .detach() to reduce the memory load\"\n        }), \"\\n    embeddings.append(outputs.last_hidden_state[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"][\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"].detach().numpy())\\nembeddings = np.array(embeddings)\\n\\nEMB_DIM = embeddings.shape[-\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1\"\n        }), \"]\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"for\"\n        }), \" i \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"in\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"range\"\n        }), \"(EMB_DIM):\\n    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Lastly, we append each column of embeddings to our data as a Continuous variable\"\n        }), \"\\n    out_data = out_data.add_column(ContinuousVariable(\", _jsxs(_components.span, {\n          className: \"hljs-string\",\n          children: [\"f\\\"ESM-emb-\", _jsx(_components.span, {\n            className: \"hljs-subst\",\n            children: \"{i}\"\n          }), \"\\\"\"]\n        }), \"), embeddings[:, i])\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"NOTE: Executing this code might take a few minutes up to an hour depending on your computational resources!\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2025-01-bio-foundation-models/query-ESM-2.png\",\n      width: \"1430\",\n      height: \"615\",\n      src: \"/blog/2025-01-bio-foundation-models/__optimized-images__/query-ESM-2.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Letâs inspect what does our table look like now. In addition to our protein data, there are 320 columns representing the embedding. These values do now have meaning on their own, but we will see how to extract some information out of them shortly. Since the computation of embeddings took quite a few time, letâs store the data first, before doing any further analysis.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Step 2: Visualizing Embeddings with t-SNE\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now that we have the embeddings, letâs make sense of them visually. Using a t-SNE plot, weâll turn these high-dimensional numbers into a simple 2D scatter plot. This makes it easy to spot clusters of proteins with similar structures. Even proteins without known structures can find their place in these clusters, helping us discover hidden relationships between them. If you want to inspect any of these groups, select them on the plot while holding the Shift key. We can inspect proteins in each group in the DataTable and change their group label to something more meaningful. Lastly, we can see different groups of proteins with respect to their structures, eventhough we did not have to compare any structures at all. Isnât that amazing.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2025-01-bio-foundation-models/analyse-ESM-2-embeddings.png\",\n      width: \"1354\",\n      height: \"912\",\n      src: \"/blog/2025-01-bio-foundation-models/__optimized-images__/analyse-ESM-2-embeddings.png\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Wrapping Up\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Foundation models paired with tools like Orange open up a world of possibilities on how to analyze complex data. This post is meant to introduce you to how we can use Hugging Face foundation models using a Python Script widget. It might seem a bit involved at first, but with a bit of help from ChatGPT, you can be using the latest cutting edge foundation models in no time.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}},"thumbImage":{"width":804,"height":443,"src":"/blog/2025-01-bio-foundation-models/__optimized-images__/ESM2-thumb.png"}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"foundation-models-in-orange-with-just-a-few-lines-of-code"},"buildId":"jeVGYe9O_-swSp6tsvUw6","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>