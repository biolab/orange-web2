<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-9f90a364d66949ce.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8cfbd06f8ddd0b49.js" defer=""></script><script src="/_next/static/chunks/675-262430aa11afdf01.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-ba4a3f289f8ef3c5.js" defer=""></script><script src="/_next/static/GAVvi42gDEHMzYTCLyMnv/_buildManifest.js" defer=""></script><script src="/_next/static/GAVvi42gDEHMzYTCLyMnv/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.iBQlkL{background:coral;height:60px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.iBQlkL ul{display:none;}}/*!sc*/
data-styled.g1[id="sc-7295e4c-0"]{content:"iBQlkL,"}/*!sc*/
.bDMZDz{display:none;font-size:22px;margin-left:auto;}/*!sc*/
@media (max-width:920px){.bDMZDz{display:block;}}/*!sc*/
data-styled.g2[id="sc-7295e4c-1"]{content:"bDMZDz,"}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
body{background:#fff;}/*!sc*/
html{box-sizing:border-box;font-size:16px;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
img,video{max-width:100%;height:auto;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g3[id="sc-global-cqyaiF1"]{content:"sc-global-cqyaiF1,"}/*!sc*/
.cGDPDa{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g6[id="sc-f0e62130-0"]{content:"cGDPDa,"}/*!sc*/
</style></head><body><div id="__next"><nav class="sc-7295e4c-0 iBQlkL"><ul><a href="/blog">Blog</a></ul><button class="sc-7295e4c-1 bDMZDz">X</button></nav><main><div class="sc-f0e62130-0 cGDPDa"><h1>Visualizing Misclassifications</h1><div class="lg-react-element "><p>In data mining <strong><a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a></strong> is one of the key methods for making predictions and gaining important information from our data. We would, for example, use classification for predicting which patients are likely to have the disease based on a given set of symptoms.</p>
<p>In Orange an easy way to classify your data is to select several <strong>classification widgets</strong> (e.g. Naive Bayes, Classification Tree and Linear Regression), compare the prediction quality of each learner with <strong>Test Learners</strong> and <strong>Confusion Matrix</strong> and then use the best performing classifier on a new data set for classification. Below we use Iris data set for simplicity, but the same procedure works just as well on all kinds of data sets.</p>
<p>Here we have three confusion matrices for <strong><a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive Bayes</a></strong> (top), <strong><a href="https://en.wikipedia.org/wiki/Decision_tree_learning">Classification Tree</a></strong> (middle) and <strong><a href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression">Logistic Regression</a></strong> (bottom).</p>
<a href="/blog/2015-07-visualizing-misclassifications/__webp-images__/Misclassification-matrices.webp" data-gallery="true"><img alt="" srcSet="/blog/2015-07-visualizing-misclassifications/__webp-images__/Misclassification-matrices.webp 1x, /blog/2015-07-visualizing-misclassifications/__webp-images__/Misclassification-matrices.webp 2x" src="/blog/2015-07-visualizing-misclassifications/__webp-images__/Misclassification-matrices.webp" width="1200" height="960" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>Three misclassification matrices (Naive Bayes, Classification Tree and Logistic Regression)</p>
<p>We see that <strong>Classification Tree</strong> did the best with only 9 misclassified instances. To see which instances were assigned a false class, we select ‘<em>Misclassified</em>’ option in the widget, which highlights misclassifications and feeds them to the <strong>Scatter Plot</strong> widget. In the graph we thus see the entire data set presented with empty dots and the selected misclassifications with full dots.</p>
<a href="/blog/2015-07-visualizing-misclassifications/__webp-images__/misclassification-schema-scatterplot.webp" data-gallery="true"><img alt="" srcSet="/blog/2015-07-visualizing-misclassifications/__webp-images__/misclassification-schema-scatterplot.webp 1x, /blog/2015-07-visualizing-misclassifications/__webp-images__/misclassification-schema-scatterplot.webp 2x" src="/blog/2015-07-visualizing-misclassifications/__webp-images__/misclassification-schema-scatterplot.webp" width="1200" height="960" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>Visualization of misclassified instances in scatter plot.</p>
<p>Feel free to switch between learners in <strong>Confusion Matrix</strong> to see how the visualization changes for each of them.</p></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"AJDA","date":"2015-07-24 08:03:40+00:00","draft":false,"title":"Visualizing Misclassifications","type":"blog","blog":["analysis","classification","visualization"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    strong: \"strong\",\n    a: \"a\",\n    img: \"img\",\n    em: \"em\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"In data mining \", _jsx(_components.strong, {\n        children: _jsx(_components.a, {\n          href: \"https://en.wikipedia.org/wiki/Statistical_classification\",\n          children: \"classification\"\n        })\n      }), \" is one of the key methods for making predictions and gaining important information from our data. We would, for example, use classification for predicting which patients are likely to have the disease based on a given set of symptoms.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In Orange an easy way to classify your data is to select several \", _jsx(_components.strong, {\n        children: \"classification widgets\"\n      }), \" (e.g. Naive Bayes, Classification Tree and Linear Regression), compare the prediction quality of each learner with \", _jsx(_components.strong, {\n        children: \"Test Learners\"\n      }), \" and \", _jsx(_components.strong, {\n        children: \"Confusion Matrix\"\n      }), \" and then use the best performing classifier on a new data set for classification. Below we use Iris data set for simplicity, but the same procedure works just as well on all kinds of data sets.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Here we have three confusion matrices for \", _jsx(_components.strong, {\n        children: _jsx(_components.a, {\n          href: \"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\",\n          children: \"Naive Bayes\"\n        })\n      }), \" (top), \", _jsx(_components.strong, {\n        children: _jsx(_components.a, {\n          href: \"https://en.wikipedia.org/wiki/Decision_tree_learning\",\n          children: \"Classification Tree\"\n        })\n      }), \" (middle) and \", _jsx(_components.strong, {\n        children: _jsx(_components.a, {\n          href: \"https://en.wikipedia.org/wiki/Multinomial_logistic_regression\",\n          children: \"Logistic Regression\"\n        })\n      }), \" (bottom).\"]\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2015-07-visualizing-misclassifications/__webp-images__/Misclassification-matrices.webp\",\n      alt: \"\",\n      width: \"1200\",\n      height: \"960\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Three misclassification matrices (Naive Bayes, Classification Tree and Logistic Regression)\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We see that \", _jsx(_components.strong, {\n        children: \"Classification Tree\"\n      }), \" did the best with only 9 misclassified instances. To see which instances were assigned a false class, we select ‘\", _jsx(_components.em, {\n        children: \"Misclassified\"\n      }), \"’ option in the widget, which highlights misclassifications and feeds them to the \", _jsx(_components.strong, {\n        children: \"Scatter Plot\"\n      }), \" widget. In the graph we thus see the entire data set presented with empty dots and the selected misclassifications with full dots.\"]\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2015-07-visualizing-misclassifications/__webp-images__/misclassification-schema-scatterplot.webp\",\n      alt: \"\",\n      width: \"1200\",\n      height: \"960\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Visualization of misclassified instances in scatter plot.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Feel free to switch between learners in \", _jsx(_components.strong, {\n        children: \"Confusion Matrix\"\n      }), \" to see how the visualization changes for each of them.\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"visualizing-misclassifications"},"buildId":"GAVvi42gDEHMzYTCLyMnv","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>