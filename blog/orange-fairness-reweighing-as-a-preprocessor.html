<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="description" content="Orange Data Mining Toolbox"/><meta property="og:url" content="https://orangedatamining.com"/><meta property="og:site_name" content="Orange Data Mining"/><meta name="author" content="Bioinformatics Laboratory, University of Ljubljana"/><title>Orange Data Mining - Orange Fairness - Reweighing as a preprocessor</title><meta name="robots" content="index,follow"/><meta property="og:title" content="Orange Data Mining - Orange Fairness - Reweighing as a preprocessor"/><meta property="og:description" content="Expanding on the Orange fairness Reweighing widget: using it as a preprocessor and integrating new fairness scoring metrics."/><meta property="og:type" content="article"/><meta property="article:published_time" content="2023-09-19 04:00:00+00:00"/><meta property="article:author" content="Žan Mervič"/><meta property="article:tag" content="fairness"/><meta property="article:tag" content="reweighing"/><meta property="og:image" content="/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-thumb.webp"/><meta property="og:image:width" content="856"/><meta property="og:image:height" content="500"/><meta name="next-head-count" content="18"/><link rel="preload" href="/_next/static/media/e7c7dbb62ddcf6fa-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/148a6a0ea3cd708f.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/148a6a0ea3cd708f.css" crossorigin="" data-n-g=""/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" crossorigin="" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-21c828b96ad33382.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-0c7baedefba6b077.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-ab94bcaa7cae018a.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-a1f2d6ce25f37533.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/110-f463c991b9377c97.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-9f1e5219ad36b56a.js" defer="" crossorigin=""></script><script src="/_next/static/YG6HGRTcm1VQoDRdUZteU/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/YG6HGRTcm1VQoDRdUZteU/_ssgManifest.js" defer="" crossorigin=""></script><style data-styled="" data-styled-version="5.3.6">.iSNtvJ{position:relative;max-width:1296px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;box-sizing:content-box;}/*!sc*/
@media (max-width:1130px){.iSNtvJ{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.iSNtvJ{padding-left:15px;padding-right:15px;}}/*!sc*/
.fJLXpS{position:relative;max-width:1296px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;box-sizing:content-box;max-width:714px;}/*!sc*/
@media (max-width:1130px){.fJLXpS{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.fJLXpS{padding-left:15px;padding-right:15px;}}/*!sc*/
data-styled.g1[id="sc-ef15f394-0"]{content:"iSNtvJ,fJLXpS,"}/*!sc*/
.jyxOJT{position:relative;display:inline-block;max-width:100%;font-size:20px;line-height:1.25;font-weight:600;-webkit-text-decoration:none;text-decoration:none;color:#fff;padding:10px 15px;border-radius:5px;background-image:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);background-size:100%;cursor:pointer;z-index:2;}/*!sc*/
@media (max-width:720px){.jyxOJT{font-size:18px;}}/*!sc*/
.jyxOJT:before{content:"";display:block;position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;background-image:linear-gradient(180deg,#ffbc44 100%,#FE7A00 100%);opacity:0;z-index:-100;-webkit-transition:opacity 0.45s;transition:opacity 0.45s;}/*!sc*/
.jyxOJT:hover{color:#fff;}/*!sc*/
.jyxOJT:hover:before{opacity:1;}/*!sc*/
data-styled.g2[id="sc-b6ea565a-0"]{content:"jyxOJT,"}/*!sc*/
.iQtqNS{background:#1F1F1F;padding:38px 0 25px;color:#fff;}/*!sc*/
data-styled.g3[id="sc-c82ca4e2-0"]{content:"iQtqNS,"}/*!sc*/
.iiCJUO{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-column-gap:80px;column-gap:80px;row-gap:40px;margin-bottom:40px;}/*!sc*/
@media (max-width:720px){.iiCJUO{display:grid;grid-template-columns:1fr 1fr;-webkit-column-gap:20px;column-gap:20px;}}/*!sc*/
.iiCJUO h3{font-size:16px;font-weight:600;margin-bottom:12px;}/*!sc*/
.iiCJUO li + li{margin-top:12px;}/*!sc*/
data-styled.g4[id="sc-c82ca4e2-1"]{content:"iiCJUO,"}/*!sc*/
.eWdALT{display:none;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:44px;height:34px;padding:6px;border-radius:5px;border:none;background:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);cursor:pointer;margin-left:auto;}/*!sc*/
@media (max-width:920px){.eWdALT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.eWdALT div{width:22px;height:2px;background:#fff;-webkit-transform-origin:1px;-ms-transform-origin:1px;transform-origin:1px;-webkit-transition:all 0.3s linear;transition:all 0.3s linear;}/*!sc*/
data-styled.g5[id="sc-46d6b9d9-0"]{content:"eWdALT,"}/*!sc*/
.jTcDmc{-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;overflow:hidden;position:absolute;white-space:nowrap;width:1px;}/*!sc*/
data-styled.g6[id="sc-cdea7863-0"]{content:"jTcDmc,"}/*!sc*/
.gPgccM{position:fixed;top:0;left:0;width:100%;height:80px;z-index:5;background:#fff;box-shadow:0px 4px 10px 4px rgba(0,0,0,0.04);}/*!sc*/
data-styled.g7[id="sc-6852f5f6-0"]{content:"gPgccM,"}/*!sc*/
.jrLPNu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;}/*!sc*/
.jrLPNu .img-logo{width:115px;}/*!sc*/
data-styled.g8[id="sc-6852f5f6-1"]{content:"jrLPNu,"}/*!sc*/
.hzGhxs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.hzGhxs{display:block;position:absolute;top:80px;left:0;width:100%;z-index:1;padding:0 30px 30px;background-color:#fff;opacity:0;z-index:-9999;pointer-events:none;-webkit-transition:opacity 0.3s ease;transition:opacity 0.3s ease;box-shadow:0 4px 10px -1px rgba(0,0,0,0.04);}}/*!sc*/
@media (max-width:720px){.hzGhxs{padding:0 15px 15px;}}/*!sc*/
data-styled.g9[id="sc-6852f5f6-2"]{content:"hzGhxs,"}/*!sc*/
.chSgxF{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.chSgxF{display:block;margin-bottom:15px;}}/*!sc*/
.chSgxF li + li{margin-left:26px;}/*!sc*/
@media (max-width:920px){.chSgxF li + li{margin-left:0;}}/*!sc*/
.chSgxF a{display:inline-block;font-size:1.25rem;line-height:1;color:#000000;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color 0.3s;transition:color 0.3s;}/*!sc*/
.chSgxF a:hover{color:#FE7A00;}/*!sc*/
@media (max-width:920px){.chSgxF a{padding:8px 0;}}/*!sc*/
data-styled.g10[id="sc-6852f5f6-3"]{content:"chSgxF,"}/*!sc*/
.hTbjmy{position:relative;width:160px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;margin-left:26px;}/*!sc*/
@media (max-width:920px){.hTbjmy{width:auto;margin-left:0;}}/*!sc*/
data-styled.g11[id="sc-6852f5f6-4"]{content:"hTbjmy,"}/*!sc*/
.kzOElI{display:inline-block;position:absolute;top:0;right:42px;width:calc(100% - 42px);height:100%;font-size:16px;line-height:1.25;padding:10px 13px;background:#fff;border-radius:5px 0px 0px 5px;border:1px solid #D9D9D9;border-right:none;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;}/*!sc*/
@media (max-width:920px){.kzOElI{display:none;}}/*!sc*/
.kzOElI::-webkit-input-placeholder{color:#D9D9D9;}/*!sc*/
.kzOElI::-moz-placeholder{color:#D9D9D9;}/*!sc*/
.kzOElI:-ms-input-placeholder{color:#D9D9D9;}/*!sc*/
.kzOElI::placeholder{color:#D9D9D9;}/*!sc*/
data-styled.g12[id="sc-6852f5f6-5"]{content:"kzOElI,"}/*!sc*/
.dSfmcG{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;color:#fff;margin-left:auto;-webkit-flex:0 0 42px;-ms-flex:0 0 42px;flex:0 0 42px;height:41px;border:1px solid #474747;border-radius:0px 5px 5px 0px;background-color:#474747;}/*!sc*/
@media (max-width:920px){.dSfmcG{margin-left:0;}}/*!sc*/
data-styled.g13[id="sc-6852f5f6-6"]{content:"dSfmcG,"}/*!sc*/
.eBQFeB{min-height:100vh;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
data-styled.g18[id="sc-da66f971-0"]{content:"eBQFeB,"}/*!sc*/
*,*:before,*:after{box-sizing:border-box;-webkit-font-smoothing:antialiased;}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
html{font-family:'Source Sans Pro',sans-serif;font-weight:400;color:#000000;}/*!sc*/
body{background:#fff;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
main{padding-top:80px;-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
figure{margin:0;}/*!sc*/
img,video{display:block;max-width:100%;height:auto;}/*!sc*/
a{color:unset;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
a:hover{color:unset;}/*!sc*/
strong{font-weight:600;}/*!sc*/
pre{display:block;padding:20px;margin:0 0 10px;font-size:16px;line-height:1.42857143;word-break:break-all;word-wrap:break-word;color:#000;border:1px solid #ebebeb;border-radius:5px;overflow-x:auto;word-wrap:normal;}/*!sc*/
pre code{padding:0;font-size:inherit;color:inherit;white-space:pre-wrap;background-color:transparent;border-radius:0;border:none;}/*!sc*/
code{padding:2px 3px;background:#f7f7f7;border:1px solid #ededed;border-radius:0.375rem;display:inline-block;line-height:1.2;margin:0;font-size:82%;}/*!sc*/
::selection{background-color:#FE7A00;color:#fff;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g19[id="sc-global-hVeuQf1"]{content:"sc-global-hVeuQf1,"}/*!sc*/
.fHlQS h1{font-size:44px;line-height:1.13;font-weight:700;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.fHlQS h1{font-size:38px;}}/*!sc*/
@media (max-width:720px){.fHlQS h1{font-size:32px;}}/*!sc*/
.fHlQS h2{font-size:33px;line-height:1.13;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.fHlQS h2{font-size:30px;}}/*!sc*/
@media (max-width:720px){.fHlQS h2{font-size:26px;}}/*!sc*/
.fHlQS h3{font-size:28px;line-height:1.18;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.fHlQS h3{font-size:26px;}}/*!sc*/
@media (max-width:720px){.fHlQS h3{font-size:24px;}}/*!sc*/
.fHlQS h4{font-size:22px;line-height:1.18;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:720px){.fHlQS h4{font-size:20px;}}/*!sc*/
.fHlQS p{font-size:22px;line-height:1.36;color:#1F1F1F;}/*!sc*/
@media (max-width:1130px){.fHlQS p{font-size:20px;}}/*!sc*/
@media (max-width:920px){.fHlQS p{font-size:18px;}}/*!sc*/
.fHlQS ul,.fHlQS ol{padding-left:40px;}/*!sc*/
.fHlQS ul li,.fHlQS ol li{font-size:22px;line-height:1.36;color:#1F1F1F;}/*!sc*/
@media (max-width:1130px){.fHlQS ul li,.fHlQS ol li{font-size:20px;}}/*!sc*/
@media (max-width:920px){.fHlQS ul li,.fHlQS ol li{font-size:18px;}}/*!sc*/
.fHlQS ul li + li,.fHlQS ol li + li{margin-top:4px;}/*!sc*/
.fHlQS ul{list-style:disc;}/*!sc*/
.fHlQS ol{list-style:decimal;}/*!sc*/
.fHlQS p a,.fHlQS li a{color:#FE7A00;}/*!sc*/
.fHlQS p a:hover,.fHlQS li a:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fHlQS * + *:not(li,a,code){margin-top:15px;}/*!sc*/
.fHlQS * + a[data-gallery],.fHlQS * + video{margin-top:40px;}/*!sc*/
.fHlQS a[data-gallery]{display:block;margin-bottom:40px;}/*!sc*/
.fHlQS iframe,.fHlQS video{margin-bottom:40px;}/*!sc*/
data-styled.g20[id="sc-36356763-0"]{content:"fHlQS,"}/*!sc*/
.dPowUc{display:block;margin-left:auto;margin-right:auto;}/*!sc*/
data-styled.g21[id="sc-36356763-1"]{content:"dPowUc,"}/*!sc*/
.cXdfZy{font-size:62px;line-height:1.04;font-weight:700;color:#fff;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.cXdfZy{font-size:50px;}}/*!sc*/
@media (max-width:720px){.cXdfZy{font-size:42px;}}/*!sc*/
data-styled.g23[id="sc-4d34df46-0"]{content:"cXdfZy,"}/*!sc*/
.wRRdf{padding:80px 0;}/*!sc*/
@media (max-width:920px){.wRRdf{padding:60px 0;}}/*!sc*/
@media (max-width:720px){.wRRdf{padding:40px 0;}}/*!sc*/
data-styled.g30[id="sc-2d40882b-0"]{content:"wRRdf,"}/*!sc*/
.bMcRdu{margin-bottom:30px;}/*!sc*/
data-styled.g31[id="sc-2d40882b-1"]{content:"bMcRdu,"}/*!sc*/
.fZuXtn{position:relative;}/*!sc*/
data-styled.g32[id="sc-2d40882b-2"]{content:"fZuXtn,"}/*!sc*/
.hlBQLj{position:absolute;top:0;right:100%;width:200px;margin-right:50px;text-align:right;}/*!sc*/
@media (max-width:1130px){.hlBQLj{position:unset;width:auto;text-align:left;margin:0 0 30px 0;}}/*!sc*/
data-styled.g33[id="sc-2d40882b-3"]{content:"hlBQLj,"}/*!sc*/
.jOGEdN{font-size:20px;line-height:1.25;color:#1F1F1F;text-transform:capitalize;color:#5651EC;}/*!sc*/
@media (max-width:920px){.jOGEdN{font-size:18px;}}/*!sc*/
.GbnzW{font-size:20px;line-height:1.25;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.GbnzW{font-size:18px;}}/*!sc*/
data-styled.g34[id="sc-2d40882b-4"]{content:"jOGEdN,GbnzW,"}/*!sc*/
</style></head><body><div id="__next"><div class="sc-da66f971-0 eBQFeB __className_667be3"><nav class="sc-6852f5f6-0 gPgccM"><div class="sc-ef15f394-0 iSNtvJ"><div class="sc-6852f5f6-1 jrLPNu"><a href="/"><img alt="Orange Logo" loading="lazy" width="120" height="35" decoding="async" data-nimg="1" class="img-logo" style="color:transparent" src="/_next/static/media/logo-orange.faff1861.svg"/></a><div><button aria-label="Toggle navigation" class="sc-46d6b9d9-0 eWdALT"><div></div><div></div><div></div></button><div class="sc-6852f5f6-2 hzGhxs"><ul class="sc-6852f5f6-3 chSgxF"><li><a href="/examples">Examples</a></li><li><a href="/download">Download</a></li><li><a href="/blog">Blog</a></li><li><a href="/docs">Docs</a></li><li><a href="/workshops">Workshops</a></li></ul><form class="sc-6852f5f6-4 hTbjmy"><div class="sc-6852f5f6-5 kzOElI">Search</div><button class="sc-6852f5f6-6 dSfmcG"><img alt="Icon for search" loading="lazy" width="18" height="17" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/icon-search.459b2665.svg"/><span class="sc-cdea7863-0 jTcDmc">Search through page</span></button></form></div></div></div></div></nav><main><div class="sc-2d40882b-0 wRRdf"><div class="sc-ef15f394-0 fJLXpS"><div class="sc-2d40882b-1 bMcRdu"><p class="sc-2d40882b-4 jOGEdN"><strong>fairness, reweighing</strong></p><h1 class="sc-4d34df46-0 cXdfZy">Orange Fairness - Reweighing as a preprocessor</h1></div><div class="sc-2d40882b-2 fZuXtn"><div class="sc-2d40882b-3 hlBQLj"><p class="sc-2d40882b-4 GbnzW"><strong>Žan Mervič</strong></p><p class="sc-2d40882b-4 GbnzW">Sep 19, 2023</p></div><div class="sc-36356763-0 fHlQS"><div class="lg-react-element "><p>In the <a href="/blog/2023-09-19-fairness-reweighing-dataset/">previous blog post</a>, we introduced the Orange fairness Reweighing widget and used it to reweigh a dataset. In this blog, we will explore another use case for the Reweighing widget: using it as a preprocessor for a specific model.</p>
<h3>Fairness metrics:</h3>
<p>With the fairness addon and widgets that come with it, we also introduced four bias scoring metrics which we can use to evaluate the fairness of model predictions. The metrics are:</p>
<ul>
<li>Disparate Impact (DI): The ratio of favorable outcomes for an unprivileged group to that of the privileged group. An ideal value of 1.0 means the ratio is the same for both groups.<!-- -->
<ul>
<li>DI &lt; 1.0: The privileged group receives favorable outcomes at a higher rate than the unprivileged group.</li>
<li>DI &gt; 1.0: The privileged group receives favorable outcomes at a lower rate than the unprivileged group.</li>
</ul>
</li>
<li>Statistical Parity Difference (SPD): Very similar to disparate impact. Instead of the ratio, it measures the difference in favorable outcomes. An ideal value is 0.0.<!-- -->
<ul>
<li>SPD &lt; 0: The privileged group has a higher rate of favorable outcomes.</li>
<li>SPD &gt; 0: The privileged group has a lower rate of favorable outcomes.</li>
</ul>
</li>
<li>Average Odds Difference (AOD): This metric calculates the average difference between the true positive rates (correctly predicting a positive outcome) and false positive rates (incorrectly predicting a positive outcome) for both the privileged and unprivileged groups. A value of 0.0 indicates equal rates for both groups, signifying fairness.<!-- -->
<ul>
<li>AOD &lt; 0: Indicates bias in favor of the privileged group.</li>
<li>AOD &gt; 0: Indicates bias against the privileged group.</li>
</ul>
</li>
<li>Equal Opportunity Difference (EOD): Similar to the Average Odds Difference. It measures the difference in true positive rates. An ideal value is 0.0, indicating the difference in true positive rates is the same for both groups.<!-- -->
<ul>
<li>EOD &lt; 0: The privileged group has a higher true positive rate.</li>
<li>EOD &gt; 0: The privileged group has a lower true positive rate.</li>
</ul>
</li>
</ul>
<h3>Weighted Logistic Regression and Combine Preprocessors:</h3>
<p>At the time of writing, there were two limitations in using the Reweighing widget as a preprocessor:</p>
<ul>
<li>Currently, model widgets in Orange do not account for instance weights when training.</li>
<li>Model widgets only accept one preprocessor widget as an input; this usually would be fine since all preprocessors can be added from a single widget called Preprocess, but Reweighing is a separate widget and thus could not be combined with other methods.</li>
</ul>
<p>To combat this, we introduced two new widgets which we will use in the example below:</p>
<ul>
<li>Weighted Logistic Regression is an adapted form of the Logistic Regression widget designed to handle weighted datasets.</li>
<li>Combine Preprocessors, which enables users to merge multiple preprocessors into one before inputting it into a widget. This becomes handy when integrating preprocessors other than Reweighing with a model.</li>
</ul>
<h2>Orange use case</h2>
<p>Now that we know all the required widgets and new fairness scoring metrics, let us explore a real-world example of using the reweighing widget as a preprocessor. Doing so will allow us to use the reweighing algorithm when evaluating model performance using cross-validation, random sampling, etc.</p>
<p>We will use the <a href="http://archive.ics.uci.edu/dataset/144/statlog+german+credit+data">German credit dataset</a> for this illustration. The German Credit is a dataset related to bank loans. The main goal is to assess an individual&#x27;s credit risk - whether a person is a good or bad credit risk. The collection consists of 1,000 cases with 20 attributes, of which 13 are categorical and 7 are numerical. The attributes include financial characteristics such as the amount and purpose of the loan, employment status, and credit history, as well as personal features like age, gender, housing status, and foreign worker status. The most frequently used protected attributes in this collection are gender and age.</p>
<p>Like the previous blog, we will not use the As Fairness Data widget to select fairness attributes. Instead, we will use the default attributes, &quot;sex&quot; as the protected attribute and &quot;male&quot; as the privileged group, already defined in the dataset.</p>
<a href="/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-use-case.webp" data-gallery="true"><img alt="" loading="lazy" width="1037" height="467" decoding="async" data-nimg="1" class="sc-36356763-1 dPowUc" style="color:transparent" src="/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-use-case.webp"/></a>
<a href="/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-scores.webp" data-gallery="true"><img alt="" loading="lazy" width="1217" height="471" decoding="async" data-nimg="1" class="sc-36356763-1 dPowUc" style="color:transparent" src="/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-scores.webp"/></a>
<p>The results show that the model using reweighing as a preprocessor achieved better fairness scores than the model without reweighing at the cost of slightly lower accuracy. The Reweighing algorithm mainly focuses on the Disparate Impact and Statistical Parity Difference metrics, which reflect the ratio and difference between the favorable outcomes of the unprivileged and privileged groups.</p>
<p>In this case the ratio of favorable outcomes went from 0.869 to 0.952, while the difference went from -0.105 to -0.038. Both metrics indicate less bias towards the unprivileged group.</p>
<p>We can easily visualize the results using a box plot. For a clearer visualization, we have used the Edit Domain widget to merge all values of each protected group into one, which resulted in two groups: males and females.</p>
<a href="/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-box-plot-bias.webp" data-gallery="true"><img alt="" loading="lazy" width="1208" height="520" decoding="async" data-nimg="1" class="sc-36356763-1 dPowUc" style="color:transparent" src="/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-box-plot-bias.webp"/></a>
<a href="/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-box-plot-debias.webp" data-gallery="true"><img alt="" loading="lazy" width="1203" height="513" decoding="async" data-nimg="1" class="sc-36356763-1 dPowUc" style="color:transparent" src="/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-box-plot-debias.webp"/></a>
<p>The first box plot shows the ratio of favorable and unfavorable outcomes for the unprivileged and privileged groups for predictions from the model without reweighing. The second box plot shows the same for the model with reweighing.</p>
<p>We can see that when using reweighing the amount of favorable outcomes increased for the unprivileged group and decreased for the privileged group bringing the ratios closer between the two groups.</p></div></div></div></div></div></main><footer class="sc-c82ca4e2-0 iQtqNS"><div class="sc-ef15f394-0 iSNtvJ"><div class="sc-c82ca4e2-1 iiCJUO"><div><h3>Orange</h3><ul><li><a href="/faq">FAQ</a></li><li><a href="/license">License</a></li><li><a href="/privacy">Privacy</a></li><li><a href="/citation">Citation</a></li><li><a href="/contact">Contact</a></li></ul></div><div><h3>Download</h3><ul><li><a href="/download#win">Windows</a></li><li><a href="/download#mac">Mac OS</a></li></ul></div><div><h3>Community</h3><ul><li><a href="https://twitter.com/OrangeDataMiner">Twitter</a></li><li><a href="https://www.facebook.com/orangedatamining">Facebook</a></li><li><a href="https://datascience.stackexchange.com/questions/tagged/orange">Stack Exchange</a></li><li><a href="https://www.youtube.com/channel/UClKKWBe2SCAEyv7ZNGhIe4g">YouTube</a></li><li><a href="https://discord.com/invite/FWrfeXV">Discord</a></li></ul></div><div><h3>Documentation</h3><ul><li><a href="/getting-started">Get started</a></li><li><a href="/widget-catalogue">Widgets</a></li><li><a href="https://orange3.readthedocs.io/projects/orange-data-mining-library/en/latest/">Scripting</a></li></ul></div><div><h3>Developers</h3><ul><li><a href="https://github.com/biolab/orange3">GitHub</a></li><li><a href="http://docs.biolab.si/3/development/">Getting started</a></li></ul></div><div><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=A76TAX87ZVR3J" target="_blank" rel="noreferrer" class="sc-b6ea565a-0 jyxOJT">Donate to Orange</a></div></div><p>Copyright © University of Ljubljana</p></div></footer></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"frontmatter":{"author":"Žan Mervič","date":"2023-09-19 04:00:00+00:00","draft":false,"title":"Orange Fairness - Reweighing as a preprocessor","thumbImage":"2023-09-19-fairness-reweighing-preprocessor-thumb.png","frontPageImage":"2023-09-19-fairness-reweighing-preprocessor-thumb.png","blog":["fairness","reweighing"],"shortExcerpt":"Expanding on the Orange fairness Reweighing widget: using it as a preprocessor and integrating new fairness scoring metrics.","longExcerpt":"Diving deeper into the Orange fairness Reweighing widget, we explore its use as a preprocessor for models. Discover the new widgets and fairness scoring metrics; all illustrated using the German credit dataset, supplemented with visual insights through box plots.","oldUrl":"/blog/2023/2023-09-19-fairness-reweighing-preprocessor/"},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    h3: \"h3\",\n    ul: \"ul\",\n    li: \"li\",\n    h2: \"h2\"\n  }, _provideComponents(), props.components), {WindowScreenshot} = _components;\n  if (!WindowScreenshot) _missingMdxReference(\"WindowScreenshot\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"In the \", _jsx(_components.a, {\n        href: \"/blog/2023-09-19-fairness-reweighing-dataset/\",\n        children: \"previous blog post\"\n      }), \", we introduced the Orange fairness Reweighing widget and used it to reweigh a dataset. In this blog, we will explore another use case for the Reweighing widget: using it as a preprocessor for a specific model.\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Fairness metrics:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"With the fairness addon and widgets that come with it, we also introduced four bias scoring metrics which we can use to evaluate the fairness of model predictions. The metrics are:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"Disparate Impact (DI): The ratio of favorable outcomes for an unprivileged group to that of the privileged group. An ideal value of 1.0 means the ratio is the same for both groups.\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"DI \u003c 1.0: The privileged group receives favorable outcomes at a higher rate than the unprivileged group.\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"DI \u003e 1.0: The privileged group receives favorable outcomes at a lower rate than the unprivileged group.\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"Statistical Parity Difference (SPD): Very similar to disparate impact. Instead of the ratio, it measures the difference in favorable outcomes. An ideal value is 0.0.\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"SPD \u003c 0: The privileged group has a higher rate of favorable outcomes.\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"SPD \u003e 0: The privileged group has a lower rate of favorable outcomes.\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"Average Odds Difference (AOD): This metric calculates the average difference between the true positive rates (correctly predicting a positive outcome) and false positive rates (incorrectly predicting a positive outcome) for both the privileged and unprivileged groups. A value of 0.0 indicates equal rates for both groups, signifying fairness.\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"AOD \u003c 0: Indicates bias in favor of the privileged group.\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"AOD \u003e 0: Indicates bias against the privileged group.\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"Equal Opportunity Difference (EOD): Similar to the Average Odds Difference. It measures the difference in true positive rates. An ideal value is 0.0, indicating the difference in true positive rates is the same for both groups.\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"EOD \u003c 0: The privileged group has a higher true positive rate.\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"EOD \u003e 0: The privileged group has a lower true positive rate.\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Weighted Logistic Regression and Combine Preprocessors:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"At the time of writing, there were two limitations in using the Reweighing widget as a preprocessor:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Currently, model widgets in Orange do not account for instance weights when training.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Model widgets only accept one preprocessor widget as an input; this usually would be fine since all preprocessors can be added from a single widget called Preprocess, but Reweighing is a separate widget and thus could not be combined with other methods.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To combat this, we introduced two new widgets which we will use in the example below:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Weighted Logistic Regression is an adapted form of the Logistic Regression widget designed to handle weighted datasets.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Combine Preprocessors, which enables users to merge multiple preprocessors into one before inputting it into a widget. This becomes handy when integrating preprocessors other than Reweighing with a model.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Orange use case\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now that we know all the required widgets and new fairness scoring metrics, let us explore a real-world example of using the reweighing widget as a preprocessor. Doing so will allow us to use the reweighing algorithm when evaluating model performance using cross-validation, random sampling, etc.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We will use the \", _jsx(_components.a, {\n        href: \"http://archive.ics.uci.edu/dataset/144/statlog+german+credit+data\",\n        children: \"German credit dataset\"\n      }), \" for this illustration. The German Credit is a dataset related to bank loans. The main goal is to assess an individual's credit risk - whether a person is a good or bad credit risk. The collection consists of 1,000 cases with 20 attributes, of which 13 are categorical and 7 are numerical. The attributes include financial characteristics such as the amount and purpose of the loan, employment status, and credit history, as well as personal features like age, gender, housing status, and foreign worker status. The most frequently used protected attributes in this collection are gender and age.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Like the previous blog, we will not use the As Fairness Data widget to select fairness attributes. Instead, we will use the default attributes, \\\"sex\\\" as the protected attribute and \\\"male\\\" as the privileged group, already defined in the dataset.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-reweighing-preprocessor/2023-09-19-fairness-reweighing-preprocessor-use-case.png\",\n      width: \"1037\",\n      height: \"467\",\n      src: \"/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-use-case.webp\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-reweighing-preprocessor/2023-09-19-fairness-reweighing-preprocessor-scores.png\",\n      width: \"1217\",\n      height: \"471\",\n      src: \"/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-scores.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The results show that the model using reweighing as a preprocessor achieved better fairness scores than the model without reweighing at the cost of slightly lower accuracy. The Reweighing algorithm mainly focuses on the Disparate Impact and Statistical Parity Difference metrics, which reflect the ratio and difference between the favorable outcomes of the unprivileged and privileged groups.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In this case the ratio of favorable outcomes went from 0.869 to 0.952, while the difference went from -0.105 to -0.038. Both metrics indicate less bias towards the unprivileged group.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We can easily visualize the results using a box plot. For a clearer visualization, we have used the Edit Domain widget to merge all values of each protected group into one, which resulted in two groups: males and females.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-reweighing-preprocessor/2023-09-19-fairness-reweighing-preprocessor-box-plot-bias.png\",\n      width: \"1208\",\n      height: \"520\",\n      src: \"/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-box-plot-bias.webp\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-reweighing-preprocessor/2023-09-19-fairness-reweighing-preprocessor-box-plot-debias.png\",\n      width: \"1203\",\n      height: \"513\",\n      src: \"/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-box-plot-debias.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The first box plot shows the ratio of favorable and unfavorable outcomes for the unprivileged and privileged groups for predictions from the model without reweighing. The second box plot shows the same for the model with reweighing.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We can see that when using reweighing the amount of favorable outcomes increased for the unprivileged group and decreased for the privileged group bringing the ratios closer between the two groups.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}},"thumbImage":{"width":856,"height":500,"src":"/blog/2023-09-fairness-reweighing-preprocessor/__webp-images__/2023-09-19-fairness-reweighing-preprocessor-thumb.webp"}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"orange-fairness-reweighing-as-a-preprocessor"},"buildId":"YG6HGRTcm1VQoDRdUZteU","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>