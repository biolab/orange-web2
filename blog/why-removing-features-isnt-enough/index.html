<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="description" content="Orange Data Mining Toolbox"/><meta property="og:url" content="https://orangedatamining.com"/><meta property="og:site_name" content="Orange Data Mining"/><meta name="author" content="Bioinformatics Laboratory, University of Ljubljana"/><title>Orange Data Mining - Why Removing Features Isn&#x27;t Enough</title><meta name="robots" content="index,follow"/><meta property="og:title" content="Orange Data Mining - Why Removing Features Isn&#x27;t Enough"/><meta property="og:description" content="Find out why merely removing protected attributes will not fix bias. Features often correlate, letting models infer biases. Fairness algorithms are key for genuine bias mitigation."/><meta property="og:type" content="article"/><meta property="article:published_time" content="2023-09-19 05:00:00+00:00"/><meta property="article:author" content="Žan Mervič"/><meta property="article:tag" content="fairness"/><meta property="og:image" content="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-thumb.png"/><meta property="og:image:width" content="607"/><meta property="og:image:height" content="542"/><meta name="next-head-count" content="17"/><link rel="preload" href="/_next/static/media/9cf9c6e84ed13b5e-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/7d889d328a863459.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/7d889d328a863459.css" crossorigin="" data-n-g=""/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" crossorigin="" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-21c828b96ad33382.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-0c7baedefba6b077.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-61a1de8ce4711ed8.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-64d049a45bab48a2.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/690-eebe7c6b2c5b12a7.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-f211bd4808f46605.js" defer="" crossorigin=""></script><script src="/_next/static/zOIGyQpVxUbLsFe4Ju8ds/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/zOIGyQpVxUbLsFe4Ju8ds/_ssgManifest.js" defer="" crossorigin=""></script><style data-styled="" data-styled-version="5.3.6">.eVggRJ{max-width:1296px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;box-sizing:content-box;}/*!sc*/
@media (max-width:1130px){.eVggRJ{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.eVggRJ{padding-left:15px;padding-right:15px;}}/*!sc*/
.CVQuR{max-width:1296px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;box-sizing:content-box;margin-bottom:80px;max-width:714px;}/*!sc*/
@media (max-width:1130px){.CVQuR{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.CVQuR{padding-left:15px;padding-right:15px;}}/*!sc*/
@media (max-width:920px){.CVQuR{margin-bottom:60px;}}/*!sc*/
data-styled.g1[id="sc-61db3aea-0"]{content:"eVggRJ,CVQuR,"}/*!sc*/
.jyxOJT{position:relative;display:inline-block;max-width:100%;font-size:20px;line-height:1.25;font-weight:600;-webkit-text-decoration:none;text-decoration:none;color:#fff;padding:10px 15px;border-radius:5px;background-image:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);background-size:100%;cursor:pointer;z-index:2;}/*!sc*/
@media (max-width:720px){.jyxOJT{font-size:18px;}}/*!sc*/
.jyxOJT:before{content:"";display:block;position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;background-image:linear-gradient(180deg,#ffbc44 100%,#FE7A00 100%);opacity:0;z-index:-100;-webkit-transition:opacity 0.45s;transition:opacity 0.45s;}/*!sc*/
.jyxOJT:hover{color:#fff;}/*!sc*/
.jyxOJT:hover:before{opacity:1;}/*!sc*/
data-styled.g2[id="sc-b6ea565a-0"]{content:"jyxOJT,"}/*!sc*/
.ioIxRn{background:#1F1F1F;padding:38px 0 25px;color:#fff;}/*!sc*/
data-styled.g3[id="sc-3419d6b6-0"]{content:"ioIxRn,"}/*!sc*/
.iYFXoP{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-column-gap:80px;column-gap:80px;row-gap:40px;margin-bottom:40px;}/*!sc*/
@media (max-width:720px){.iYFXoP{display:grid;grid-template-columns:1fr 1fr;-webkit-column-gap:20px;column-gap:20px;}}/*!sc*/
.iYFXoP h3{font-size:16px;font-weight:600;margin-bottom:12px;}/*!sc*/
.iYFXoP li + li{margin-top:12px;}/*!sc*/
data-styled.g4[id="sc-3419d6b6-1"]{content:"iYFXoP,"}/*!sc*/
.eWdALT{display:none;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:44px;height:34px;padding:6px;border-radius:5px;border:none;background:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);cursor:pointer;margin-left:auto;}/*!sc*/
@media (max-width:920px){.eWdALT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.eWdALT div{width:22px;height:2px;background:#fff;-webkit-transform-origin:1px;-ms-transform-origin:1px;transform-origin:1px;-webkit-transition:all 0.3s linear;transition:all 0.3s linear;}/*!sc*/
data-styled.g5[id="sc-46d6b9d9-0"]{content:"eWdALT,"}/*!sc*/
.jTcDmc{-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;overflow:hidden;position:absolute;white-space:nowrap;width:1px;}/*!sc*/
data-styled.g6[id="sc-cdea7863-0"]{content:"jTcDmc,"}/*!sc*/
.dAXQuQ{z-index:100;height:80px;background:#fff;box-shadow:0px 4px 10px 4px rgba(0,0,0,0.04);}/*!sc*/
data-styled.g7[id="sc-a026f25c-0"]{content:"dAXQuQ,"}/*!sc*/
.gUFsBX{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;}/*!sc*/
.gUFsBX .img-logo{width:115px;}/*!sc*/
data-styled.g8[id="sc-a026f25c-1"]{content:"gUFsBX,"}/*!sc*/
.bcvGIl{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.bcvGIl{display:block;position:absolute;top:80px;left:0;width:100%;z-index:1;padding:0 30px 30px;background-color:#fff;opacity:0;z-index:-9999;pointer-events:none;-webkit-transition:opacity 0.3s ease;transition:opacity 0.3s ease;box-shadow:0 4px 10px -1px rgba(0,0,0,0.04);}}/*!sc*/
@media (max-width:720px){.bcvGIl{padding:0 15px 15px;}}/*!sc*/
data-styled.g9[id="sc-a026f25c-2"]{content:"bcvGIl,"}/*!sc*/
.jjIqRA{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.jjIqRA{display:block;margin-bottom:15px;}}/*!sc*/
.jjIqRA li + li{margin-left:26px;}/*!sc*/
@media (max-width:920px){.jjIqRA li + li{margin-left:0;}}/*!sc*/
.jjIqRA a{display:inline-block;font-size:1.25rem;line-height:1;color:#000000;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color 0.3s;transition:color 0.3s;}/*!sc*/
.jjIqRA a:hover{color:#FE7A00;}/*!sc*/
@media (max-width:920px){.jjIqRA a{padding:8px 0;}}/*!sc*/
data-styled.g10[id="sc-a026f25c-3"]{content:"jjIqRA,"}/*!sc*/
.eLPewT{position:relative;width:142px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;margin-left:26px;}/*!sc*/
@media (max-width:920px){.eLPewT{width:auto;margin-left:0;}}/*!sc*/
data-styled.g11[id="sc-a026f25c-4"]{content:"eLPewT,"}/*!sc*/
.ipGgXV{display:inline-block;position:absolute;top:0;right:42px;width:calc(100% - 42px);height:100%;font-size:16px;line-height:1.25;padding:10px 13px;background:#fff;border-radius:5px 0px 0px 5px;border:1px solid #D9D9D9;border-right:none;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;}/*!sc*/
@media (max-width:920px){.ipGgXV{display:none;}}/*!sc*/
.ipGgXV::-webkit-input-placeholder{color:#D9D9D9;}/*!sc*/
.ipGgXV::-moz-placeholder{color:#D9D9D9;}/*!sc*/
.ipGgXV:-ms-input-placeholder{color:#D9D9D9;}/*!sc*/
.ipGgXV::placeholder{color:#D9D9D9;}/*!sc*/
data-styled.g12[id="sc-a026f25c-5"]{content:"ipGgXV,"}/*!sc*/
.iFVURz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;color:#fff;margin-left:auto;-webkit-flex:0 0 42px;-ms-flex:0 0 42px;flex:0 0 42px;height:41px;border:1px solid #474747;border-radius:0px 5px 5px 0px;background-color:#474747;}/*!sc*/
@media (max-width:920px){.iFVURz{margin-left:0;}}/*!sc*/
data-styled.g13[id="sc-a026f25c-6"]{content:"iFVURz,"}/*!sc*/
.kOMJoa{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:12px;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}/*!sc*/
data-styled.g18[id="sc-7e1621ad-0"]{content:"kOMJoa,"}/*!sc*/
.kkwPib{position:fixed;bottom:20px;right:20px;padding:20px;z-index:999;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background:#1F1F1F;color:#fff;border-radius:5px;border:1px solid #D9D9D9;box-shadow:0px 6px 20px 0px rgba(0,0,0,0.06);-webkit-transform:translateY(calc(100% + 100px));-ms-transform:translateY(calc(100% + 100px));transform:translateY(calc(100% + 100px));-webkit-transition:-webkit-transform 0.5s ease-in-out;-webkit-transition:transform 0.5s ease-in-out;transition:transform 0.5s ease-in-out;}/*!sc*/
@media (max-width:720px){.kkwPib{left:10px;right:10px;bottom:10px;}}/*!sc*/
.kkwPib p{margin-bottom:11px;font-size:17px;}/*!sc*/
data-styled.g19[id="sc-7e1621ad-1"]{content:"kkwPib,"}/*!sc*/
.fkWelF{font-size:15px;padding:9px 12px;border-radius:8px;cursor:pointer;background:#1F1F1F;color:#fff;border:1px solid #fff;}/*!sc*/
.dsztgy{font-size:15px;padding:9px 12px;border-radius:8px;cursor:pointer;background:#fff;color:#1F1F1F;border:1px solid #fff;padding-left:22px;padding-right:22px;}/*!sc*/
data-styled.g20[id="sc-7e1621ad-2"]{content:"fkWelF,dsztgy,"}/*!sc*/
.eWBvvS{min-height:100vh;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
data-styled.g21[id="sc-b34fb00f-0"]{content:"eWBvvS,"}/*!sc*/
*,*:before,*:after{box-sizing:border-box;-webkit-font-smoothing:antialiased;}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
html{font-family:'Source Sans Pro',sans-serif;font-weight:400;color:#000000;}/*!sc*/
body{background:#fff;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
main{-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
figure{margin:0;}/*!sc*/
img,video{display:block;max-width:100%;height:auto;}/*!sc*/
a{color:unset;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
a:hover{color:unset;}/*!sc*/
strong{font-weight:600;}/*!sc*/
pre{display:block;padding:15px;margin:0 0 10px;font-size:14px;word-break:break-all;word-wrap:break-word;color:#000;border:1px solid #ebebeb;border-radius:5px;overflow-x:auto;word-wrap:normal;}/*!sc*/
pre code{padding:0 !important;font-size:inherit;color:inherit;white-space:pre-wrap;background-color:transparent;border-radius:0;border:none;line-height:1.35;}/*!sc*/
code{padding:2px 3px;background:#f7f7f7;border:1px solid #ededed;border-radius:0.375rem;display:inline-block;line-height:1.2;margin:0;font-size:78%;}/*!sc*/
::selection{background-color:#FE7A00;color:#fff;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
pre code.hljs{display:block;overflow-x:auto;padding:1em;}/*!sc*/
code.hljs{padding:3px 5px;}/*!sc*/
.hljs{color:#24292e;background:#fff;}/*!sc*/
.hljs-doctag,.hljs-keyword,.hljs-meta .hljs-keyword,.hljs-template-tag,.hljs-template-variable,.hljs-type,.hljs-variable.language_{color:#d73a49;}/*!sc*/
.hljs-title,.hljs-title.class_,.hljs-title.class_.inherited__,.hljs-title.function_{color:#6f42c1;}/*!sc*/
.hljs-attr,.hljs-attribute,.hljs-literal,.hljs-meta,.hljs-number,.hljs-operator,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-variable{color:#005cc5;}/*!sc*/
.hljs-meta .hljs-string,.hljs-regexp,.hljs-string{color:#032f62;}/*!sc*/
.hljs-built_in,.hljs-symbol{color:#e36209;}/*!sc*/
.hljs-code,.hljs-comment,.hljs-formula{color:#6a737d;}/*!sc*/
.hljs-name,.hljs-quote,.hljs-selector-pseudo,.hljs-selector-tag{color:#22863a;}/*!sc*/
.hljs-subst{color:#24292e;}/*!sc*/
.hljs-section{color:#005cc5;font-weight:700;}/*!sc*/
.hljs-bullet{color:#735c0f;}/*!sc*/
.hljs-emphasis{color:#24292e;font-style:italic;}/*!sc*/
.hljs-strong{color:#24292e;font-weight:700;}/*!sc*/
.hljs-addition{color:#22863a;background-color:#f0fff4;}/*!sc*/
.hljs-deletion{color:#b31d28;background-color:#ffeef0;}/*!sc*/
data-styled.g22[id="sc-global-ehweHW1"]{content:"sc-global-ehweHW1,"}/*!sc*/
.dpPsin h1{font-size:44px;line-height:1.13;font-weight:700;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.dpPsin h1{font-size:38px;}}/*!sc*/
@media (max-width:720px){.dpPsin h1{font-size:32px;}}/*!sc*/
.dpPsin h2{font-size:33px;line-height:1.13;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.dpPsin h2{font-size:30px;}}/*!sc*/
@media (max-width:720px){.dpPsin h2{font-size:26px;}}/*!sc*/
.dpPsin h3{font-size:28px;line-height:1.18;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.dpPsin h3{font-size:26px;}}/*!sc*/
@media (max-width:720px){.dpPsin h3{font-size:24px;}}/*!sc*/
.dpPsin h4{font-size:22px;line-height:1.18;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:720px){.dpPsin h4{font-size:20px;}}/*!sc*/
.dpPsin p{font-size:20px;line-height:1.4;color:#1F1F1F;}/*!sc*/
@media (max-width:1130px){.dpPsin p{font-size:20px;}}/*!sc*/
@media (max-width:920px){.dpPsin p{font-size:18px;}}/*!sc*/
.dpPsin ul,.dpPsin ol{padding-left:40px;}/*!sc*/
.dpPsin ul li,.dpPsin ol li{font-size:20px;line-height:1.4;color:#1F1F1F;}/*!sc*/
@media (max-width:1130px){.dpPsin ul li,.dpPsin ol li{font-size:20px;}}/*!sc*/
@media (max-width:920px){.dpPsin ul li,.dpPsin ol li{font-size:18px;}}/*!sc*/
.dpPsin ul li + li,.dpPsin ol li + li{margin-top:4px;}/*!sc*/
.dpPsin ul{list-style:disc;}/*!sc*/
.dpPsin ol{list-style:decimal;}/*!sc*/
.dpPsin p a,.dpPsin li a{color:#FE7A00;}/*!sc*/
.dpPsin p a:hover,.dpPsin li a:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.dpPsin * + *:not(li,a,code){margin-top:20px;}/*!sc*/
.dpPsin * + a[data-gallery],.dpPsin * + video{margin-top:40px;}/*!sc*/
.dpPsin a[data-gallery]{display:block;margin-bottom:40px;}/*!sc*/
.dpPsin iframe,.dpPsin video{margin-bottom:40px;}/*!sc*/
data-styled.g23[id="sc-8f0614a2-0"]{content:"dpPsin,"}/*!sc*/
.cHIhER{display:block;margin-left:auto;margin-right:auto;}/*!sc*/
data-styled.g24[id="sc-8f0614a2-1"]{content:"cHIhER,"}/*!sc*/
.loxVcf{font-size:62px;line-height:1.04;font-weight:700;color:#fff;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.loxVcf{font-size:50px;}}/*!sc*/
@media (max-width:720px){.loxVcf{font-size:42px;}}/*!sc*/
data-styled.g26[id="sc-c67a4900-0"]{content:"loxVcf,"}/*!sc*/
.cyZFCR{padding:80px 0;}/*!sc*/
@media (max-width:920px){.cyZFCR{padding:60px 0;}}/*!sc*/
@media (max-width:720px){.cyZFCR{padding:40px 0;}}/*!sc*/
data-styled.g33[id="sc-b9a2839b-0"]{content:"cyZFCR,"}/*!sc*/
.cIBHvM{margin-bottom:30px;}/*!sc*/
data-styled.g34[id="sc-b9a2839b-1"]{content:"cIBHvM,"}/*!sc*/
.kBOXgB{position:relative;}/*!sc*/
data-styled.g35[id="sc-b9a2839b-2"]{content:"kBOXgB,"}/*!sc*/
.fMPIzd{position:absolute;top:0;right:100%;width:200px;margin-right:50px;text-align:right;}/*!sc*/
@media (max-width:1130px){.fMPIzd{position:unset;width:auto;text-align:left;margin:0 0 30px 0;}}/*!sc*/
data-styled.g36[id="sc-b9a2839b-3"]{content:"fMPIzd,"}/*!sc*/
.cdlBoX{font-size:20px;line-height:1.25;color:#1F1F1F;text-transform:capitalize;color:#5651EC;}/*!sc*/
@media (max-width:920px){.cdlBoX{font-size:18px;}}/*!sc*/
.ehbERY{font-size:20px;line-height:1.25;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.ehbERY{font-size:18px;}}/*!sc*/
data-styled.g37[id="sc-b9a2839b-4"]{content:"cdlBoX,ehbERY,"}/*!sc*/
</style></head><body><div id="__next"><div class="sc-b34fb00f-0 eWBvvS __className_aeb8b9"><nav class="sc-a026f25c-0 dAXQuQ"><div class="sc-61db3aea-0 eVggRJ"><div class="sc-a026f25c-1 gUFsBX"><a href="/"><img alt="Orange Logo" loading="lazy" width="120" height="35" decoding="async" data-nimg="1" class="img-logo" style="color:transparent" src="/_next/static/media/logo-orange.faff1861.svg"/></a><div><button aria-label="Toggle navigation" class="sc-46d6b9d9-0 eWdALT"><div></div><div></div><div></div></button><div class="sc-a026f25c-2 bcvGIl"><ul class="sc-a026f25c-3 jjIqRA"><li><a href="/screenshots/">Screenshots</a></li><li><a href="/download/">Download</a></li><li><a href="/blog/">Blog</a></li><li><a href="/docs/">Docs</a></li><li><a href="/workshops/">Workshops</a></li><li><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=A76TAX87ZVR3J">Donate</a></li></ul><form class="sc-a026f25c-4 eLPewT"><div class="sc-a026f25c-5 ipGgXV">Search</div><button class="sc-a026f25c-6 iFVURz"><img alt="Icon for search" loading="lazy" width="18" height="17" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/icon-search.459b2665.svg"/><span class="sc-cdea7863-0 jTcDmc">Search through page</span></button></form></div></div></div></div></nav><main><div class="sc-b9a2839b-0 cyZFCR"><div class="sc-61db3aea-0 CVQuR"><div class="sc-b9a2839b-1 cIBHvM"><p class="sc-b9a2839b-4 cdlBoX"><strong>fairness</strong></p><h1 class="sc-c67a4900-0 loxVcf">Why Removing Features Isn&#x27;t Enough</h1></div><div class="sc-b9a2839b-2 kBOXgB"><div class="sc-b9a2839b-3 fMPIzd"><p class="sc-b9a2839b-4 ehbERY"><strong>Žan Mervič</strong></p><p class="sc-b9a2839b-4 ehbERY">Sep 19, 2023</p></div><div class="sc-8f0614a2-0 dpPsin"><div class="lg-react-element "><p>Previously, we introduced and explained different fairness algorithms that can be used to mitigate bias in a dataset or model predictions. Here, we will discuss a common misconception: removing the protected attribute from the dataset will remove bias. We show why this is not the case and why it is essential to use fairness algorithms.</p>
<h2>Hiding Protected Attribute:</h2>
<p>Our setup is the following: we have two workflows, and both are using the adult data set. In the first workflow, we will train a logistic regression model using Reweighing as a preprocessor and a regular logistic regression model as a baseline on data that has not been modified. The second workflow uses the same dataset but with the protected attribute hidden from the models. We will then compare the predictions of the two workflows using a Box Plot.</p>
<a href="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-use-case-1.png" data-gallery="true"><img alt="" loading="lazy" width="953" height="355" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-use-case-1.png"/></a>
<a href="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-use-case-2.png" data-gallery="true"><img alt="" loading="lazy" width="841" height="246" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-use-case-2.png"/></a>
<p>The two workflows are very similar, the only difference being the extra learner used in the first workflow, the reweighted learner, and the Select Columns widget used in the second workflow. The Select Columns widget is used to hide the protected attribute from the models, by moving it to the meta-attributes.</p>
<p>In this example, we will not be able to use the scores to compare the fairness metrics of the models because we could not calculate the fairness metrics for the workflow with the hidden protected attribute. This is because the protected attribute is required to calculate the fairness metrics. Saying that we can still compare the accuracy scores of the models. Here are the scores for the reweighted model, the baseline model, and the model learning on altered data:</p>
<a href="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-scores.png" data-gallery="true"><img alt="" loading="lazy" width="815" height="196" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-scores.png"/></a>
<p>The baseline model and the model learning on altered data have very similar accuracy scores, while the reweighted model has a slight dip in accuracy.</p>
<p>Instead of using the scores to compare the models, we will visualize the fairness Disparate Impact and Statistical Parity Difference fairness metrics using the Box Plot widget, just like we did in many previous blogs. Here we will show three different box plots, the first one will be from the reweighted model, the second one from the baseline, and the third from the model learning on data with the protected attribute removed:</p>
<a href="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-box-plot.png" data-gallery="true"><img alt="" loading="lazy" width="718" height="693" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-box-plot.png"/></a>
<p>The box plots show that the baseline model results are very similar to the model learning on data with the protected attribute removed. In contrast, the reweighted model results are very different. The ratio of favorable prediction is much more similar when using debiasing compared to the baseline model and the model learning on data with the protected attribute removed.</p>
<p>A similar observation can be made for the Equalized Odds Difference and Average Odds Difference fairness metrics. Using a similar setup as in the <a href="/blog/2023-09-19-fairness-equal-odds-postprocessing/">previous blog post</a>, we visualized the True Positive Rate for each group using the box plot widget. We trained one model using the Equalized Odds Postprocessing widget and one on data with the protected attribute &quot;age&quot; hidden. Here are the results:</p>
<a href="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-box-plot-2.png" data-gallery="true"><img alt="" loading="lazy" width="705" height="450" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-box-plot-2.png"/></a>
<p>In the visualizations, the red part of each row represents the true positive rate for each group. We can see that the difference in True Positive Rate between the two groups is much smaller when using the Equal Odds Postprocessing widget.</p>
<h2>Why and how?</h2>
<p>If we removed the protected attribute from the dataset on which we train and test the model, how is it that the predictions are still biased towards one of the groups?</p>
<p>The answer is that features in a dataset are often correlated. This means that even if we remove the protected attribute, other features can still be used to infer the protected attribute. For example, suppose the protected attribute is race, and we have a feature like zip code in the data. Since certain races might be predominant in particular zip codes, the model may still indirectly learn the bias. We can test this correlation by predicting the protected attribute from the other features. If we can predict the protected attribute with high accuracy, we know that the other features are correlated with the protected attribute. Here is an example of such a workflow:</p>
<a href="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-sex.png" data-gallery="true"><img alt="" loading="lazy" width="547" height="248" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-sex.png"/></a>
<p>In this workflow, we set the &quot;sex&quot; attribute as the target variable and use a Logistic Regression model to try and predict it.</p>
<a href="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-sex-scores.png" data-gallery="true"><img alt="" loading="lazy" width="423" height="58" decoding="async" data-nimg="1" class="sc-8f0614a2-1 cHIhER" style="color:transparent" src="/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-sex-scores.png"/></a>
<p>We can see that the model has a very high accuracy score, which means that the other features in the dataset are correlated with the protected attribute. This means that even if we remove the protected attribute from the dataset, the model can still infer it from the other features. This is why it is crucial to use fairness algorithms instead of simply removing the protected attribute.</p>
<p>The other reason might be that the sex attribute is not very important for making predictions. We tested this by calculating feature importance for the models. We found that sex is the second lest important feature for making predictions. This means, that the protected attribute - sex, does not directly influence the predictions.</p></div></div></div></div></div></main><footer class="sc-3419d6b6-0 ioIxRn"><div class="sc-61db3aea-0 eVggRJ"><div class="sc-3419d6b6-1 iYFXoP"><div><h3>Orange</h3><ul><li><a href="/faq/">FAQ</a></li><li><a href="/license/">License</a></li><li><a href="/privacy/">Privacy</a></li><li><a href="/citation/">Citation</a></li><li><a href="/contact/">Contact</a></li></ul></div><div><h3><a href="/download/">Download</a></h3><ul><li><a href="/download/#win">Windows</a></li><li><a href="/download/#mac">Mac OS</a></li><li><a href="/download/#other">Other platforms</a></li></ul></div><div><h3>Community</h3><ul><li><a href="https://twitter.com/OrangeDataMiner">Twitter</a></li><li><a href="https://www.facebook.com/orangedatamining">Facebook</a></li><li><a href="https://datascience.stackexchange.com/questions/tagged/orange">Stack Exchange</a></li><li><a href="https://www.youtube.com/channel/UClKKWBe2SCAEyv7ZNGhIe4g">YouTube</a></li><li><a href="https://discord.com/invite/FWrfeXV">Discord</a></li></ul></div><div><h3><a href="/docs/">Documentation</a></h3><ul><li><a href="/getting-started/">Get started</a></li><li><a href="https://www.youtube.com/channel/UClKKWBe2SCAEyv7ZNGhIe4g">YouTube tutorials</a></li><li><a href="/examples/">Example workflows</a></li><li><a href="/widget-catalog/">Widgets</a></li><li><a href="https://orange3.readthedocs.io/projects/orange-data-mining-library/en/latest/">Scripting</a></li></ul></div><div><h3>Developers</h3><ul><li><a href="https://github.com/biolab/orange3">GitHub</a></li><li><a href="http://docs.biolab.si/3/development/">Getting started</a></li></ul></div><div><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=A76TAX87ZVR3J" target="_blank" rel="noreferrer" class="sc-b6ea565a-0 jyxOJT">Donate to Orange</a></div></div><p>Copyright © University of Ljubljana</p></div></footer><div class="sc-7e1621ad-1 kkwPib"><div><p>This site uses cookies to improve your experience.</p><div class="sc-7e1621ad-0 kOMJoa"><button class="sc-7e1621ad-2 fkWelF">Details</button><button class="sc-7e1621ad-2 dsztgy">Understand</button></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"frontmatter":{"author":"Žan Mervič","date":"2023-09-19 05:00:00+00:00","draft":false,"title":"Why Removing Features Isn't Enough","thumbImage":"2023-09-19-fairness-hiding-protected-attribute-thumb.png","frontPageImage":"2023-09-19-fairness-hiding-protected-attribute-thumb.png","blog":["fairness"],"shortExcerpt":"Find out why merely removing protected attributes will not fix bias. Features often correlate, letting models infer biases. Fairness algorithms are key for genuine bias mitigation.","longExcerpt":"In this blog, we confront the common misconception that merely removing a protected attribute from a dataset eliminates bias in model predictions. Our case study reveals that models trained without these attributes still produce biased results. This is due to feature correlations that indirectly capture the protected information. Our conclusion? You cannot sidestep the need for specialized fairness algorithms.","oldUrl":"/blog/2023/2023-09-19-fairness-hiding-protected-attribute/"},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    h2: \"h2\",\n    a: \"a\"\n  }, _provideComponents(), props.components), {WindowScreenshot} = _components;\n  if (!WindowScreenshot) _missingMdxReference(\"WindowScreenshot\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Previously, we introduced and explained different fairness algorithms that can be used to mitigate bias in a dataset or model predictions. Here, we will discuss a common misconception: removing the protected attribute from the dataset will remove bias. We show why this is not the case and why it is essential to use fairness algorithms.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Hiding Protected Attribute:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Our setup is the following: we have two workflows, and both are using the adult data set. In the first workflow, we will train a logistic regression model using Reweighing as a preprocessor and a regular logistic regression model as a baseline on data that has not been modified. The second workflow uses the same dataset but with the protected attribute hidden from the models. We will then compare the predictions of the two workflows using a Box Plot.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/2023-09-19-fairness-hiding-protected-attribute-use-case-1.png\",\n      width: \"953\",\n      height: \"355\",\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-use-case-1.png\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/2023-09-19-fairness-hiding-protected-attribute-use-case-2.png\",\n      width: \"841\",\n      height: \"246\",\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-use-case-2.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The two workflows are very similar, the only difference being the extra learner used in the first workflow, the reweighted learner, and the Select Columns widget used in the second workflow. The Select Columns widget is used to hide the protected attribute from the models, by moving it to the meta-attributes.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In this example, we will not be able to use the scores to compare the fairness metrics of the models because we could not calculate the fairness metrics for the workflow with the hidden protected attribute. This is because the protected attribute is required to calculate the fairness metrics. Saying that we can still compare the accuracy scores of the models. Here are the scores for the reweighted model, the baseline model, and the model learning on altered data:\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/2023-09-19-fairness-hiding-protected-attribute-scores.png\",\n      width: \"815\",\n      height: \"196\",\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-scores.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The baseline model and the model learning on altered data have very similar accuracy scores, while the reweighted model has a slight dip in accuracy.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Instead of using the scores to compare the models, we will visualize the fairness Disparate Impact and Statistical Parity Difference fairness metrics using the Box Plot widget, just like we did in many previous blogs. Here we will show three different box plots, the first one will be from the reweighted model, the second one from the baseline, and the third from the model learning on data with the protected attribute removed:\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/2023-09-19-fairness-hiding-protected-attribute-box-plot.png\",\n      width: \"718\",\n      height: \"693\",\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-box-plot.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The box plots show that the baseline model results are very similar to the model learning on data with the protected attribute removed. In contrast, the reweighted model results are very different. The ratio of favorable prediction is much more similar when using debiasing compared to the baseline model and the model learning on data with the protected attribute removed.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"A similar observation can be made for the Equalized Odds Difference and Average Odds Difference fairness metrics. Using a similar setup as in the \", _jsx(_components.a, {\n        href: \"/blog/2023-09-19-fairness-equal-odds-postprocessing/\",\n        children: \"previous blog post\"\n      }), \", we visualized the True Positive Rate for each group using the box plot widget. We trained one model using the Equalized Odds Postprocessing widget and one on data with the protected attribute \\\"age\\\" hidden. Here are the results:\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/2023-09-19-fairness-hiding-protected-attribute-box-plot-2.png\",\n      width: \"705\",\n      height: \"450\",\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-box-plot-2.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In the visualizations, the red part of each row represents the true positive rate for each group. We can see that the difference in True Positive Rate between the two groups is much smaller when using the Equal Odds Postprocessing widget.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Why and how?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If we removed the protected attribute from the dataset on which we train and test the model, how is it that the predictions are still biased towards one of the groups?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The answer is that features in a dataset are often correlated. This means that even if we remove the protected attribute, other features can still be used to infer the protected attribute. For example, suppose the protected attribute is race, and we have a feature like zip code in the data. Since certain races might be predominant in particular zip codes, the model may still indirectly learn the bias. We can test this correlation by predicting the protected attribute from the other features. If we can predict the protected attribute with high accuracy, we know that the other features are correlated with the protected attribute. Here is an example of such a workflow:\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/2023-09-19-fairness-hiding-protected-attribute-sex.png\",\n      width: \"547\",\n      height: \"248\",\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-sex.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In this workflow, we set the \\\"sex\\\" attribute as the target variable and use a Logistic Regression model to try and predict it.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/2023-09-19-fairness-hiding-protected-attribute-sex-scores.png\",\n      width: \"423\",\n      height: \"58\",\n      src: \"/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-sex-scores.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We can see that the model has a very high accuracy score, which means that the other features in the dataset are correlated with the protected attribute. This means that even if we remove the protected attribute from the dataset, the model can still infer it from the other features. This is why it is crucial to use fairness algorithms instead of simply removing the protected attribute.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The other reason might be that the sex attribute is not very important for making predictions. We tested this by calculating feature importance for the models. We found that sex is the second lest important feature for making predictions. This means, that the protected attribute - sex, does not directly influence the predictions.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}},"thumbImage":{"width":607,"height":542,"src":"/blog/2023-09-fairness-hiding-protected-attribute/__optimized-images__/2023-09-19-fairness-hiding-protected-attribute-thumb.png"}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"why-removing-features-isnt-enough"},"buildId":"zOIGyQpVxUbLsFe4Ju8ds","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>