<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-9f90a364d66949ce.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8cfbd06f8ddd0b49.js" defer=""></script><script src="/_next/static/chunks/675-262430aa11afdf01.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-ba4a3f289f8ef3c5.js" defer=""></script><script src="/_next/static/t3FkTJiCx_jp9wzVJgeAY/_buildManifest.js" defer=""></script><script src="/_next/static/t3FkTJiCx_jp9wzVJgeAY/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.iBQlkL{background:coral;height:60px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.iBQlkL ul{display:none;}}/*!sc*/
data-styled.g1[id="sc-7295e4c-0"]{content:"iBQlkL,"}/*!sc*/
.bDMZDz{display:none;font-size:22px;margin-left:auto;}/*!sc*/
@media (max-width:920px){.bDMZDz{display:block;}}/*!sc*/
data-styled.g2[id="sc-7295e4c-1"]{content:"bDMZDz,"}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
body{background:#fff;}/*!sc*/
html{box-sizing:border-box;font-size:16px;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
img,video{max-width:100%;height:auto;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g3[id="sc-global-cqyaiF1"]{content:"sc-global-cqyaiF1,"}/*!sc*/
.cGDPDa{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g6[id="sc-f0e62130-0"]{content:"cGDPDa,"}/*!sc*/
</style></head><body><div id="__next"><nav class="sc-7295e4c-0 iBQlkL"><ul><a href="/blog">Blog</a></ul><button class="sc-7295e4c-1 bDMZDz">X</button></nav><main><div class="sc-f0e62130-0 cGDPDa"><h1>Making Predictions</h1><div class="lg-react-element "><p>One of the cool things about being a data scientist is being able to predict. That is, predict before we know the actual outcome. I am not talking about verifying your favorite classification algorithm here, and I am not talking about cross-validation or classification accuracies or AUC or anything like that. I am talking about the good old prediction. This is where our very own Predictions widget comes to help.</p>
<p><a href="/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface2.webp" data-gallery="true"><img alt="" srcSet="/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface2.webp 1x, /blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface2.webp 2x" src="/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface2.webp" width="638" height="573" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
Predictions workflow.</p>
<p>We will be exploring the Iris data set again, but we&#x27;re going to add a little twist to it. Since we&#x27;ve <a href="/blog/2015/07/24/visualizing-misclassifications/">worked so much</a> with it already, I&#x27;m sure you know all about this data. But now we got three new flowers in the office and of course there&#x27;s no label attached to tell us what species of Iris these flowers are. [sigh....] Obviously, we will be measuring petals and sepals and contrasting the results with our data.</p>
<p><a href="/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface3-2.webp" data-gallery="true"><img alt="" srcSet="/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface3-2.webp 1x, /blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface3-2.webp 2x" src="/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface3-2.webp" width="658" height="376" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
Our new data on three flowers. We have used Google Sheets to enter the data and the copied the sharable link and pasted the link to the File widget.</p>
<p>But surely you don&#x27;t want to go through all 150 flowers to properly match the three new Irises? So instead, let&#x27;s first train a model on the existing data set. We connect the File widget to the chosen classifier (we went with Classification Tree this time) and feed the results into Predictions. Now we write down the measurements for our new flowers into <a href="https://www.youtube.com/watch?v=MHcGdQeYCMg">Google Sheets</a> (just like above), load it into Orange with a new File widget and input the fresh data into Predictions. We can observe the predicted class directly in the widget itself.</p>
<p><a href="/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface1.webp" data-gallery="true"><img alt="" srcSet="/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface1.webp 1x, /blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface1.webp 2x" src="/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface1.webp" width="832" height="495" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
Predictions made by classification tree.</p>
<p>In the left part of the visualization we have the input data set (our measurements) and in the right part the predictions made with classification tree. By default you see probabilities for all three class values and the predicted class. You can of course use other classifiers as well - it would probably make sense to first evaluate classifiers on the existing data set, find the best one for your and then use it on the new data.</p></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"AJDA","date":"2016-01-22 16:01:36+00:00","draft":false,"title":"Making Predictions","type":"blog","blog":["analysis","data","examples","predictive analytics","widget"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\",\n    a: \"a\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"One of the cool things about being a data scientist is being able to predict. That is, predict before we know the actual outcome. I am not talking about verifying your favorite classification algorithm here, and I am not talking about cross-validation or classification accuracies or AUC or anything like that. I am talking about the good old prediction. This is where our very own Predictions widget comes to help.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.img, {\n        src: \"/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface2.webp\",\n        alt: \"\",\n        width: \"638\",\n        height: \"573\"\n      }), \"\\nPredictions workflow.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We will be exploring the Iris data set again, but we're going to add a little twist to it. Since we've \", _jsx(_components.a, {\n        href: \"/blog/2015/07/24/visualizing-misclassifications/\",\n        children: \"worked so much\"\n      }), \" with it already, I'm sure you know all about this data. But now we got three new flowers in the office and of course there's no label attached to tell us what species of Iris these flowers are. [sigh....] Obviously, we will be measuring petals and sepals and contrasting the results with our data.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.img, {\n        src: \"/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface3-2.webp\",\n        alt: \"\",\n        width: \"658\",\n        height: \"376\"\n      }), \"\\nOur new data on three flowers. We have used Google Sheets to enter the data and the copied the sharable link and pasted the link to the File widget.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"But surely you don't want to go through all 150 flowers to properly match the three new Irises? So instead, let's first train a model on the existing data set. We connect the File widget to the chosen classifier (we went with Classification Tree this time) and feed the results into Predictions. Now we write down the measurements for our new flowers into \", _jsx(_components.a, {\n        href: \"https://www.youtube.com/watch?v=MHcGdQeYCMg\",\n        children: \"Google Sheets\"\n      }), \" (just like above), load it into Orange with a new File widget and input the fresh data into Predictions. We can observe the predicted class directly in the widget itself.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.img, {\n        src: \"/blog/2016-01-predictive-analytics-with-orange/__webp-images__/predictions_new_interface1.webp\",\n        alt: \"\",\n        width: \"832\",\n        height: \"495\"\n      }), \"\\nPredictions made by classification tree.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In the left part of the visualization we have the input data set (our measurements) and in the right part the predictions made with classification tree. By default you see probabilities for all three class values and the predicted class. You can of course use other classifiers as well - it would probably make sense to first evaluate classifiers on the existing data set, find the best one for your and then use it on the new data.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"making-predictions"},"buildId":"t3FkTJiCx_jp9wzVJgeAY","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>