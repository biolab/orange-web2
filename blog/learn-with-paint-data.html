<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-9f90a364d66949ce.js" defer=""></script><script src="/_next/static/chunks/pages/_app-72ed113f22a36849.js" defer=""></script><script src="/_next/static/chunks/675-262430aa11afdf01.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-686c32cdd11f6681.js" defer=""></script><script src="/_next/static/Z7L00iEto9rZ4XCOOSDzJ/_buildManifest.js" defer=""></script><script src="/_next/static/Z7L00iEto9rZ4XCOOSDzJ/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.iBQlkL{background:coral;height:60px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.iBQlkL ul{display:none;}}/*!sc*/
data-styled.g1[id="sc-7295e4c-0"]{content:"iBQlkL,"}/*!sc*/
.bDMZDz{display:none;font-size:22px;margin-left:auto;}/*!sc*/
@media (max-width:920px){.bDMZDz{display:block;}}/*!sc*/
data-styled.g2[id="sc-7295e4c-1"]{content:"bDMZDz,"}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
body{background:#fff;}/*!sc*/
html{box-sizing:border-box;font-size:16px;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
img,video{max-width:100%;height:auto;}/*!sc*/
data-styled.g3[id="sc-global-eYmBoQ1"]{content:"sc-global-eYmBoQ1,"}/*!sc*/
.eTvBKa{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g4[id="sc-f1463bb7-0"]{content:"eTvBKa,"}/*!sc*/
</style></head><body><div id="__next"><nav class="sc-7295e4c-0 iBQlkL"><ul><a href="/blog">Blog</a></ul><button class="sc-7295e4c-1 bDMZDz">X</button></nav><main><div class="sc-f1463bb7-0 eTvBKa"><h1>Learn with Paint Data</h1><p><strong>Paint Data</strong> widget might initially look like a kids’ game, but in combination with other Orange widgets it becomes a very simple and useful tool for conveying statistical concepts, such as <strong>k-means</strong>, <strong>hierarchical clustering</strong> and <strong>prediction models</strong> (like SVM, logistical regression, etc.).</p>
<p>The widget enables you to draw your data on a 2-D plane. You can name the x and y axes, select the number of classes (which are represented by different colors) and then position the points on a graph.</p>
<p><img src="/blog/2015-07-learn-with-paint-data/PaintData-Example.png" alt=""/></p>
<p>Several painting tools allow you to manage your data set according to your specific needs; brush will paint several data instances at once, while put allows you paint a single data instance. Select a data subset and view it in the Data Table widget or zoom in to see the position of your points up close. Jitter and magnet are converse tools which allow either to spread the instances or draw them closer together.</p>
<p>The data will be represented in a data table with two attributes, where their instances correspond to coordinates in the system. Such data set is great for demonstrating k-means and hierarchical clustering methods. Just like we do below. In the screenshot we see that k-means, with our particular settings, recognizes clusters way better than hierarchical clustering. It returns a score rank, where the best score (the one with the highest value) means the most likely number of clusters. Hierarchical clustering, however, doesn’t even group the right classes together.</p>
<p><img src="/blog/2015-07-learn-with-paint-data/PaintData-k-means1.png" alt=""/></p>
<p>Paint Data widget for comparing precision of k-means and hierarchical clustering methods.</p>
<p>Another way to use <strong>Paint Data</strong> is to observe the performance of classification methods, where we can alter the graph to demonstrate improvement or deterioration of prediction models. By painting the data points we can try to construct the data set, which would be difficult for one but easy for another classifier. Say, why does linear SVM fail on the data set below?</p>
<p><img src="/blog/2015-07-learn-with-paint-data/PaintData-TestLearners.png" alt=""/></p>
<p>Use Paint Data to compare prediction quality of several classifiers.</p>
<p>Happy painting!</p></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"AJDA","date":"2015-07-10 07:00:54+00:00","draft":false,"title":"Learn with Paint Data","type":"blog","blog":["classification","clustering","data","examples","plot","visualization"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    strong: \"strong\",\n    img: \"img\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \"Paint Data\"\n      }), \" widget might initially look like a kids’ game, but in combination with other Orange widgets it becomes a very simple and useful tool for conveying statistical concepts, such as \", _jsx(_components.strong, {\n        children: \"k-means\"\n      }), \", \", _jsx(_components.strong, {\n        children: \"hierarchical clustering\"\n      }), \" and \", _jsx(_components.strong, {\n        children: \"prediction models\"\n      }), \" (like SVM, logistical regression, etc.).\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The widget enables you to draw your data on a 2-D plane. You can name the x and y axes, select the number of classes (which are represented by different colors) and then position the points on a graph.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/blog/2015-07-learn-with-paint-data/PaintData-Example.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Several painting tools allow you to manage your data set according to your specific needs; brush will paint several data instances at once, while put allows you paint a single data instance. Select a data subset and view it in the Data Table widget or zoom in to see the position of your points up close. Jitter and magnet are converse tools which allow either to spread the instances or draw them closer together.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The data will be represented in a data table with two attributes, where their instances correspond to coordinates in the system. Such data set is great for demonstrating k-means and hierarchical clustering methods. Just like we do below. In the screenshot we see that k-means, with our particular settings, recognizes clusters way better than hierarchical clustering. It returns a score rank, where the best score (the one with the highest value) means the most likely number of clusters. Hierarchical clustering, however, doesn’t even group the right classes together.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/blog/2015-07-learn-with-paint-data/PaintData-k-means1.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Paint Data widget for comparing precision of k-means and hierarchical clustering methods.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Another way to use \", _jsx(_components.strong, {\n        children: \"Paint Data\"\n      }), \" is to observe the performance of classification methods, where we can alter the graph to demonstrate improvement or deterioration of prediction models. By painting the data points we can try to construct the data set, which would be difficult for one but easy for another classifier. Say, why does linear SVM fail on the data set below?\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/blog/2015-07-learn-with-paint-data/PaintData-TestLearners.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Use Paint Data to compare prediction quality of several classifiers.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Happy painting!\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"learn-with-paint-data"},"buildId":"Z7L00iEto9rZ4XCOOSDzJ","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>