<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-9f90a364d66949ce.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8cfbd06f8ddd0b49.js" defer=""></script><script src="/_next/static/chunks/675-262430aa11afdf01.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-ba4a3f289f8ef3c5.js" defer=""></script><script src="/_next/static/GwUsIp3okGZ01glTrQqIW/_buildManifest.js" defer=""></script><script src="/_next/static/GwUsIp3okGZ01glTrQqIW/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.iBQlkL{background:coral;height:60px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.iBQlkL ul{display:none;}}/*!sc*/
data-styled.g1[id="sc-7295e4c-0"]{content:"iBQlkL,"}/*!sc*/
.bDMZDz{display:none;font-size:22px;margin-left:auto;}/*!sc*/
@media (max-width:920px){.bDMZDz{display:block;}}/*!sc*/
data-styled.g2[id="sc-7295e4c-1"]{content:"bDMZDz,"}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
body{background:#fff;}/*!sc*/
html{box-sizing:border-box;font-size:16px;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
img,video{max-width:100%;height:auto;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g3[id="sc-global-cqyaiF1"]{content:"sc-global-cqyaiF1,"}/*!sc*/
.cGDPDa{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g6[id="sc-f0e62130-0"]{content:"cGDPDa,"}/*!sc*/
</style></head><body><div id="__next"><nav class="sc-7295e4c-0 iBQlkL"><ul><a href="/blog">Blog</a></ul><button class="sc-7295e4c-1 bDMZDz">X</button></nav><main><div class="sc-f0e62130-0 cGDPDa"><h1>Look-alike Images</h1><div class="lg-react-element "><p>There is a cool and perhaps not often used widget in Orange called Neighbors. The widget accepts the data and a reference data item and outputs the nearest neighbors of that item.</p>
<p>Related: <a href="/blog/2018/02/02/image-analytics-workshop-at-aiucd-2018/" target="_blank">Image Analytics Workshop at AIUCD 2018</a></p>
<p>Here I will show how to use it to display a set of images most similar to a selected reference image. I will use the following workflow:</p>
<a href="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-workflow.webp" data-gallery="true"><img srcSet="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-workflow.webp 1x, /blog/2020-01-neighbors-images/2020-01-08-neighbors-images-workflow.webp 2x" src="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-workflow.webp" width="715" height="288" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>\</p>
<p>We may use any collection of images, and for this blog, I have decided to pull out some image sets available from Datasets widget. To use your own collection of images, check out our <a href="https://www.youtube.com/watch?v=Iu8g2Twjn9U">YouTube video on image clustering</a> to see how to prepare it. In the Dataset widget, filter the data sets to list only those that include images:</p>
<a href="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-datasets.webp" data-gallery="true"><img srcSet="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-datasets.webp 1x, /blog/2020-01-neighbors-images/2020-01-08-neighbors-images-datasets.webp 2x" src="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-datasets.webp" width="955" height="458" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p><br/>
<!-- -->\</p>
<p>I will use Bone Healing image set from our recent <a href="https://www.nature.com/articles/s41467-019-12397-x">Nature Communications paper</a>. In the workflow, we first embed the images in the vector space. We send all the embedded images to the Neighbors widget through its input data channel and display them in Image Viewer. In the viewer, we can select an image. Image Viewer sends its output -- the selected image -- to the reference channel of the Neighbors widget. I have instructed this widget to send out three data items that are the most similar to the item in the reference, and on the output excluded the reference item:</p>
<a href="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-neighbors.webp" data-gallery="true"><img srcSet="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-neighbors.webp 1x, /blog/2020-01-neighbors-images/2020-01-08-neighbors-images-neighbors.webp 2x" src="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-neighbors.webp" width="443" height="208" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p><br/>
<!-- -->\</p>
<p>Image Viewer (1) at the end of the pipeline displays three images that are most like the chosen image:</p>
<a href="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-result.webp" data-gallery="true"><img srcSet="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-result.webp 1x, /blog/2020-01-neighbors-images/2020-01-08-neighbors-images-result.webp 2x" src="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-result.webp" width="1064" height="390" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p><br/>
<!-- -->\</p>
<p>Any other set of images works as well. Here is our image look-alike for traffic signs:</p>
<a href="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-bicycles.webp" data-gallery="true"><img srcSet="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-bicycles.webp 1x, /blog/2020-01-neighbors-images/2020-01-08-neighbors-images-bicycles.webp 2x" src="/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-bicycles.webp" width="1071" height="672" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p><br/>
<!-- -->\</p>
<p>We skipped any details on image embedding, measuring distances and so on. For more on these, check out our recent <a href="https://www.nature.com/articles/s41467-019-12397-x">paper in Nature Communications</a> or see our <a href="https://www.youtube.com/watch?v=Iu8g2Twjn9U">set of image analytics videos on YouTube</a>.</p></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"Bla≈æ Zupan","date":"2020-01-08","draft":false,"title":"Look-alike Images","type":"blog","thumbImage":"2020-01-08-neighbors-images-small.png","frontPageImage":"2020-01-08-neighbors-images-small.png","blog":["neighbors","images"],"shortExcerpt":"We show how to use Neighbors widget on image embedding space to find image look-alikes.","longExcerpt":"We show how to use Neighbors widget on image embedding space to find image look-alikes."},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    br: \"br\"\n  }, _provideComponents(), props.components), {LinkNew, Figure} = _components;\n  if (!Figure) _missingMdxReference(\"Figure\", true);\n  if (!LinkNew) _missingMdxReference(\"LinkNew\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"There is a cool and perhaps not often used widget in Orange called Neighbors. The widget accepts the data and a reference data item and outputs the nearest neighbors of that item.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Related: \", _jsx(LinkNew, {\n        url: \"/blog/2018/02/02/image-analytics-workshop-at-aiucd-2018/\",\n        name: \"Image Analytics Workshop at AIUCD 2018\"\n      })]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Here I will show how to use it to display a set of images most similar to a selected reference image. I will use the following workflow:\"\n    }), \"\\n\", _jsx(Figure, {\n      src: \"/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-workflow.png\",\n      width: \"715\",\n      height: \"288\",\n      src: \"/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-workflow.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"\\\\\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We may use any collection of images, and for this blog, I have decided to pull out some image sets available from Datasets widget. To use your own collection of images, check out our \", _jsx(_components.a, {\n        href: \"https://www.youtube.com/watch?v=Iu8g2Twjn9U\",\n        children: \"YouTube video on image clustering\"\n      }), \" to see how to prepare it. In the Dataset widget, filter the data sets to list only those that include images:\"]\n    }), \"\\n\", _jsx(Figure, {\n      src: \"/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-datasets.png\",\n      width: \"955\",\n      height: \"458\",\n      src: \"/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-datasets.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.br, {}), \"\\n\", \"\\\\\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"I will use Bone Healing image set from our recent \", _jsx(_components.a, {\n        href: \"https://www.nature.com/articles/s41467-019-12397-x\",\n        children: \"Nature Communications paper\"\n      }), \". In the workflow, we first embed the images in the vector space. We send all the embedded images to the Neighbors widget through its input data channel and display them in Image Viewer. In the viewer, we can select an image. Image Viewer sends its output -- the selected image -- to the reference channel of the Neighbors widget. I have instructed this widget to send out three data items that are the most similar to the item in the reference, and on the output excluded the reference item:\"]\n    }), \"\\n\", _jsx(Figure, {\n      src: \"/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-neighbors.png\",\n      width: \"443\",\n      height: \"208\",\n      src: \"/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-neighbors.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.br, {}), \"\\n\", \"\\\\\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Image Viewer (1) at the end of the pipeline displays three images that are most like the chosen image:\"\n    }), \"\\n\", _jsx(Figure, {\n      src: \"/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-result.png\",\n      width: \"1064\",\n      height: \"390\",\n      src: \"/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-result.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.br, {}), \"\\n\", \"\\\\\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Any other set of images works as well. Here is our image look-alike for traffic signs:\"\n    }), \"\\n\", _jsx(Figure, {\n      src: \"/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-bicycles.png\",\n      width: \"1071\",\n      height: \"672\",\n      src: \"/blog/2020-01-neighbors-images/2020-01-08-neighbors-images-bicycles.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.br, {}), \"\\n\", \"\\\\\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We skipped any details on image embedding, measuring distances and so on. For more on these, check out our recent \", _jsx(_components.a, {\n        href: \"https://www.nature.com/articles/s41467-019-12397-x\",\n        children: \"paper in Nature Communications\"\n      }), \" or see our \", _jsx(_components.a, {\n        href: \"https://www.youtube.com/watch?v=Iu8g2Twjn9U\",\n        children: \"set of image analytics videos on YouTube\"\n      }), \".\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"look-alike-images"},"buildId":"GwUsIp3okGZ01glTrQqIW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>