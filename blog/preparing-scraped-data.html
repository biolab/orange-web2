<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="true"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-efcb3c938269e030.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bbe7c02f88884f96.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-8a8ec1e433f76884.js" defer=""></script><script src="/_next/static/S5l9rKfq_rDVhPyXKs7au/_buildManifest.js" defer=""></script><script src="/_next/static/S5l9rKfq_rDVhPyXKs7au/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.gdllpa{position:relative;max-width:1440px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;}/*!sc*/
@media (max-width:1130px){.gdllpa{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.gdllpa{padding-left:15px;padding-right:15px;}}/*!sc*/
data-styled.g1[id="sc-bc0cd3d0-0"]{content:"gdllpa,"}/*!sc*/
.bkyaFH{position:relative;display:inline-block;max-width:100%;font-size:20px;line-height:1.25;font-weight:600;-webkit-text-decoration:none;text-decoration:none;color:#fff;padding:10px 15px;border-radius:5px;background-image:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);background-size:100%;cursor:pointer;z-index:100;}/*!sc*/
.bkyaFH:before{content:"";display:block;position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;background-image:linear-gradient(180deg,#ffbc44 100%,#FE7A00 100%);opacity:0;z-index:-100;-webkit-transition:opacity 0.45s;transition:opacity 0.45s;}/*!sc*/
.bkyaFH:hover{color:#fff;}/*!sc*/
.bkyaFH:hover:before{opacity:1;}/*!sc*/
data-styled.g2[id="sc-8c5c4936-0"]{content:"bkyaFH,"}/*!sc*/
.fViuVa{background:#1F1F1F;padding:38px 0 25px;color:#fff;}/*!sc*/
data-styled.g3[id="sc-334e4108-0"]{content:"fViuVa,"}/*!sc*/
.fecJbg{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:80px;margin-bottom:40px;}/*!sc*/
.fecJbg h3{font-size:16px;font-weight:600;margin-bottom:12px;}/*!sc*/
.fecJbg li + li{margin-top:12px;}/*!sc*/
data-styled.g4[id="sc-334e4108-1"]{content:"fecJbg,"}/*!sc*/
.eWdALT{display:none;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:44px;height:34px;padding:6px;border-radius:5px;border:none;background:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);cursor:pointer;margin-left:auto;}/*!sc*/
@media (max-width:920px){.eWdALT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.eWdALT div{width:22px;height:2px;background:#fff;-webkit-transform-origin:1px;-ms-transform-origin:1px;transform-origin:1px;-webkit-transition:all 0.3s linear;transition:all 0.3s linear;}/*!sc*/
data-styled.g5[id="sc-46d6b9d9-0"]{content:"eWdALT,"}/*!sc*/
.jTcDmc{-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;overflow:hidden;position:absolute;white-space:nowrap;width:1px;}/*!sc*/
data-styled.g6[id="sc-cdea7863-0"]{content:"jTcDmc,"}/*!sc*/
.kzEZXJ{position:fixed;top:0;left:0;width:100%;height:80px;z-index:5;background:#fff;box-shadow:0px 4px 10px 4px rgba(0,0,0,0.04);}/*!sc*/
data-styled.g7[id="sc-f2146ecb-0"]{content:"kzEZXJ,"}/*!sc*/
.fBPfPh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;}/*!sc*/
.fBPfPh .img-logo{width:115px;margin-top:18px;}/*!sc*/
data-styled.g8[id="sc-f2146ecb-1"]{content:"fBPfPh,"}/*!sc*/
.uyBkV{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.uyBkV{display:block;position:absolute;top:80px;left:0;width:100%;z-index:1;padding:0 30px 30px;background-color:#fff;opacity:0;z-index:-9999;pointer-events:none;-webkit-transition:opacity 0.3s ease;transition:opacity 0.3s ease;box-shadow:0 4px 10px -1px rgba(0,0,0,0.04);}}/*!sc*/
@media (max-width:720px){.uyBkV{padding:0 15px 15px;}}/*!sc*/
data-styled.g9[id="sc-f2146ecb-2"]{content:"uyBkV,"}/*!sc*/
.hdARHE{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.hdARHE{display:block;margin-bottom:15px;}}/*!sc*/
.hdARHE li + li{margin-left:26px;}/*!sc*/
@media (max-width:920px){.hdARHE li + li{margin-left:0;}}/*!sc*/
.hdARHE a{display:inline-block;font-size:1.25rem;line-height:1;color:#000000;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color 0.3s;transition:color 0.3s;}/*!sc*/
.hdARHE a:hover{color:#FE7A00;}/*!sc*/
@media (max-width:920px){.hdARHE a{padding:8px 0;}}/*!sc*/
data-styled.g10[id="sc-f2146ecb-3"]{content:"hdARHE,"}/*!sc*/
.dJsZoP{position:relative;width:160px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;margin-left:26px;}/*!sc*/
@media (max-width:920px){.dJsZoP{width:auto;margin-left:0;}}/*!sc*/
data-styled.g11[id="sc-f2146ecb-4"]{content:"dJsZoP,"}/*!sc*/
.liGudk{display:inline-block;position:absolute;top:0;right:42px;width:calc(100% - 42px);height:100%;font-size:16px;line-height:1.25;padding:10px 13px;background:#fff;border-radius:5px 0px 0px 5px;border:1px solid #D9D9D9;border-right:none;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;}/*!sc*/
@media (max-width:920px){.liGudk{display:none;}}/*!sc*/
.liGudk::-webkit-input-placeholder{color:#D9D9D9;}/*!sc*/
.liGudk::-moz-placeholder{color:#D9D9D9;}/*!sc*/
.liGudk:-ms-input-placeholder{color:#D9D9D9;}/*!sc*/
.liGudk::placeholder{color:#D9D9D9;}/*!sc*/
data-styled.g12[id="sc-f2146ecb-5"]{content:"liGudk,"}/*!sc*/
.dfDKLD{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;color:#fff;margin-left:auto;-webkit-flex:0 0 42px;-ms-flex:0 0 42px;flex:0 0 42px;height:41px;border:1px solid #474747;border-radius:0px 5px 5px 0px;background-color:#474747;}/*!sc*/
@media (max-width:920px){.dfDKLD{margin-left:0;}}/*!sc*/
data-styled.g13[id="sc-f2146ecb-6"]{content:"dfDKLD,"}/*!sc*/
*,*:before,*:after{box-sizing:border-box;}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
html{font-family:'Source Sans Pro',sans-serif;font-weight:400;color:#000000;}/*!sc*/
body{background:#fff;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
main{padding-top:80px;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
figure{margin:0;}/*!sc*/
img,video{display:block;max-width:100%;height:auto;}/*!sc*/
a{color:unset;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
a:hover{color:unset;}/*!sc*/
strong{font-weight:600;}/*!sc*/
::selection{background-color:#FE7A00;color:#fff;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g14[id="sc-global-hnVSQk1"]{content:"sc-global-hnVSQk1,"}/*!sc*/
.hToqnf{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g17[id="sc-233f3b9d-0"]{content:"hToqnf,"}/*!sc*/
</style><style data-href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@400;600;700&display=swap">@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3aPA.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rAkw.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vAkw.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNa7lujVj9_mf.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qPK7lujVj9_mf.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNK7lujVj9_mf.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qO67lujVj9_mf.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qN67lujVj9_mf.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNq7lujVj9_mf.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7lujVj9w.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmhdu3cOWxy40.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwkxdu3cOWxy40.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmxdu3cOWxy40.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmRdu3cOWxy40.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlxdu3cOWxw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmhdu3cOWxy40.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwkxdu3cOWxy40.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmxdu3cOWxy40.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmRdu3cOWxy40.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlxdu3cOWxw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><nav class="sc-f2146ecb-0 kzEZXJ"><div class="sc-bc0cd3d0-0 gdllpa"><div class="sc-f2146ecb-1 fBPfPh"><a href="/"><img alt="Orange Logo" src="/_next/static/media/logo-orange.4f24b038.svg" width="115" height="33" decoding="async" data-nimg="1" class="img-logo" loading="lazy" style="color:transparent"/></a><div><button aria-label="Toggle navigation" class="sc-46d6b9d9-0 eWdALT"><div></div><div></div><div></div></button><div class="sc-f2146ecb-2 uyBkV"><ul class="sc-f2146ecb-3 hdARHE"><li><a href="/workflows">Workflows</a></li><li><a href="/downloads">Downloads</a></li><li><a href="/blog">Blog</a></li><li><a href="/docs">Docs</a></li><li><a href="/workshops">Workshops</a></li></ul><form class="sc-f2146ecb-4 dJsZoP"><input type="text" placeholder="Search" class="sc-f2146ecb-5 liGudk" value=""/><button type="submit" class="sc-f2146ecb-6 dfDKLD"><img alt="Icon for search" src="/_next/static/media/icon-search.459b2665.svg" width="18" height="17" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/><span class="sc-cdea7863-0 jTcDmc">Search through page</span></button></form></div></div></div></div></nav><main><div class="sc-233f3b9d-0 hToqnf"><h1>Preparing Scraped Data</h1><div class="lg-react-element "><p>One of the key questions of every data analysis is how to get the data and put it in the right form(at). In this post I&#x27;ll show you how to easily get the data from the web and transfer it to a file Orange can read.</p>
<p><strong>Related:</strong> <a href="/blog/2015/08/07/creating-a-new-data-table-in-orange-through-python/">Creating a new data table in Orange through Python</a></p>
<p>First, we&#x27;ll have to do some scripting. We&#x27;ll use a couple of Python libraries - <a href="https://docs.python.org/3.5/library/urllib.request.html">urllib.requests</a> fetching the data, <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> for reading it, <a href="https://docs.python.org/3.5/library/csv.html">csv</a> for writing it and <a href="https://docs.python.org/3.5/library/re.html">regular expressions</a> for extracting the right data.</p>
<pre><code>    from urllib.request import urlopen
    from bs4 import BeautifulSoup
    import csv
    import re
</code></pre>
<p>Ok, we&#x27;ve imported the all the libraries we&#x27;ll need. Now we will scrape the data from our own blog to see how many posts we&#x27;ve written throughout the years.</p>
<pre><code>    html = urlopen(&#x27;http://blog.biolab.si&#x27;)
    soup = BeautifulSoup(html.read(), &#x27;lxml&#x27;)
</code></pre>
<p>The first line opens the address of the site we want to scrape. In our case this is our blog. The second line retrieves a html response from the site, which is our raw text. It looks like this:</p>
<pre><code>    &lt;aside id=&quot;archives-2&quot; class=&quot;widget widget_archive&quot;&gt;&lt;h3 class=&quot;widget-title&quot;&gt;Archives&lt;/h3&gt;
    &lt;ul&gt;
       &lt;li&gt;&lt;a href=&#x27;http://blog.biolab.si/2017/01/&#x27;&gt;January 2017&lt;/a&gt;&amp;nbsp;(1)&lt;/li&gt;
       &lt;li&gt;&lt;a href=&#x27;http://blog.biolab.si/2016/12/&#x27;&gt;December 2016&lt;/a&gt;&amp;nbsp;(3)&lt;/li&gt;
       &lt;li&gt;&lt;a href=&#x27;http://blog.biolab.si/2016/11/&#x27;&gt;November 2016&lt;/a&gt;&amp;nbsp;(4)&lt;/li&gt;
       &lt;li&gt;&lt;a href=&#x27;http://blog.biolab.si/2016/10/&#x27;&gt;October 2016&lt;/a&gt;&amp;nbsp;(3)&lt;/li&gt;
       &lt;li&gt;&lt;a href=&#x27;http://blog.biolab.si/2016/09/&#x27;&gt;September 2016&lt;/a&gt;&amp;nbsp;(2)&lt;/li&gt;
       &lt;li&gt;&lt;a href=&#x27;http://blog.biolab.si/2016/08/&#x27;&gt;August 2016&lt;/a&gt;&amp;nbsp;(5)&lt;/li&gt;
       &lt;li&gt;&lt;a href=&#x27;http://blog.biolab.si/2016/07/&#x27;&gt;July 2016&lt;/a&gt;&amp;nbsp;(3)&lt;/li&gt;....
</code></pre>
<p>Ok, html is nice, but we can&#x27;t really do data analysis with this. We will have to transform this output into something sensible. How about .csv, a simple comma-demilited format Orange can recognize?</p>
<pre><code>    with open(&#x27;scraped.csv&#x27;, &#x27;w&#x27;) as csvfile:
        csvwriter = csv.writer(csvfile, delimiter=&#x27;,&#x27;)
</code></pre>
<p>We created a new file called &#x27;<em>scraped.csv</em>&#x27; to which we will write our content (&#x27;w&#x27; parameter means write). Then we defined the writer and set the delimiter to comma.</p>
<p>Now we need to add the header row, so Orange will know what are the column names. We add this just after csvwriter variable.</p>
<pre><code>    csvwriter.writerow([&quot;Date&quot;, &quot;No_of_Blogs&quot;])
</code></pre>
<p>Now we have two columns, one named &#x27;Date&#x27; and the other &#x27;No_of_Blogs&#x27;. The final step is to extract the data. We have a bunch of lines in html, but the one we&#x27;re interested in is in a section &#x27;aside&#x27; and has an id &#x27;<em>archives-2</em>&#x27;. We will first extract only this section (<em>.find(id=&#x27;archives-2&#x27;</em>) and get all the lines of the archive with the tag &#x27;li&#x27; (<em>.find_all(&#x27;li&#x27;)</em>):</p>
<pre><code>    for item in soup.find(id=&quot;archives-2&quot;).find_all(&#x27;li&#x27;):
</code></pre>
<p>This is the result of <em>print(item)</em>.</p>
<pre><code>    &lt;li&gt;&lt;a href=&quot;http://blog.biolab.si/2017/01/&quot;&gt;January 2017&lt;/a&gt; (1)&lt;/li&gt;
</code></pre>
<p>Now we need to get the actual content from each line. The first part we need is the date of the archived content. Orange can read dates, but they need to come in the right format. We will extract the date from <em>href</em> part with <em>item.a.get(&#x27;href&#x27;)</em>. Then we need to extract only digits from it as we&#x27;re not interested in the rest of the link. We do this with Regex for finding digits:</p>
<pre><code>    date = re.findall(r&#x27;\d+&#x27;, item.a.get(&#x27;href&#x27;))
</code></pre>
<p>Regex&#x27;s <em>findall</em> function returns a list, in our case containing two items - the year and month of archived content. The second part of our data is the number of blogs archived in a particular month. We will again extract this with a Regex digit search, but this time we will be extracting data from the actual content - &#x27;<em>item.contents[1]</em>&#x27;.</p>
<pre><code>    digits = re.findall(r&#x27;\d+&#x27;, item.contents[1])
</code></pre>
<p>Finally, we need to write each line to a .csv file we created above.</p>
<pre><code>    csvwriter.writerow([&quot;%s-%s-01&quot; % (date[0], date[1]), digits[0]])
</code></pre>
<p>Here, we formatted the date into an ISO-standard format Orange recognizes as time variable (<em>&quot;%s-%s-01&quot; % (date[0], date[1])</em>), while the second part is simply a count of our blog posts.</p>
<p>This is the entire code:</p>
<pre><code>    from urllib.request import urlopen
    from bs4 import BeautifulSoup
    import csv
    import re
    
    html = urlopen(&#x27;http://blog.biolab.si&#x27;)
    soup = BeautifulSoup(html.read(), &#x27;lxml&#x27;)
    
    with open(&#x27;scraped.csv&#x27;, &#x27;w&#x27;) as csvfile:
        csvwriter = csv.writer(csvfile, delimiter=&#x27;,&#x27;)
        csvwriter.writerow([&quot;Date&quot;, &quot;No_of_Blogs&quot;])
        for item in soup.find(id=&quot;archives-2&quot;).find_all(&#x27;li&#x27;):
            date = re.findall(r&#x27;\d+&#x27;, item.a.get(&#x27;href&#x27;))
            digits = re.findall(r&#x27;\d+&#x27;, item.contents[1])
            csvwriter.writerow([&quot;%s-%s-01&quot; % (date[0], date[1]), digits[0]])
</code></pre>
<p><strong>Related:</strong> <a href="/blog/2016-06-10-scripting-with-time-variable/">Scripting with Time Variable</a></p>
<p>Now let&#x27;s load this in Orange. File widget can easily read .csv formats and also correctly identifies the two column types, datetime and numeric. A quick glance into the Data Table...</p>
<a href="/blog/2017-01-preparing-scraped-data/__webp-images__/Screen-Shot-2017-01-23-at-12.54.12.webp" data-gallery="true"><img alt="" src="/blog/2017-01-preparing-scraped-data/__webp-images__/Screen-Shot-2017-01-23-at-12.54.12.webp" width="1244" height="1048" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>Everything looks ok. We can use <a href="https://github.com/biolab/orange3-timeseries">Timeseries add-on</a> to inspect how many blogs we&#x27;ve written each month since 2010. Connect <strong>As Timeseries</strong> widget to File. Orange will automatically suggest to use Date as our time variable. Finally, we&#x27;ll plot the data with <strong>Line Chart</strong>. This is the curve of our blog activity.</p>
<a href="/blog/2017-01-preparing-scraped-data/__webp-images__/Screen-Shot-2017-01-23-at-12.54.53.webp" data-gallery="true"><img alt="" src="/blog/2017-01-preparing-scraped-data/__webp-images__/Screen-Shot-2017-01-23-at-12.54.53.webp" width="2222" height="1274" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<a href="/blog/2017-01-preparing-scraped-data/__webp-images__/Screen-Shot-2017-01-23-at-12.55.14.webp" data-gallery="true"><img alt="" src="/blog/2017-01-preparing-scraped-data/__webp-images__/Screen-Shot-2017-01-23-at-12.55.14.webp" width="650" height="374" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>The example is extremely simple. A somewhat proficient user can extract much more interesting data than a simple blog count, but one always needs to keep in mind the legal aspects of web scraping. Nevertheless, this is a popular and fruitful way to extract and explore the data!</p></div></div></main><footer class="sc-334e4108-0 fViuVa"><div class="sc-bc0cd3d0-0 gdllpa"><div class="sc-334e4108-1 fecJbg"><div><h3>Orange</h3><ul><li><a href="/faq">FAQ</a></li><li><a href="/license">License</a></li><li><a href="/privacy">Privacy</a></li><li><a href="/citation">Citation</a></li><li><a href="/contact">Contact</a></li></ul></div><div><h3>Download</h3><ul><li><a href="/download#win">Windows</a></li><li><a href="/download#mac">Mac OS</a></li></ul></div><div><h3>Community</h3><ul><li><a href="https://twitter.com/OrangeDataMiner">Twitter</a></li><li><a href="https://www.facebook.com/orangedatamining">Facebook</a></li><li><a href="https://datascience.stackexchange.com/questions/tagged/orange">Stack Exchange</a></li><li><a href="https://www.youtube.com/channel/UClKKWBe2SCAEyv7ZNGhIe4g">YouTube</a></li><li><a href="https://discord.com/invite/FWrfeXV">Discord</a></li></ul></div><div><h3>Documentation</h3><ul><li><a href="/getting-started">Get started</a></li><li><a href="/widget-catalogue">Widgets</a></li><li><a href="https://orange3.readthedocs.io/projects/orange-data-mining-library/en/latest/">Scripting</a></li></ul></div><div><h3>Developers</h3><ul><li><a href="https://github.com/biolab/orange3">GitHub</a></li><li><a href="http://docs.biolab.si/3/development/">Getting started</a></li></ul></div><div><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=A76TAX87ZVR3J" target="_blank" rel="noreferrer" class="sc-8c5c4936-0 bkyaFH">Donate to Orange</a></div></div><p>Copyright © University of Ljubljana</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"AJDA","date":"2017-01-23 12:29:20+00:00","draft":false,"title":"Preparing Scraped Data","type":"blog","blog":["addons","analysis","data","dataloading","examples","python","scripting"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    strong: \"strong\",\n    a: \"a\",\n    pre: \"pre\",\n    code: \"code\",\n    em: \"em\",\n    img: \"img\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"One of the key questions of every data analysis is how to get the data and put it in the right form(at). In this post I'll show you how to easily get the data from the web and transfer it to a file Orange can read.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \"Related:\"\n      }), \" \", _jsx(_components.a, {\n        href: \"/blog/2015/08/07/creating-a-new-data-table-in-orange-through-python/\",\n        children: \"Creating a new data table in Orange through Python\"\n      })]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"First, we'll have to do some scripting. We'll use a couple of Python libraries - \", _jsx(_components.a, {\n        href: \"https://docs.python.org/3.5/library/urllib.request.html\",\n        children: \"urllib.requests\"\n      }), \" fetching the data, \", _jsx(_components.a, {\n        href: \"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\",\n        children: \"BeautifulSoup\"\n      }), \" for reading it, \", _jsx(_components.a, {\n        href: \"https://docs.python.org/3.5/library/csv.html\",\n        children: \"csv\"\n      }), \" for writing it and \", _jsx(_components.a, {\n        href: \"https://docs.python.org/3.5/library/re.html\",\n        children: \"regular expressions\"\n      }), \" for extracting the right data.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    from urllib.request import urlopen\\n    from bs4 import BeautifulSoup\\n    import csv\\n    import re\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Ok, we've imported the all the libraries we'll need. Now we will scrape the data from our own blog to see how many posts we've written throughout the years.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    html = urlopen('http://blog.biolab.si')\\n    soup = BeautifulSoup(html.read(), 'lxml')\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The first line opens the address of the site we want to scrape. In our case this is our blog. The second line retrieves a html response from the site, which is our raw text. It looks like this:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    \u003caside id=\\\"archives-2\\\" class=\\\"widget widget_archive\\\"\u003e\u003ch3 class=\\\"widget-title\\\"\u003eArchives\u003c/h3\u003e\\n    \u003cul\u003e\\n       \u003cli\u003e\u003ca href='http://blog.biolab.si/2017/01/'\u003eJanuary 2017\u003c/a\u003e\u0026nbsp;(1)\u003c/li\u003e\\n       \u003cli\u003e\u003ca href='http://blog.biolab.si/2016/12/'\u003eDecember 2016\u003c/a\u003e\u0026nbsp;(3)\u003c/li\u003e\\n       \u003cli\u003e\u003ca href='http://blog.biolab.si/2016/11/'\u003eNovember 2016\u003c/a\u003e\u0026nbsp;(4)\u003c/li\u003e\\n       \u003cli\u003e\u003ca href='http://blog.biolab.si/2016/10/'\u003eOctober 2016\u003c/a\u003e\u0026nbsp;(3)\u003c/li\u003e\\n       \u003cli\u003e\u003ca href='http://blog.biolab.si/2016/09/'\u003eSeptember 2016\u003c/a\u003e\u0026nbsp;(2)\u003c/li\u003e\\n       \u003cli\u003e\u003ca href='http://blog.biolab.si/2016/08/'\u003eAugust 2016\u003c/a\u003e\u0026nbsp;(5)\u003c/li\u003e\\n       \u003cli\u003e\u003ca href='http://blog.biolab.si/2016/07/'\u003eJuly 2016\u003c/a\u003e\u0026nbsp;(3)\u003c/li\u003e....\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Ok, html is nice, but we can't really do data analysis with this. We will have to transform this output into something sensible. How about .csv, a simple comma-demilited format Orange can recognize?\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    with open('scraped.csv', 'w') as csvfile:\\n        csvwriter = csv.writer(csvfile, delimiter=',')\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We created a new file called '\", _jsx(_components.em, {\n        children: \"scraped.csv\"\n      }), \"' to which we will write our content ('w' parameter means write). Then we defined the writer and set the delimiter to comma.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now we need to add the header row, so Orange will know what are the column names. We add this just after csvwriter variable.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    csvwriter.writerow([\\\"Date\\\", \\\"No_of_Blogs\\\"])\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Now we have two columns, one named 'Date' and the other 'No_of_Blogs'. The final step is to extract the data. We have a bunch of lines in html, but the one we're interested in is in a section 'aside' and has an id '\", _jsx(_components.em, {\n        children: \"archives-2\"\n      }), \"'. We will first extract only this section (\", _jsx(_components.em, {\n        children: \".find(id='archives-2'\"\n      }), \") and get all the lines of the archive with the tag 'li' (\", _jsx(_components.em, {\n        children: \".find_all('li')\"\n      }), \"):\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    for item in soup.find(id=\\\"archives-2\\\").find_all('li'):\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This is the result of \", _jsx(_components.em, {\n        children: \"print(item)\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    \u003cli\u003e\u003ca href=\\\"http://blog.biolab.si/2017/01/\\\"\u003eJanuary 2017\u003c/a\u003e (1)\u003c/li\u003e\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Now we need to get the actual content from each line. The first part we need is the date of the archived content. Orange can read dates, but they need to come in the right format. We will extract the date from \", _jsx(_components.em, {\n        children: \"href\"\n      }), \" part with \", _jsx(_components.em, {\n        children: \"item.a.get('href')\"\n      }), \". Then we need to extract only digits from it as we're not interested in the rest of the link. We do this with Regex for finding digits:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    date = re.findall(r'\\\\d+', item.a.get('href'))\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Regex's \", _jsx(_components.em, {\n        children: \"findall\"\n      }), \" function returns a list, in our case containing two items - the year and month of archived content. The second part of our data is the number of blogs archived in a particular month. We will again extract this with a Regex digit search, but this time we will be extracting data from the actual content - '\", _jsx(_components.em, {\n        children: \"item.contents[1]\"\n      }), \"'.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    digits = re.findall(r'\\\\d+', item.contents[1])\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Finally, we need to write each line to a .csv file we created above.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    csvwriter.writerow([\\\"%s-%s-01\\\" % (date[0], date[1]), digits[0]])\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Here, we formatted the date into an ISO-standard format Orange recognizes as time variable (\", _jsx(_components.em, {\n        children: \"\\\"%s-%s-01\\\" % (date[0], date[1])\"\n      }), \"), while the second part is simply a count of our blog posts.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This is the entire code:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    from urllib.request import urlopen\\n    from bs4 import BeautifulSoup\\n    import csv\\n    import re\\n    \\n    html = urlopen('http://blog.biolab.si')\\n    soup = BeautifulSoup(html.read(), 'lxml')\\n    \\n    with open('scraped.csv', 'w') as csvfile:\\n        csvwriter = csv.writer(csvfile, delimiter=',')\\n        csvwriter.writerow([\\\"Date\\\", \\\"No_of_Blogs\\\"])\\n        for item in soup.find(id=\\\"archives-2\\\").find_all('li'):\\n            date = re.findall(r'\\\\d+', item.a.get('href'))\\n            digits = re.findall(r'\\\\d+', item.contents[1])\\n            csvwriter.writerow([\\\"%s-%s-01\\\" % (date[0], date[1]), digits[0]])\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \"Related:\"\n      }), \" \", _jsx(_components.a, {\n        href: \"/blog/2016-06-10-scripting-with-time-variable/\",\n        children: \"Scripting with Time Variable\"\n      })]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now let's load this in Orange. File widget can easily read .csv formats and also correctly identifies the two column types, datetime and numeric. A quick glance into the Data Table...\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2017-01-preparing-scraped-data/__webp-images__/Screen-Shot-2017-01-23-at-12.54.12.webp\",\n      alt: \"\",\n      width: \"1244\",\n      height: \"1048\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Everything looks ok. We can use \", _jsx(_components.a, {\n        href: \"https://github.com/biolab/orange3-timeseries\",\n        children: \"Timeseries add-on\"\n      }), \" to inspect how many blogs we've written each month since 2010. Connect \", _jsx(_components.strong, {\n        children: \"As Timeseries\"\n      }), \" widget to File. Orange will automatically suggest to use Date as our time variable. Finally, we'll plot the data with \", _jsx(_components.strong, {\n        children: \"Line Chart\"\n      }), \". This is the curve of our blog activity.\"]\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2017-01-preparing-scraped-data/__webp-images__/Screen-Shot-2017-01-23-at-12.54.53.webp\",\n      alt: \"\",\n      width: \"2222\",\n      height: \"1274\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2017-01-preparing-scraped-data/__webp-images__/Screen-Shot-2017-01-23-at-12.55.14.webp\",\n      alt: \"\",\n      width: \"650\",\n      height: \"374\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The example is extremely simple. A somewhat proficient user can extract much more interesting data than a simple blog count, but one always needs to keep in mind the legal aspects of web scraping. Nevertheless, this is a popular and fruitful way to extract and explore the data!\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"preparing-scraped-data"},"buildId":"S5l9rKfq_rDVhPyXKs7au","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>