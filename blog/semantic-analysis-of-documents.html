<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="true"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-efcb3c938269e030.js" defer=""></script><script src="/_next/static/chunks/pages/_app-949f11068c90eb51.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-8a8ec1e433f76884.js" defer=""></script><script src="/_next/static/KYbjc5GYFTpZZ3WKkutMB/_buildManifest.js" defer=""></script><script src="/_next/static/KYbjc5GYFTpZZ3WKkutMB/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.eWdALT{display:none;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:44px;height:34px;padding:6px;border-radius:5px;border:none;background:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);cursor:pointer;margin-left:auto;}/*!sc*/
@media (max-width:920px){.eWdALT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.eWdALT div{width:22px;height:2px;background:#fff;-webkit-transform-origin:1px;-ms-transform-origin:1px;transform-origin:1px;-webkit-transition:all 0.3s linear;transition:all 0.3s linear;}/*!sc*/
data-styled.g1[id="sc-46d6b9d9-0"]{content:"eWdALT,"}/*!sc*/
.gdllpa{position:relative;max-width:1440px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;}/*!sc*/
@media (max-width:1130px){.gdllpa{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.gdllpa{padding-left:15px;padding-right:15px;}}/*!sc*/
data-styled.g2[id="sc-bc0cd3d0-0"]{content:"gdllpa,"}/*!sc*/
.hbMyDX{position:relative;display:inline-block;max-width:100%;font-size:20px;line-height:1.25;font-weight:600;-webkit-text-decoration:none;text-decoration:none;color:#fff;padding:10px 15px;border-radius:5px;background-image:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);background-size:100%;cursor:pointer;z-index:100;}/*!sc*/
.hbMyDX:before{content:"";display:block;position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;background-image:linear-gradient(180deg,#ffbc44 100%,#FE7A00 100%);opacity:0;z-index:-100;-webkit-transition:opacity 0.45s;transition:opacity 0.45s;}/*!sc*/
.hbMyDX:hover{color:#fff;}/*!sc*/
.hbMyDX:hover:before{opacity:1;}/*!sc*/
data-styled.g3[id="sc-f44c196f-0"]{content:"hbMyDX,"}/*!sc*/
.fNtYgJ{position:fixed;top:0;left:0;width:100%;height:80px;z-index:5;background:#fff;box-shadow:0px 4px 10px 4px rgba(0,0,0,0.04);}/*!sc*/
data-styled.g4[id="sc-3b94eb26-0"]{content:"fNtYgJ,"}/*!sc*/
.cdFZOf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;}/*!sc*/
.cdFZOf .img-logo{width:115px;margin-top:18px;}/*!sc*/
data-styled.g5[id="sc-3b94eb26-1"]{content:"cdFZOf,"}/*!sc*/
.dCamfx{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;width:calc(100% - 115px);padding-left:35px;}/*!sc*/
@media (max-width:920px){.dCamfx{display:block;position:absolute;top:80px;left:0;width:100%;z-index:1;padding:0 30px 30px;background-color:#fff;opacity:0;z-index:-9999;pointer-events:none;-webkit-transition:opacity 0.3s ease;transition:opacity 0.3s ease;box-shadow:0 4px 10px -1px rgba(0,0,0,0.04);}}/*!sc*/
@media (max-width:720px){.dCamfx{padding:0 15px 15px;}}/*!sc*/
data-styled.g6[id="sc-3b94eb26-2"]{content:"dCamfx,"}/*!sc*/
.geJsMM{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.geJsMM{display:block;margin-bottom:15px;}}/*!sc*/
.geJsMM li + li{margin-left:26px;}/*!sc*/
@media (max-width:920px){.geJsMM li + li{margin-left:0;}}/*!sc*/
.geJsMM a{display:inline-block;font-size:1.25rem;line-height:1;color:#000000;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color 0.3s;transition:color 0.3s;}/*!sc*/
.geJsMM a:hover{color:#FE7A00;}/*!sc*/
@media (max-width:920px){.geJsMM a{padding:8px 0;}}/*!sc*/
data-styled.g7[id="sc-3b94eb26-3"]{content:"geJsMM,"}/*!sc*/
.kTFjQX{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.kTFjQX{display:block;}}/*!sc*/
.kTFjQX * + *{margin-left:26px;}/*!sc*/
@media (max-width:920px){.kTFjQX * + *{margin-left:0;margin-top:15px;}}/*!sc*/
data-styled.g8[id="sc-3b94eb26-4"]{content:"kTFjQX,"}/*!sc*/
.hUvfYz{width:100px;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
data-styled.g9[id="sc-8ca87acb-0"]{content:"hUvfYz,"}/*!sc*/
.dSZeYk{width:100%;}/*!sc*/
data-styled.g10[id="sc-8ca87acb-1"]{content:"dSZeYk,"}/*!sc*/
*,*:before,*:after{box-sizing:border-box;}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
html{font-family:'Source Sans Pro',sans-serif;font-weight:400;color:#000000;}/*!sc*/
body{background:#fff;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
main{padding-top:80px;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
figure{margin:0;}/*!sc*/
img,video{display:block;max-width:100%;height:auto;}/*!sc*/
a{color:unset;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
a:hover{color:unset;}/*!sc*/
strong{font-weight:600;}/*!sc*/
::selection{background-color:#FE7A00;color:#fff;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g11[id="sc-global-hnVSQk1"]{content:"sc-global-hnVSQk1,"}/*!sc*/
.jHVHUC{display:block;margin-left:auto;margin-right:auto;}/*!sc*/
data-styled.g12[id="sc-2868d811-0"]{content:"jHVHUC,"}/*!sc*/
.hToqnf{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g14[id="sc-233f3b9d-0"]{content:"hToqnf,"}/*!sc*/
</style><style data-href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@400;600;700&display=swap">@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3aPA.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rAkw.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vAkw.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNa7lujVj9_mf.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qPK7lujVj9_mf.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNK7lujVj9_mf.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qO67lujVj9_mf.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qN67lujVj9_mf.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNq7lujVj9_mf.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7lujVj9w.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmhdu3cOWxy40.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwkxdu3cOWxy40.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmxdu3cOWxy40.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmRdu3cOWxy40.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlxdu3cOWxw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmhdu3cOWxy40.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwkxdu3cOWxy40.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmxdu3cOWxy40.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmRdu3cOWxy40.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlxdu3cOWxw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><nav class="sc-3b94eb26-0 fNtYgJ"><div class="sc-bc0cd3d0-0 gdllpa"><div class="sc-3b94eb26-1 cdFZOf"><a href="/"><img alt="Orange Logo" src="/_next/static/media/logo-orange.4f24b038.svg" width="115" height="33" decoding="async" data-nimg="1" class="img-logo" loading="lazy" style="color:transparent"/></a><button aria-label="Toggle navigation" class="sc-46d6b9d9-0 eWdALT"><div></div><div></div><div></div></button><div class="sc-3b94eb26-2 dCamfx"><ul class="sc-3b94eb26-3 geJsMM"><li><a href="/blog">Blog</a></li><li><a href="/workflows">Workflows</a></li></ul><div class="sc-3b94eb26-4 kTFjQX"><a class="sc-f44c196f-0 hbMyDX">Donate</a><form class="sc-8ca87acb-0 hUvfYz"><input type="text" placeholder="Search" class="sc-8ca87acb-1 dSZeYk" value=""/><button type="submit">Go</button></form></div></div></div></div></nav><main><div class="sc-233f3b9d-0 hToqnf"><h1>Semantic Analysis of Documents</h1><div class="lg-react-element "><p>Our recent project with the Ministry of Public Administration comprises building a <a href="https://nio.gov.si/nio/asset/semanticni+analizator+besedil?lang=en">semantic analysis pipeline in Orange</a>, enabling the users to quickly and efficiently explore the content of documents, compare a subset against the corpus, extract keywords, and semantically explore document maps. If this sounds too vague, don&#x27;t worry, here&#x27;s a quick demo on how to perform semantic analysis in Orange.</p>
<p>First, we will use the pre-prepared corpus of <a href="https://predlagam.vladi.si/">proposals to the government</a>, which you can download <a href="http://file.biolab.si/text-semantics/data/predlogi-vladi-1k.tab">here</a>. These are the initiatives which the citizens of Slovenia propose to the current government for consideration. The present corpus contains 1093 such proposals.</p>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf1.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf1.webp" width="256" height="113" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-corpus.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-corpus.webp" width="605" height="431" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<p>Each proposal contains a title, the content of the proposal, the author, the date when it was published, number of upvotes, and so on. But for a thousand proposals, it would take a long time to read all of them and see which policy areas they cover. Instead, we will use two new Orange widgets to determine the content (main keywords) of a subset of documents.</p>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-corpus-viewer.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-corpus-viewer.webp" width="1207" height="628" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<p>As always, we will first preprocess the corpus to create tokens, the core units of our analysis. The preprocessing pipeline is sequential; first, we lowercase the text, then we split the text into words (this is what the regular expression <code>\w+.</code> does), transform the words into lemmas with UDPipe, and finally remove stopwords from the list (such as &quot;in&quot;, &quot;da&quot;, &quot;če&quot;). Since we are working with a Slovenian language text, we have to select the corresponding models and stopword lists.</p>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf2.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf2.webp" width="254" height="114" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-preprocess-text.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-preprocess-text.webp" width="984" height="1030" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<p>After preprocessing, we build a document-term matrix using the <strong>Bag of Words</strong> widget with the Count+IDF setting. Next, we pass the data to <strong>t-SNE</strong> to observe the document map. t-SNE takes the document-term matrix and finds a 2D projection, where similar documents lie close together.</p>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf3.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf3.webp" width="282" height="112" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-tsne1.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-tsne1.webp" width="2240" height="1456" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<p>Now we will select a small subset of the document, say in the lower right corner, where we have a nice cluster of points. The question is, what are these documents talking about?</p>
<p>We will use <strong>Extract Keywords</strong> widget to find the most significant keywords in the selection. There are several methods we can use, even the popuar <a href="https://repositorio.inesctec.pt/bitstream/123456789/7623/1/P-00N-NF5.pdf">YAKE!</a>, but we will go with a simple TF-IDF method, which takes the words with the highest TF-IDF score. Note that the vectorizer uses the default sklearn&#x27;s <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html">TfidfVectorizer</a> settings, that is the tf-idf transform with L2 norm, keeping the passed tokens as they are.</p>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf4.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf4.webp" width="288" height="118" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-extract-keywords.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-extract-keywords.webp" width="643" height="548" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<p>It looks like the top words characterizing the selected subcorpus are &quot;študent&quot; (<em>student</em>), &quot;delati&quot; (<em>to work</em>), and &quot;delo&quot; (<em>the work</em>). Apparently, the documents talk mostly about student work. Let us explore this a bit further. It would be nice to have a certain score attached to the documents, which would correspond to how much a document talks about student work. In other words, we would like to score the documents based on how many of the selected words they contain (and in what proportion).</p>
<p>To achieve this, we will use <strong>Score Documents</strong>. We will pass it the document-term matrix and the list of selected keywords from <strong>Extract Keywords</strong>. The widget again offers several different ways of scoring documents. A simple way to score them is to compute how often selected words appear in each document, which corresponds to the &quot;Word Count&quot; method.</p>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf5.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf5.webp" width="566" height="218" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-score-documents.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-score-documents.webp" width="1007" height="634" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<p><strong>Score Documents</strong> returns keyword scores for each document. Let us pass the scored documents to another <strong>t-SNE</strong> widget. If we set the color and the size of the points to &quot;Word Count&quot; variable, t-SNE plot will expose the documents with the highest scores. These documents talk the most about students and work. A great thing is that we can see documents with high scores that were not a part of our selection, which means the general bottom-right area contains documents relating to this topic.</p>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-tsne2.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-tsne2.webp" width="1832" height="1160" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<a href="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-workflow.webp" data-gallery="true"><img alt="" src="/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-workflow.webp" width="1734" height="562" decoding="async" data-nimg="1" class="sc-2868d811-0 jHVHUC" loading="lazy" style="color:transparent"/></a>
<p>Now try selecting a different subset yourself and see what the documents are about. You can use any corpus you want, even the ones that come with Orange.</p></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"Ajda Pretnar","date":"2021-09-17","draft":false,"title":"Semantic Analysis of Documents","type":"blog","thumbImage":"2021-09-17-seman.png","frontPageImage":"2021-09-17-seman.png","blog":["semantic analysis","text mining","corpus","keywords"],"shortExcerpt":"How to use Text add-on for semantic analysis of documents.","longExcerpt":"How to use Text add-on to extract keywords from documents, score documents on keywords, and display semantic content in a map.","x2images":true},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    code: \"code\",\n    strong: \"strong\",\n    em: \"em\"\n  }, _provideComponents(), props.components), {WindowScreenshot} = _components;\n  if (!WindowScreenshot) _missingMdxReference(\"WindowScreenshot\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"Our recent project with the Ministry of Public Administration comprises building a \", _jsx(_components.a, {\n        href: \"https://nio.gov.si/nio/asset/semanticni+analizator+besedil?lang=en\",\n        children: \"semantic analysis pipeline in Orange\"\n      }), \", enabling the users to quickly and efficiently explore the content of documents, compare a subset against the corpus, extract keywords, and semantically explore document maps. If this sounds too vague, don't worry, here's a quick demo on how to perform semantic analysis in Orange.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"First, we will use the pre-prepared corpus of \", _jsx(_components.a, {\n        href: \"https://predlagam.vladi.si/\",\n        children: \"proposals to the government\"\n      }), \", which you can download \", _jsx(_components.a, {\n        href: \"http://file.biolab.si/text-semantics/data/predlogi-vladi-1k.tab\",\n        children: \"here\"\n      }), \". These are the initiatives which the citizens of Slovenia propose to the current government for consideration. The present corpus contains 1093 such proposals.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-wf1.png\",\n      width: \"256\",\n      height: \"113\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf1.webp\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-corpus.png\",\n      width: \"605\",\n      height: \"431\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-corpus.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Each proposal contains a title, the content of the proposal, the author, the date when it was published, number of upvotes, and so on. But for a thousand proposals, it would take a long time to read all of them and see which policy areas they cover. Instead, we will use two new Orange widgets to determine the content (main keywords) of a subset of documents.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-corpus-viewer.png\",\n      width: \"1207\",\n      height: \"628\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-corpus-viewer.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"As always, we will first preprocess the corpus to create tokens, the core units of our analysis. The preprocessing pipeline is sequential; first, we lowercase the text, then we split the text into words (this is what the regular expression \", _jsx(_components.code, {\n        children: \"\\\\w+.\"\n      }), \" does), transform the words into lemmas with UDPipe, and finally remove stopwords from the list (such as \\\"in\\\", \\\"da\\\", \\\"če\\\"). Since we are working with a Slovenian language text, we have to select the corresponding models and stopword lists.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-wf2.png\",\n      width: \"254\",\n      height: \"114\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf2.webp\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-preprocess-text.png\",\n      width: \"984\",\n      height: \"1030\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-preprocess-text.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"After preprocessing, we build a document-term matrix using the \", _jsx(_components.strong, {\n        children: \"Bag of Words\"\n      }), \" widget with the Count+IDF setting. Next, we pass the data to \", _jsx(_components.strong, {\n        children: \"t-SNE\"\n      }), \" to observe the document map. t-SNE takes the document-term matrix and finds a 2D projection, where similar documents lie close together.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-wf3.png\",\n      width: \"282\",\n      height: \"112\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf3.webp\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-tsne1.png\",\n      width: \"2240\",\n      height: \"1456\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-tsne1.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now we will select a small subset of the document, say in the lower right corner, where we have a nice cluster of points. The question is, what are these documents talking about?\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We will use \", _jsx(_components.strong, {\n        children: \"Extract Keywords\"\n      }), \" widget to find the most significant keywords in the selection. There are several methods we can use, even the popuar \", _jsx(_components.a, {\n        href: \"https://repositorio.inesctec.pt/bitstream/123456789/7623/1/P-00N-NF5.pdf\",\n        children: \"YAKE!\"\n      }), \", but we will go with a simple TF-IDF method, which takes the words with the highest TF-IDF score. Note that the vectorizer uses the default sklearn's \", _jsx(_components.a, {\n        href: \"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\",\n        children: \"TfidfVectorizer\"\n      }), \" settings, that is the tf-idf transform with L2 norm, keeping the passed tokens as they are.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-wf4.png\",\n      width: \"288\",\n      height: \"118\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf4.webp\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-extract-keywords.png\",\n      width: \"643\",\n      height: \"548\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-extract-keywords.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"It looks like the top words characterizing the selected subcorpus are \\\"študent\\\" (\", _jsx(_components.em, {\n        children: \"student\"\n      }), \"), \\\"delati\\\" (\", _jsx(_components.em, {\n        children: \"to work\"\n      }), \"), and \\\"delo\\\" (\", _jsx(_components.em, {\n        children: \"the work\"\n      }), \"). Apparently, the documents talk mostly about student work. Let us explore this a bit further. It would be nice to have a certain score attached to the documents, which would correspond to how much a document talks about student work. In other words, we would like to score the documents based on how many of the selected words they contain (and in what proportion).\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"To achieve this, we will use \", _jsx(_components.strong, {\n        children: \"Score Documents\"\n      }), \". We will pass it the document-term matrix and the list of selected keywords from \", _jsx(_components.strong, {\n        children: \"Extract Keywords\"\n      }), \". The widget again offers several different ways of scoring documents. A simple way to score them is to compute how often selected words appear in each document, which corresponds to the \\\"Word Count\\\" method.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-wf5.png\",\n      width: \"566\",\n      height: \"218\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-wf5.webp\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-score-documents.png\",\n      width: \"1007\",\n      height: \"634\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-score-documents.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \"Score Documents\"\n      }), \" returns keyword scores for each document. Let us pass the scored documents to another \", _jsx(_components.strong, {\n        children: \"t-SNE\"\n      }), \" widget. If we set the color and the size of the points to \\\"Word Count\\\" variable, t-SNE plot will expose the documents with the highest scores. These documents talk the most about students and work. A great thing is that we can see documents with high scores that were not a part of our selection, which means the general bottom-right area contains documents relating to this topic.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-tsne2.png\",\n      width: \"1832\",\n      height: \"1160\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-tsne2.webp\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-09-semantic-analysis/2021-09-17-workflow.png\",\n      width: \"1734\",\n      height: \"562\",\n      src: \"/blog/2021-09-semantic-analysis/__webp-images__/2021-09-17-workflow.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now try selecting a different subset yourself and see what the documents are about. You can use any corpus you want, even the ones that come with Orange.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"semantic-analysis-of-documents"},"buildId":"KYbjc5GYFTpZZ3WKkutMB","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>