<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="description" content="Orange Data Mining Toolbox"/><meta property="og:description" content="Orange Data Mining Toolbox"/><meta property="og:url" content="https://orangedatamining.com"/><meta property="og:image" content="/_next/static/media/orange-cover.6d606323.png"/><meta property="og:image:width" content="1033"/><meta property="og:image:height" content="626"/><meta property="og:site_name" content="Orange Data Mining"/><meta name="author" content="Bioinformatics Laboratory, University of Ljubljana"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/github.min.css"/><title>Orange Data Mining - GSoC Review: MF - Matrix Factorization Techniques for Data Mining</title><meta name="robots" content="index,follow"/><meta property="og:title" content="Orange Data Mining - GSoC Review: MF - Matrix Factorization Techniques for Data Mining"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2011-09-01 23:48:00+00:00"/><meta property="article:author" content="BIOLAB"/><meta property="article:tag" content="gsoc"/><meta property="article:tag" content="matrixfactorization"/><meta name="next-head-count" content="19"/><link rel="preload" href="/_next/static/media/a9b61b60c2d733b4-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/984cb0988e66ab60.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/984cb0988e66ab60.css" crossorigin="" data-n-g=""/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" crossorigin="" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-21c828b96ad33382.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-0c7baedefba6b077.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-61a1de8ce4711ed8.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-b45dca1ea9268ffb.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/110-f463c991b9377c97.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-44e1b061a1479cde.js" defer="" crossorigin=""></script><script src="/_next/static/6xLEQMyCCK6_CTvfzh5Gh/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/6xLEQMyCCK6_CTvfzh5Gh/_ssgManifest.js" defer="" crossorigin=""></script><style data-styled="" data-styled-version="5.3.6">.eVggRJ{max-width:1296px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;box-sizing:content-box;}/*!sc*/
@media (max-width:1130px){.eVggRJ{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.eVggRJ{padding-left:15px;padding-right:15px;}}/*!sc*/
.CVQuR{max-width:1296px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;box-sizing:content-box;margin-bottom:80px;max-width:714px;}/*!sc*/
@media (max-width:1130px){.CVQuR{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.CVQuR{padding-left:15px;padding-right:15px;}}/*!sc*/
@media (max-width:920px){.CVQuR{margin-bottom:60px;}}/*!sc*/
data-styled.g1[id="sc-61db3aea-0"]{content:"eVggRJ,CVQuR,"}/*!sc*/
.jyxOJT{position:relative;display:inline-block;max-width:100%;font-size:20px;line-height:1.25;font-weight:600;-webkit-text-decoration:none;text-decoration:none;color:#fff;padding:10px 15px;border-radius:5px;background-image:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);background-size:100%;cursor:pointer;z-index:2;}/*!sc*/
@media (max-width:720px){.jyxOJT{font-size:18px;}}/*!sc*/
.jyxOJT:before{content:"";display:block;position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;background-image:linear-gradient(180deg,#ffbc44 100%,#FE7A00 100%);opacity:0;z-index:-100;-webkit-transition:opacity 0.45s;transition:opacity 0.45s;}/*!sc*/
.jyxOJT:hover{color:#fff;}/*!sc*/
.jyxOJT:hover:before{opacity:1;}/*!sc*/
data-styled.g2[id="sc-b6ea565a-0"]{content:"jyxOJT,"}/*!sc*/
.bhDsrC{background:#1F1F1F;padding:38px 0 25px;color:#fff;}/*!sc*/
data-styled.g3[id="sc-62144270-0"]{content:"bhDsrC,"}/*!sc*/
.cLlhlS{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-column-gap:80px;column-gap:80px;row-gap:40px;margin-bottom:40px;}/*!sc*/
@media (max-width:720px){.cLlhlS{display:grid;grid-template-columns:1fr 1fr;-webkit-column-gap:20px;column-gap:20px;}}/*!sc*/
.cLlhlS h3{font-size:16px;font-weight:600;margin-bottom:12px;}/*!sc*/
.cLlhlS li + li{margin-top:12px;}/*!sc*/
data-styled.g4[id="sc-62144270-1"]{content:"cLlhlS,"}/*!sc*/
.eWdALT{display:none;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:44px;height:34px;padding:6px;border-radius:5px;border:none;background:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);cursor:pointer;margin-left:auto;}/*!sc*/
@media (max-width:920px){.eWdALT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.eWdALT div{width:22px;height:2px;background:#fff;-webkit-transform-origin:1px;-ms-transform-origin:1px;transform-origin:1px;-webkit-transition:all 0.3s linear;transition:all 0.3s linear;}/*!sc*/
data-styled.g5[id="sc-46d6b9d9-0"]{content:"eWdALT,"}/*!sc*/
.jTcDmc{-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;overflow:hidden;position:absolute;white-space:nowrap;width:1px;}/*!sc*/
data-styled.g6[id="sc-cdea7863-0"]{content:"jTcDmc,"}/*!sc*/
.VutWK{z-index:100;height:80px;background:#fff;box-shadow:0px 4px 10px 4px rgba(0,0,0,0.04);}/*!sc*/
data-styled.g7[id="sc-fa4dd68d-0"]{content:"VutWK,"}/*!sc*/
.fRVTNh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;}/*!sc*/
.fRVTNh .img-logo{width:115px;}/*!sc*/
data-styled.g8[id="sc-fa4dd68d-1"]{content:"fRVTNh,"}/*!sc*/
.fpwttX{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.fpwttX{display:block;position:absolute;top:80px;left:0;width:100%;z-index:1;padding:0 30px 30px;background-color:#fff;opacity:0;z-index:-9999;pointer-events:none;-webkit-transition:opacity 0.3s ease;transition:opacity 0.3s ease;box-shadow:0 4px 10px -1px rgba(0,0,0,0.04);}}/*!sc*/
@media (max-width:720px){.fpwttX{padding:0 15px 15px;}}/*!sc*/
data-styled.g9[id="sc-fa4dd68d-2"]{content:"fpwttX,"}/*!sc*/
.iNJwOO{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.iNJwOO{display:block;margin-bottom:15px;}}/*!sc*/
.iNJwOO li + li{margin-left:26px;}/*!sc*/
@media (max-width:920px){.iNJwOO li + li{margin-left:0;}}/*!sc*/
.iNJwOO a{display:inline-block;font-size:1.25rem;line-height:1;color:#00000;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color 0.3s;transition:color 0.3s;}/*!sc*/
.iNJwOO a:hover{color:#FE7A00;}/*!sc*/
@media (max-width:920px){.iNJwOO a{padding:8px 0;}}/*!sc*/
data-styled.g10[id="sc-fa4dd68d-3"]{content:"iNJwOO,"}/*!sc*/
.qOxdF{position:relative;width:160px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;margin-left:26px;}/*!sc*/
@media (max-width:920px){.qOxdF{width:auto;margin-left:0;}}/*!sc*/
data-styled.g11[id="sc-fa4dd68d-4"]{content:"qOxdF,"}/*!sc*/
.lhgrCn{display:inline-block;position:absolute;top:0;right:42px;width:calc(100% - 42px);height:100%;font-size:16px;line-height:1.25;padding:10px 13px;background:#fff;border-radius:5px 0px 0px 5px;border:1px solid #D9D9D9;border-right:none;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;}/*!sc*/
@media (max-width:920px){.lhgrCn{display:none;}}/*!sc*/
.lhgrCn::-webkit-input-placeholder{color:#D9D9D9;}/*!sc*/
.lhgrCn::-moz-placeholder{color:#D9D9D9;}/*!sc*/
.lhgrCn:-ms-input-placeholder{color:#D9D9D9;}/*!sc*/
.lhgrCn::placeholder{color:#D9D9D9;}/*!sc*/
data-styled.g12[id="sc-fa4dd68d-5"]{content:"lhgrCn,"}/*!sc*/
.izsUUd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;color:#fff;margin-left:auto;-webkit-flex:0 0 42px;-ms-flex:0 0 42px;flex:0 0 42px;height:41px;border:1px solid #474747;border-radius:0px 5px 5px 0px;background-color:#474747;}/*!sc*/
@media (max-width:920px){.izsUUd{margin-left:0;}}/*!sc*/
data-styled.g13[id="sc-fa4dd68d-6"]{content:"izsUUd,"}/*!sc*/
.eBQFeB{min-height:100vh;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
data-styled.g18[id="sc-da66f971-0"]{content:"eBQFeB,"}/*!sc*/
*,*:before,*:after{box-sizing:border-box;-webkit-font-smoothing:antialiased;}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
html{font-family:'Source Sans Pro',sans-serif;font-weight:400;color:#00000;}/*!sc*/
body{background:#fff;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
main{-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
figure{margin:0;}/*!sc*/
img,video{display:block;max-width:100%;height:auto;}/*!sc*/
a{color:unset;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
a:hover{color:unset;}/*!sc*/
strong{font-weight:600;}/*!sc*/
pre{display:block;padding:15px;margin:0 0 10px;font-size:14px;word-break:break-all;word-wrap:break-word;color:#000;border:1px solid #ebebeb;border-radius:5px;overflow-x:auto;word-wrap:normal;}/*!sc*/
pre code{padding:0 !important;font-size:inherit;color:inherit;white-space:pre-wrap;background-color:transparent;border-radius:0;border:none;line-height:1.35;}/*!sc*/
code{padding:2px 3px;background:#f7f7f7;border:1px solid #ededed;border-radius:0.375rem;display:inline-block;line-height:1.2;margin:0;font-size:78%;}/*!sc*/
::selection{background-color:#FE7A00;color:#fff;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g19[id="sc-global-cZYHqZ1"]{content:"sc-global-cZYHqZ1,"}/*!sc*/
.dpPsin h1{font-size:44px;line-height:1.13;font-weight:700;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.dpPsin h1{font-size:38px;}}/*!sc*/
@media (max-width:720px){.dpPsin h1{font-size:32px;}}/*!sc*/
.dpPsin h2{font-size:33px;line-height:1.13;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.dpPsin h2{font-size:30px;}}/*!sc*/
@media (max-width:720px){.dpPsin h2{font-size:26px;}}/*!sc*/
.dpPsin h3{font-size:28px;line-height:1.18;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.dpPsin h3{font-size:26px;}}/*!sc*/
@media (max-width:720px){.dpPsin h3{font-size:24px;}}/*!sc*/
.dpPsin h4{font-size:22px;line-height:1.18;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:720px){.dpPsin h4{font-size:20px;}}/*!sc*/
.dpPsin p{font-size:20px;line-height:1.4;color:#1F1F1F;}/*!sc*/
@media (max-width:1130px){.dpPsin p{font-size:20px;}}/*!sc*/
@media (max-width:920px){.dpPsin p{font-size:18px;}}/*!sc*/
.dpPsin ul,.dpPsin ol{padding-left:40px;}/*!sc*/
.dpPsin ul li,.dpPsin ol li{font-size:20px;line-height:1.4;color:#1F1F1F;}/*!sc*/
@media (max-width:1130px){.dpPsin ul li,.dpPsin ol li{font-size:20px;}}/*!sc*/
@media (max-width:920px){.dpPsin ul li,.dpPsin ol li{font-size:18px;}}/*!sc*/
.dpPsin ul li + li,.dpPsin ol li + li{margin-top:4px;}/*!sc*/
.dpPsin ul{list-style:disc;}/*!sc*/
.dpPsin ol{list-style:decimal;}/*!sc*/
.dpPsin p a,.dpPsin li a{color:#FE7A00;}/*!sc*/
.dpPsin p a:hover,.dpPsin li a:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.dpPsin * + *:not(li,a,code){margin-top:20px;}/*!sc*/
.dpPsin * + a[data-gallery],.dpPsin * + video{margin-top:40px;}/*!sc*/
.dpPsin a[data-gallery]{display:block;margin-bottom:40px;}/*!sc*/
.dpPsin iframe,.dpPsin video{margin-bottom:40px;}/*!sc*/
data-styled.g24[id="sc-8f0614a2-0"]{content:"dpPsin,"}/*!sc*/
.loxVcf{font-size:62px;line-height:1.04;font-weight:700;color:#fff;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.loxVcf{font-size:50px;}}/*!sc*/
@media (max-width:720px){.loxVcf{font-size:42px;}}/*!sc*/
data-styled.g27[id="sc-c67a4900-0"]{content:"loxVcf,"}/*!sc*/
.dDgGIT{padding:80px 0;}/*!sc*/
@media (max-width:920px){.dDgGIT{padding:60px 0;}}/*!sc*/
@media (max-width:720px){.dDgGIT{padding:40px 0;}}/*!sc*/
data-styled.g30[id="sc-1656ea35-0"]{content:"dDgGIT,"}/*!sc*/
.gAKRba{margin-bottom:30px;}/*!sc*/
data-styled.g31[id="sc-1656ea35-1"]{content:"gAKRba,"}/*!sc*/
.fgUqXj{position:relative;}/*!sc*/
data-styled.g32[id="sc-1656ea35-2"]{content:"fgUqXj,"}/*!sc*/
.gWiuYb{position:absolute;top:0;right:100%;width:200px;margin-right:50px;text-align:right;}/*!sc*/
@media (max-width:1130px){.gWiuYb{position:unset;width:auto;text-align:left;margin:0 0 30px 0;}}/*!sc*/
data-styled.g33[id="sc-1656ea35-3"]{content:"gWiuYb,"}/*!sc*/
.cRMIwp{font-size:20px;line-height:1.25;color:#1F1F1F;text-transform:capitalize;color:#5651EC;}/*!sc*/
@media (max-width:920px){.cRMIwp{font-size:18px;}}/*!sc*/
.gnfHZK{font-size:20px;line-height:1.25;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.gnfHZK{font-size:18px;}}/*!sc*/
data-styled.g34[id="sc-1656ea35-4"]{content:"cRMIwp,gnfHZK,"}/*!sc*/
</style></head><body><div id="__next"><div class="sc-da66f971-0 eBQFeB __className_fa886a"><nav class="sc-fa4dd68d-0 VutWK"><div class="sc-61db3aea-0 eVggRJ"><div class="sc-fa4dd68d-1 fRVTNh"><a href="/"><img alt="Orange Logo" loading="lazy" width="120" height="35" decoding="async" data-nimg="1" class="img-logo" style="color:transparent" src="/_next/static/media/logo-orange.faff1861.svg"/></a><div><button aria-label="Toggle navigation" class="sc-46d6b9d9-0 eWdALT"><div></div><div></div><div></div></button><div class="sc-fa4dd68d-2 fpwttX"><ul class="sc-fa4dd68d-3 iNJwOO"><li><a href="/examples/">Examples</a></li><li><a href="/download/">Download</a></li><li><a href="/blog/">Blog</a></li><li><a href="/docs/">Docs</a></li><li><a href="/workshops/">Workshops</a></li></ul><form class="sc-fa4dd68d-4 qOxdF"><div class="sc-fa4dd68d-5 lhgrCn">Search</div><button class="sc-fa4dd68d-6 izsUUd"><img alt="Icon for search" loading="lazy" width="18" height="17" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/icon-search.459b2665.svg"/><span class="sc-cdea7863-0 jTcDmc">Search through page</span></button></form></div></div></div></div></nav><main><div class="sc-1656ea35-0 dDgGIT"><div class="sc-61db3aea-0 CVQuR"><div class="sc-1656ea35-1 gAKRba"><p class="sc-1656ea35-4 cRMIwp"><strong>gsoc, matrixfactorization</strong></p><h1 class="sc-c67a4900-0 loxVcf">GSoC Review: MF - Matrix Factorization Techniques for Data Mining</h1></div><div class="sc-1656ea35-2 fgUqXj"><div class="sc-1656ea35-3 gWiuYb"><p class="sc-1656ea35-4 gnfHZK"><strong>BIOLAB</strong></p><p class="sc-1656ea35-4 gnfHZK">Sep 01, 2011</p></div><div class="sc-8f0614a2-0 dpPsin"><div class="lg-react-element "><p>MF - Matrix Factorization Techniques for Data Mining is a Python scripting library which includes a number of published matrix factorization algorithms, initialization methods, quality and performance measures and facilitates the combination of these to produce new strategies. The library represents a unified and efficient interface to matrix factorization algorithms and methods.</p>
<p>The MF works with numpy dense matrices and scipy sparse matrices (where this is possible to save on space). The library has support for multiple runs of the algorithms which can be used for some quality measures. By setting runtime specific options tracking the residuals error within one (or more) run or tracking fitted factorization model is possible. Extensive documentation with working examples which demonstrate real applications, commonly used benchmark data and visualization methods are provided to help with the interpretation and comprehension of the results.</p>
<h3>Content of Current Release</h3>
<h4>Factorization Methods</h4>
<ul>
<li>BD - Bayesian nonnegative matrix factorization Gibbs sampler [Schmidt2009]</li>
<li>BMF - Binary matrix factorization [Zhang2007]</li>
<li>ICM - Iterated conditional modes nonnegative matrix factorization [Schmidt2009]</li>
<li>LFNMF - Fisher nonnegative matrix factorization for learning local features [Wang2004], [Li2001]</li>
<li>LSNMF - Alternative nonnegative least squares matrix factorization using projected gradient method for subproblems [Lin2007]</li>
<li>NMF - Standard nonnegative matrix factorization with Euclidean / Kullback-Leibler update equations and Frobenius / divergence / connectivity cost functions [Lee2001], [Brunet2004]</li>
<li>NSNMF - Nonsmooth nonnegative matrix factorization [Montano2006]</li>
<li>PMF - Probabilistic nonnegative matrix factorization [Laurberg2008], [Hansen2008]</li>
<li>PSMF - Probabilistic sparse matrix factorization [Dueck2005], [Dueck2004], [Srebro2001], [Li2007]</li>
<li>SNMF - Sparse nonnegative matrix factorization based on alternating nonnegativity constrained least squares [Park2007]</li>
<li>SNMNMF - Sparse network regularized multiple nonnegative matrix factorization [Zhang2011]</li>
</ul>
<h4>Initialization Methods</h4>
<ul>
<li>Random</li>
<li>Fixed</li>
<li>NNDSVD [Boutsidis2007]</li>
<li>Random C [Albright2006]</li>
<li>Random VCol [Albright2006]</li>
</ul>
<h4>Quality and Performance Measures</h4>
<ul>
<li>Distance</li>
<li>Residuals</li>
<li>Connectivity matrix</li>
<li>Consensus matrix</li>
<li>Entropy of the fitted NMF model [Park2007]</li>
<li>Dominant basis components computation</li>
<li>Explained variance</li>
<li>Feature score computation representing its specificity to basis vectors [Park2007]</li>
<li>Computation of most basis specific features for basis vectors [Park2007]</li>
<li>Purity [Park2007]</li>
<li>Residual sum of squares - can be used for rank estimate [Hutchins2008], [Frigyesi2008]</li>
<li>Sparseness [Hoyer2004]</li>
<li>Cophenetic correlation coefficient of consensus matrix - can be used for rank estimate [Brunet2004]</li>
<li>Dispersion [Park2007]</li>
<li>Factorization rank estimation</li>
<li>Selected matrix factorization method specific</li>
</ul>
<h3>Plans for Future</h3>
<p>General plan for future releases of MF library is to alleviate the usage for non-technical users, increase library stability and provide comprehensive visualization methods. Specifically, in algorithm sense addition of the following could be provided.</p>
<ul>
<li>Extending Bayesian methods with variational BD and linearly constrained BD.</li>
<li>Adaptation of the PMF model to interval-valued matrices.</li>
<li>Nonnegative matrix approximation. Multiplicative iterative schema.</li>
</ul>
<h3>Usage</h3>
<pre><code class="hljs language-python"><span class="hljs-comment"># Import MF library entry point for factorization</span>
<span class="hljs-keyword">import</span> mf

<span class="hljs-keyword">from</span> scipy.sparse <span class="hljs-keyword">import</span> csr_matrix
<span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> array
<span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> dot
<span class="hljs-comment"># We will try to factorize sparse matrix. Construct sparse matrix in CSR format.</span>
V = csr_matrix((array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]),array([<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]),array([<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">6</span>])),shape=(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>))

<span class="hljs-comment"># Run Standard NMF rank 4 algorithm</span>
<span class="hljs-comment"># Returned object is fitted factorization model.</span>
<span class="hljs-comment"># Through it user can access quality and performance measures.</span>
fit = mf.mf(V,method = <span class="hljs-string">&quot;nmf&quot;</span>,max_iter = <span class="hljs-number">30</span>,rank = <span class="hljs-number">4</span>,update = <span class="hljs-string">&#x27;divergence&#x27;</span>,objective = <span class="hljs-string">&#x27;div&#x27;</span>)

<span class="hljs-comment"># Basis matrix. It is sparse, as input V was sparse as well.</span>
W = fit.basis()
<span class="hljs-built_in">print</span> <span class="hljs-string">&quot;Basis matrix\n&quot;</span>, W.todense()

<span class="hljs-comment"># Mixture matrix. We print this tiny matrix in dense format.</span>
H = fit.coef()
<span class="hljs-built_in">print</span> <span class="hljs-string">&quot;Coef\n&quot;</span>, H.todense()

<span class="hljs-comment"># Return the loss function according to Kullback-Leibler divergence.</span>
<span class="hljs-built_in">print</span> <span class="hljs-string">&quot;Distance Kullback-Leibler&quot;</span>, fit.distance(metric = <span class="hljs-string">&quot;kl&quot;</span>)

<span class="hljs-comment"># Compute generic set of measures to evaluate the quality of the factorization</span>
sm = fit.summary()
<span class="hljs-comment"># Print sparseness (Hoyer, 2004) of basis and mixture matrix</span>
<span class="hljs-built_in">print</span> <span class="hljs-string">&quot;Sparseness W: %5.3f  H: %5.3f&quot;</span> % (sm[<span class="hljs-string">&#x27;sparseness&#x27;</span>][<span class="hljs-number">0</span>], sm[<span class="hljs-string">&#x27;sparseness&#x27;</span>][<span class="hljs-number">1</span>])
<span class="hljs-comment"># Print actual number of iterations performed</span>
<span class="hljs-built_in">print</span> <span class="hljs-string">&quot;Iterations&quot;</span>, sm[<span class="hljs-string">&#x27;n_iter&#x27;</span>]

<span class="hljs-comment"># Print estimate of target matrix V</span>
<span class="hljs-built_in">print</span> <span class="hljs-string">&quot;Estimate\n&quot;</span>, dot(W.todense(), H.todense())
</code></pre>
<h3>Examples</h3>
<p>Examples with visualized results in bioinformatics, image processing, text analysis, recommendation systems are provided in <a href="http://helikoid.si/mf/">Examples section of Documentation.</a></p>
<p>Figure 1: Reordered consensus matrix generated for rank = 2 on Leukemia data set.</p>
<a href="/blog/2011-09-gsoc-review-mf-matrix-factorization-techniques-for-data-mining/__optimized-images__/all_aml_consensus2.png__160x160_q95_crop.png" data-gallery="true"><img alt="" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" style="color:transparent" src="/blog/2011-09-gsoc-review-mf-matrix-factorization-techniques-for-data-mining/__optimized-images__/all_aml_consensus2.png__160x160_q95_crop.png"/></a>
<p>Figure 2: Interpretation of NMF - Divergence basis vectors on Medlars data set. By considering the highest weighted terms in this vector, we can assign a label or topic to basis vector W1, a user might attach the label liver to basis vector W1.</p>
<a href="/blog/2011-09-gsoc-review-mf-matrix-factorization-techniques-for-data-mining/__optimized-images__/documents_basisw1.png__160x160_q95_crop.png" data-gallery="true"><img alt="" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" style="color:transparent" src="/blog/2011-09-gsoc-review-mf-matrix-factorization-techniques-for-data-mining/__optimized-images__/documents_basisw1.png__160x160_q95_crop.png"/></a>
<p>Figure 3: Basis images of LSNMF obtained after 500 iterations on original face images. The bases trained by LSNMF are additive but not spatially localized for representation of faces.</p>
<a href="/blog/2011-09-gsoc-review-mf-matrix-factorization-techniques-for-data-mining/__optimized-images__/orl_faces_500_iters_large_lsnmf.png__160x160_q95_crop.png" data-gallery="true"><img alt="" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" style="color:transparent" src="/blog/2011-09-gsoc-review-mf-matrix-factorization-techniques-for-data-mining/__optimized-images__/orl_faces_500_iters_large_lsnmf.png__160x160_q95_crop.png"/></a>
<h3>Relevant Links</h3>
<ul>
<li><a href="http://helikoid.si/mf/">Extensive published documentation with examples</a></li>
<li><a href="http://orange.biolab.si/trac/wiki/MatrixFactorization">Orange wiki MF Project page</a></li>
<li><a href="https://github.com/marinkaz/mf">Github repository with source code</a></li>
<li><a href="http://helikoid.si/mf/GSoC_MF.pdf">Short presentation in pdf format of MF library</a></li>
</ul></div></div></div></div></div></main><footer class="sc-62144270-0 bhDsrC"><div class="sc-61db3aea-0 eVggRJ"><div class="sc-62144270-1 cLlhlS"><div><h3>Orange</h3><ul><li><a href="/faq/">FAQ</a></li><li><a href="/license/">License</a></li><li><a href="/privacy/">Privacy</a></li><li><a href="/citation/">Citation</a></li><li><a href="/contact/">Contact</a></li></ul></div><div><h3>Download</h3><ul><li><a href="/download/#win">Windows</a></li><li><a href="/download/#mac">Mac OS</a></li></ul></div><div><h3>Community</h3><ul><li><a href="https://twitter.com/OrangeDataMiner">Twitter</a></li><li><a href="https://www.facebook.com/orangedatamining">Facebook</a></li><li><a href="https://datascience.stackexchange.com/questions/tagged/orange">Stack Exchange</a></li><li><a href="https://www.youtube.com/channel/UClKKWBe2SCAEyv7ZNGhIe4g">YouTube</a></li><li><a href="https://discord.com/invite/FWrfeXV">Discord</a></li></ul></div><div><h3>Documentation</h3><ul><li><a href="/getting-started/">Get started</a></li><li><a href="/widget-catalogue/">Widgets</a></li><li><a href="https://orange3.readthedocs.io/projects/orange-data-mining-library/en/latest/">Scripting</a></li></ul></div><div><h3>Developers</h3><ul><li><a href="https://github.com/biolab/orange3">GitHub</a></li><li><a href="http://docs.biolab.si/3/development/">Getting started</a></li></ul></div><div><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=A76TAX87ZVR3J" target="_blank" rel="noreferrer" class="sc-b6ea565a-0 jyxOJT">Donate to Orange</a></div></div><p>Copyright Â© University of Ljubljana</p></div></footer></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"frontmatter":{"author":"BIOLAB","date":"2011-09-01 23:48:00+00:00","draft":false,"title":"GSoC Review: MF - Matrix Factorization Techniques for Data Mining","blog":["gsoc","matrixfactorization"],"oldUrl":"/blog/2011/09/01/gsoc-review-mf-matrix-factorization-techniques-for-data-mining/"},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    h3: \"h3\",\n    h4: \"h4\",\n    ul: \"ul\",\n    li: \"li\",\n    pre: \"pre\",\n    code: \"code\",\n    span: \"span\",\n    a: \"a\",\n    img: \"img\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"MF - Matrix Factorization Techniques for Data Mining is a Python scripting library which includes a number of published matrix factorization algorithms, initialization methods, quality and performance measures and facilitates the combination of these to produce new strategies. The library represents a unified and efficient interface to matrix factorization algorithms and methods.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The MF works with numpy dense matrices and scipy sparse matrices (where this is possible to save on space). The library has support for multiple runs of the algorithms which can be used for some quality measures. By setting runtime specific options tracking the residuals error within one (or more) run or tracking fitted factorization model is possible. Extensive documentation with working examples which demonstrate real applications, commonly used benchmark data and visualization methods are provided to help with the interpretation and comprehension of the results.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Content of Current Release\"\n    }), \"\\n\", _jsx(_components.h4, {\n      children: \"Factorization Methods\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"BD - Bayesian nonnegative matrix factorization Gibbs sampler [Schmidt2009]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"BMF - Binary matrix factorization [Zhang2007]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"ICM - Iterated conditional modes nonnegative matrix factorization [Schmidt2009]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"LFNMF - Fisher nonnegative matrix factorization for learning local features [Wang2004], [Li2001]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"LSNMF - Alternative nonnegative least squares matrix factorization using projected gradient method for subproblems [Lin2007]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"NMF - Standard nonnegative matrix factorization with Euclidean / Kullback-Leibler update equations and Frobenius / divergence / connectivity cost functions [Lee2001], [Brunet2004]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"NSNMF - Nonsmooth nonnegative matrix factorization [Montano2006]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"PMF - Probabilistic nonnegative matrix factorization [Laurberg2008], [Hansen2008]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"PSMF - Probabilistic sparse matrix factorization [Dueck2005], [Dueck2004], [Srebro2001], [Li2007]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"SNMF - Sparse nonnegative matrix factorization based on alternating nonnegativity constrained least squares [Park2007]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"SNMNMF - Sparse network regularized multiple nonnegative matrix factorization [Zhang2011]\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h4, {\n      children: \"Initialization Methods\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Random\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Fixed\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"NNDSVD [Boutsidis2007]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Random C [Albright2006]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Random VCol [Albright2006]\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h4, {\n      children: \"Quality and Performance Measures\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Distance\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Residuals\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Connectivity matrix\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Consensus matrix\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Entropy of the fitted NMF model [Park2007]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Dominant basis components computation\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Explained variance\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Feature score computation representing its specificity to basis vectors [Park2007]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Computation of most basis specific features for basis vectors [Park2007]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Purity [Park2007]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Residual sum of squares - can be used for rank estimate [Hutchins2008], [Frigyesi2008]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Sparseness [Hoyer2004]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Cophenetic correlation coefficient of consensus matrix - can be used for rank estimate [Brunet2004]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Dispersion [Park2007]\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Factorization rank estimation\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Selected matrix factorization method specific\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Plans for Future\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"General plan for future releases of MF library is to alleviate the usage for non-technical users, increase library stability and provide comprehensive visualization methods. Specifically, in algorithm sense addition of the following could be provided.\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Extending Bayesian methods with variational BD and linearly constrained BD.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Adaptation of the PMF model to interval-valued matrices.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Nonnegative matrix approximation. Multiplicative iterative schema.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Usage\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-python\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Import MF library entry point for factorization\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" mf\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" scipy.sparse \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" csr_matrix\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" scipy \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" array\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" numpy \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" dot\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# We will try to factorize sparse matrix. Construct sparse matrix in CSR format.\"\n        }), \"\\nV = csr_matrix((array([\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"2\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"3\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"4\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"5\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"6\"\n        }), \"]),array([\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"2\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"2\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"2\"\n        }), \"]),array([\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"2\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"3\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"6\"\n        }), \"])),shape=(\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"3\"\n        }), \",\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"3\"\n        }), \"))\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Run Standard NMF rank 4 algorithm\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Returned object is fitted factorization model.\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Through it user can access quality and performance measures.\"\n        }), \"\\nfit = mf.mf(V,method = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"nmf\\\"\"\n        }), \",max_iter = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"30\"\n        }), \",rank = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"4\"\n        }), \",update = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'divergence'\"\n        }), \",objective = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'div'\"\n        }), \")\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Basis matrix. It is sparse, as input V was sparse as well.\"\n        }), \"\\nW = fit.basis()\\n\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"print\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"Basis matrix\\\\n\\\"\"\n        }), \", W.todense()\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Mixture matrix. We print this tiny matrix in dense format.\"\n        }), \"\\nH = fit.coef()\\n\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"print\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"Coef\\\\n\\\"\"\n        }), \", H.todense()\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Return the loss function according to Kullback-Leibler divergence.\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"print\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"Distance Kullback-Leibler\\\"\"\n        }), \", fit.distance(metric = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"kl\\\"\"\n        }), \")\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Compute generic set of measures to evaluate the quality of the factorization\"\n        }), \"\\nsm = fit.summary()\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Print sparseness (Hoyer, 2004) of basis and mixture matrix\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"print\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"Sparseness W: %5.3f  H: %5.3f\\\"\"\n        }), \" % (sm[\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'sparseness'\"\n        }), \"][\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"], sm[\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'sparseness'\"\n        }), \"][\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1\"\n        }), \"])\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Print actual number of iterations performed\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"print\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"Iterations\\\"\"\n        }), \", sm[\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'n_iter'\"\n        }), \"]\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Print estimate of target matrix V\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"print\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"Estimate\\\\n\\\"\"\n        }), \", dot(W.todense(), H.todense())\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Examples\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Examples with visualized results in bioinformatics, image processing, text analysis, recommendation systems are provided in \", _jsx(_components.a, {\n        href: \"http://helikoid.si/mf/\",\n        children: \"Examples section of Documentation.\"\n      })]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Figure 1: Reordered consensus matrix generated for rank = 2 on Leukemia data set.\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2011-09-gsoc-review-mf-matrix-factorization-techniques-for-data-mining/__optimized-images__/all_aml_consensus2.png__160x160_q95_crop.png\",\n      alt: \"\",\n      width: \"160\",\n      height: \"160\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Figure 2: Interpretation of NMF - Divergence basis vectors on Medlars data set. By considering the highest weighted terms in this vector, we can assign a label or topic to basis vector W1, a user might attach the label liver to basis vector W1.\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2011-09-gsoc-review-mf-matrix-factorization-techniques-for-data-mining/__optimized-images__/documents_basisw1.png__160x160_q95_crop.png\",\n      alt: \"\",\n      width: \"160\",\n      height: \"160\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Figure 3: Basis images of LSNMF obtained after 500 iterations on original face images. The bases trained by LSNMF are additive but not spatially localized for representation of faces.\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2011-09-gsoc-review-mf-matrix-factorization-techniques-for-data-mining/__optimized-images__/orl_faces_500_iters_large_lsnmf.png__160x160_q95_crop.png\",\n      alt: \"\",\n      width: \"160\",\n      height: \"160\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Relevant Links\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"http://helikoid.si/mf/\",\n          children: \"Extensive published documentation with examples\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"http://orange.biolab.si/trac/wiki/MatrixFactorization\",\n          children: \"Orange wiki MF Project page\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://github.com/marinkaz/mf\",\n          children: \"Github repository with source code\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"http://helikoid.si/mf/GSoC_MF.pdf\",\n          children: \"Short presentation in pdf format of MF library\"\n        })\n      }), \"\\n\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}},"thumbImage":null},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"gsoc-review-mf-matrix-factorization-techniques-for-data-mining"},"buildId":"6xLEQMyCCK6_CTvfzh5Gh","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>