<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-9f90a364d66949ce.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8cfbd06f8ddd0b49.js" defer=""></script><script src="/_next/static/chunks/675-262430aa11afdf01.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-fd50a1465d8f452c.js" defer=""></script><script src="/_next/static/MdneM3OWGZMTOR1krVaKX/_buildManifest.js" defer=""></script><script src="/_next/static/MdneM3OWGZMTOR1krVaKX/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.iBQlkL{background:coral;height:60px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.iBQlkL ul{display:none;}}/*!sc*/
data-styled.g1[id="sc-7295e4c-0"]{content:"iBQlkL,"}/*!sc*/
.bDMZDz{display:none;font-size:22px;margin-left:auto;}/*!sc*/
@media (max-width:920px){.bDMZDz{display:block;}}/*!sc*/
data-styled.g2[id="sc-7295e4c-1"]{content:"bDMZDz,"}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
body{background:#fff;}/*!sc*/
html{box-sizing:border-box;font-size:16px;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
img,video{max-width:100%;height:auto;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g3[id="sc-global-cqyaiF1"]{content:"sc-global-cqyaiF1,"}/*!sc*/
.gndEvh{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g6[id="sc-6329e001-0"]{content:"gndEvh,"}/*!sc*/
</style></head><body><div id="__next"><nav class="sc-7295e4c-0 iBQlkL"><ul><a href="/blog">Blog</a></ul><button class="sc-7295e4c-1 bDMZDz">X</button></nav><main><div class="sc-6329e001-0 gndEvh"><h1>Faster classification and regression trees</h1><div class="lg-react-element "><p><strong>SimpleTreeLearner</strong> is an implementation of classification and regression trees that sacrifices flexibility for speed. A benchmark on 42 different datasets reveals that <strong>SimpleTreeLearner</strong> is <strong>11 times faster</strong> than the original <strong>TreeLearner</strong>.</p>
<p>The motivation behind developing a new tree induction algorithm from scratch was to speed up the construction of random forests, but you can also use it as a standalone learner. <strong>SimpleTreeLearner</strong> uses gain ratio for classification and MSE for regression and can handle unknown values.</p>
<h3>Comparison with TreeLearner</h3>
<p>The graph below shows <strong>SimpleTreeLearner</strong> construction times on datasets bundled with Orange normalized to <strong>TreeLearner</strong>. Smaller is better.</p>
<p><img src="/blog/2011-08-faster-classification-and-regression-trees/simpletree_speed.png__600x641_q95_crop_upscale.png" alt=""/></p>
<p>The harmonic mean (average speedup) on all the benchmarks is 11.4.</p>
<h3>Usage</h3>
<p>The user can set four parameters:</p>
<p><strong>maxMajority</strong></p>
<p>Maximal proportion of majority class.</p>
<p><strong>minExamples</strong></p>
<p>Minimal number of examples in leaves.</p>
<p><strong>maxDepth</strong></p>
<p>Maximal depth of tree.</p>
<p><strong>skipProb</strong></p>
<p>At every split an attribute will be skipped with probability skipProb. This parameter is especially useful for building random forests.</p>
<p>The code snippet below demonstrates the basic usage of <strong>SimpleTreeLearner</strong>. It behaves much like any other Orange learner would.</p>
<pre><code>    import Orange

    data = Orange.data.Table(&quot;iris&quot;)

    # build classifier and classify train data
    classifier = Orange.classification.tree.SimpleTreeLearner(data, maxMajority=0.8)
    for ex in data:
        print classifier(ex)

    # estimate classification accuracy with cross-validation
    learner = Orange.classification.tree.SimpleTreeLearner(minExamples=2)
    result = Orange.evaluation.testing.cross_validation([learner], data)
    print &#x27;CA:&#x27;, Orange.evaluation.scoring.CA(result)[0]
</code></pre></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"BIOLAB","date":"2011-08-24 22:26:00+00:00","draft":false,"title":"Faster classification and regression trees","type":"blog","blog":["classification","regression","tree"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    strong: \"strong\",\n    h3: \"h3\",\n    img: \"img\",\n    pre: \"pre\",\n    code: \"code\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \"SimpleTreeLearner\"\n      }), \" is an implementation of classification and regression trees that sacrifices flexibility for speed. A benchmark on 42 different datasets reveals that \", _jsx(_components.strong, {\n        children: \"SimpleTreeLearner\"\n      }), \" is \", _jsx(_components.strong, {\n        children: \"11 times faster\"\n      }), \" than the original \", _jsx(_components.strong, {\n        children: \"TreeLearner\"\n      }), \".\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The motivation behind developing a new tree induction algorithm from scratch was to speed up the construction of random forests, but you can also use it as a standalone learner. \", _jsx(_components.strong, {\n        children: \"SimpleTreeLearner\"\n      }), \" uses gain ratio for classification and MSE for regression and can handle unknown values.\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Comparison with TreeLearner\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The graph below shows \", _jsx(_components.strong, {\n        children: \"SimpleTreeLearner\"\n      }), \" construction times on datasets bundled with Orange normalized to \", _jsx(_components.strong, {\n        children: \"TreeLearner\"\n      }), \". Smaller is better.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/blog/2011-08-faster-classification-and-regression-trees/simpletree_speed.png__600x641_q95_crop_upscale.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The harmonic mean (average speedup) on all the benchmarks is 11.4.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Usage\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The user can set four parameters:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.strong, {\n        children: \"maxMajority\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Maximal proportion of majority class.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.strong, {\n        children: \"minExamples\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Minimal number of examples in leaves.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.strong, {\n        children: \"maxDepth\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Maximal depth of tree.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.strong, {\n        children: \"skipProb\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"At every split an attribute will be skipped with probability skipProb. This parameter is especially useful for building random forests.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The code snippet below demonstrates the basic usage of \", _jsx(_components.strong, {\n        children: \"SimpleTreeLearner\"\n      }), \". It behaves much like any other Orange learner would.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    import Orange\\n\\n    data = Orange.data.Table(\\\"iris\\\")\\n\\n    # build classifier and classify train data\\n    classifier = Orange.classification.tree.SimpleTreeLearner(data, maxMajority=0.8)\\n    for ex in data:\\n        print classifier(ex)\\n\\n    # estimate classification accuracy with cross-validation\\n    learner = Orange.classification.tree.SimpleTreeLearner(minExamples=2)\\n    result = Orange.evaluation.testing.cross_validation([learner], data)\\n    print 'CA:', Orange.evaluation.scoring.CA(result)[0]\\n\"\n      })\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"faster-classification-and-regression-trees"},"buildId":"MdneM3OWGZMTOR1krVaKX","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>