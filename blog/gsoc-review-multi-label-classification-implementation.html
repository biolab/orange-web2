<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-45fae5f2ec2ec297.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-abafce5311b78c60.js" defer=""></script><script src="/_next/static/chunks/pages/_app-463eea64dd46fd78.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-9737114052c0c44f.js" defer=""></script><script src="/_next/static/Pq4MTEXwxi3akD3CFvrRB/_buildManifest.js" defer=""></script><script src="/_next/static/Pq4MTEXwxi3akD3CFvrRB/_ssgManifest.js" defer=""></script></head><body><div id="__next"><nav class="navbar__Nav-sc-q11qw3-0 hZTkcw"><ul><a href="/blog">Blog</a></ul><button class="navbar__Burger-sc-q11qw3-1 cGMLJw">X</button></nav><main><div class="slug__Wrapper-sc-1xtdpf8-0 cHTstd"><h1>GSoC Review: Multi-label Classification Implementation</h1><p>Traditional single-label classification is concerned with learning from a set of examples that are associated with a single label <strong>l</strong> from a set of disjoint labels <strong>L</strong>, <strong>|L|</strong> &gt; <strong>1</strong>. If <strong>|L|</strong> = <strong>2</strong>, then the learning problem is called a binary classification problem, while if <strong>|L|</strong> &gt; <strong>2</strong>, then it is called a multi-class classification problem (Tsoumakas &amp; Katakis, 2007).</p>
<p>Multi-label classification methods are increasingly used by many applications, such as textual data classification, protein function classification, music categorization and semantic scene classification. However, currently, Orange can only handle single-label problems. As a result, the project <em>Multi-label classification Implementation</em> has been proposed to extend Orange to support multi-label.</p>
<p>We can group the existing methods for multi-label classification into two main categories: a) problem transformation method, and b) algorithm adaptation methods. In the former one, multi-label problems are converted to single-label, and then the traditional binary classification can apply; in the latter case, methods directly classify the multi-label data, instead.</p>
<p>In this project, two transformation methods and two algorithm adaptation methods are implemented. Along with the methods, their widgets are also added. As the evaluation metrics for multi-label data are different from the single-label ones, new evaluation measures are supported. The code is available in <a href="http://orange.biolab.si/trac/intertrac/browser%3Abranches/multilabel">SVN branch</a>.</p>
<p>Fortunately, benefiting from the Tab file format, the <strong>ExampleTable</strong> can store multi-label data without any modification. Now, we can add a special value – <strong>label</strong> into the <strong>attributes</strong> dictionary of the domain with value 1. In this way, if the attribute description has the keyword <strong>label</strong>, then it is a label; otherwise, it is a normal feature.</p>
<h3>What have been done in this project</h3>
<h4>Transformation methods</h4>
<ul>
<li>br – Binary Relevance Learner (Tsoumakas &amp; Katakis, 2007)</li>
<li>lp – Label Powerset Classification (Tsoumakas &amp; Katakis, 2007)</li>
</ul>
<h4>Algorithm Adaptation methods</h4>
<ul>
<li>mlknn – Multi-kNN Classification (Zhang &amp; Zhou, 2007)</li>
<li>brknn – BR-kNN Classification (Spyromitros et al. 2008)</li>
</ul>
<h4>Evaluation methods</h4>
<ul>
<li>mlc_hamming_loss – Example-based Hamming Loss (Schapire and Singer 2000)</li>
<li>mlc_accuracy, mlc_precision, mlc_recall – Example-based accuracy, precision, recall (Godbole &amp; Sarawagi, 2004)</li>
</ul>
<h4>Widgets</h4>
<ul>
<li>OWBR – Widget for Binary Relevance Learner</li>
<li>OWLP – Widget for Label Powerset Classification</li>
<li>OWMLkNN – Widget for Multi-kNN Classification</li>
<li>OWBRkNN – Widget for BR-kNN Classification</li>
<li>OWTestLearner – Widget for Evaluation</li>
</ul>
<h4>File Format Extension</h4>
<ul>
<li>extend the loadARFF function to support sparse Weka format</li>
<li>new support <a href="http://mulan.sourceforge.net/format.html">mulan xml and arff format</a></li>
</ul>
<h3>Plan for the future</h3>
<ul>
<li>add more classification methods for multi-label, such as PT1 to PT6</li>
<li>add feature extraction method</li>
<li>add ranking-based evaluation methods</li>
</ul>
<h3>How to use</h3>
<p>Basically, the way to use multi-label classification and evaluation is nearly the same as the single-label ones. The only difference between them is the different types of input data.</p>
<h4>Example for Classification</h4>
<pre><code>    import Orange

    data = Orange.data.Table(&quot;emotions.tab&quot;)

    classifier = Orange.multilabel.BinaryRelevanceLearner(data)

    for e in data:
        c,p = classifier(e,Orange.classification.Classifier.GetBoth)
        print c,p

    powerset_cliassifer = Orange.multilabel.LabelPowersetLearner(data)
    for e in data:
        c,p = powerset_cliassifer(e,Orange.classification.Classifier.GetBoth)
        print c,p

    mlknn_cliassifer = Orange.multilabel.MLkNNLearner(data,k=1)
    for e in data:
        c,p = mlknn_cliassifer(e,Orange.classification.Classifier.GetBoth)
        print c,p
       
    br_cliassifer = Orange.multilabel.BRkNNLearner(data,k=1)
    for e in data:
        c,p = br_cliassifer(e,Orange.classification.Classifier.GetBoth)
        print c,p
</code></pre>
<h4>Example for Evaluation</h4>
<pre><code>    import Orange

    learners = [
        Orange.multilabel.BinaryRelevanceLearner(name=&quot;br&quot;),
        Orange.multilabel.BinaryRelevanceLearner(name=&quot;br&quot;, \
            base_learner=Orange.classification.knn.kNNLearner),
        Orange.multilabel.LabelPowersetLearner(name=&quot;lp&quot;),
        Orange.multilabel.LabelPowersetLearner(name=&quot;lp&quot;, \
            base_learner=Orange.classification.knn.kNNLearner),
        Orange.multilabel.MLkNNLearner(name=&quot;mlknn&quot;,k=5),
        Orange.multilabel.BRkNNLearner(name=&quot;brknn&quot;,k=5),
    ]

    data = Orange.data.Table(&quot;emotions.xml&quot;)

    res = Orange.evaluation.testing.cross_validation(learners, data,2)
    loss = Orange.evaluation.scoring.mlc_hamming_loss(res)
    accuracy = Orange.evaluation.scoring.mlc_accuracy(res)
    precision = Orange.evaluation.scoring.mlc_precision(res)
    recall = Orange.evaluation.scoring.mlc_recall(res)
    print &#x27;loss=&#x27;, loss
    print &#x27;accuracy=&#x27;, accuracy
    print &#x27;precision=&#x27;, precision
    print &#x27;recall=&#x27;, recall
</code></pre>
<h3>References</h3>
<ul>
<li>G. Tsoumakas and I. Katakis. <em>Multi-label classification: An overview&quot;. International Journal of Data Warehousing and Mining, 3(3):1-13, 2007.</em></li>
<li>E. Spyromitros, G. Tsoumakas, and I. Vlahavas, <em>An Empirical Study of Lazy Multilabel Classification Algorithms</em>. Proc. 5th Hellenic Conference on Artificial Intelligence (SETN 2008), Springer, Syros, Greece, 2008.</li>
<li>M. Zhang and Z. Zhou. <em>ML-KNN: A lazy learning approach to multi-label learning</em>. Pattern Recognition, 40, 7 (Jul. 2007), 2038-2048.</li>
<li>S. Godbole and S. Sarawagi. <em>Discriminative Methods for Multi-labeled Classification</em>, Proceedings of the 8th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2004.</li>
<li>R. E. Schapire and Y. Singer. <em>Boostexter: a bossting-based system for text categorization</em>, Machine Learning, vol.39, no.2/3, 2000, pp:135-68.</li>
</ul></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"BIOLAB","date":"2011-09-02 05:47:00+00:00","draft":false,"title":"GSoC Review: Multi-label Classification Implementation","type":"blog","blog":["classification","gsoc","multilabel"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    strong: \"strong\",\n    em: \"em\",\n    a: \"a\",\n    h3: \"h3\",\n    h4: \"h4\",\n    ul: \"ul\",\n    li: \"li\",\n    pre: \"pre\",\n    code: \"code\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"Traditional single-label classification is concerned with learning from a set of examples that are associated with a single label \", _jsx(_components.strong, {\n        children: \"l\"\n      }), \" from a set of disjoint labels \", _jsx(_components.strong, {\n        children: \"L\"\n      }), \", \", _jsx(_components.strong, {\n        children: \"|L|\"\n      }), \" \u003e \", _jsx(_components.strong, {\n        children: \"1\"\n      }), \". If \", _jsx(_components.strong, {\n        children: \"|L|\"\n      }), \" = \", _jsx(_components.strong, {\n        children: \"2\"\n      }), \", then the learning problem is called a binary classification problem, while if \", _jsx(_components.strong, {\n        children: \"|L|\"\n      }), \" \u003e \", _jsx(_components.strong, {\n        children: \"2\"\n      }), \", then it is called a multi-class classification problem (Tsoumakas \u0026 Katakis, 2007).\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Multi-label classification methods are increasingly used by many applications, such as textual data classification, protein function classification, music categorization and semantic scene classification. However, currently, Orange can only handle single-label problems. As a result, the project \", _jsx(_components.em, {\n        children: \"Multi-label classification Implementation\"\n      }), \" has been proposed to extend Orange to support multi-label.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We can group the existing methods for multi-label classification into two main categories: a) problem transformation method, and b) algorithm adaptation methods. In the former one, multi-label problems are converted to single-label, and then the traditional binary classification can apply; in the latter case, methods directly classify the multi-label data, instead.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In this project, two transformation methods and two algorithm adaptation methods are implemented. Along with the methods, their widgets are also added. As the evaluation metrics for multi-label data are different from the single-label ones, new evaluation measures are supported. The code is available in \", _jsx(_components.a, {\n        href: \"http://orange.biolab.si/trac/intertrac/browser%3Abranches/multilabel\",\n        children: \"SVN branch\"\n      }), \".\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Fortunately, benefiting from the Tab file format, the \", _jsx(_components.strong, {\n        children: \"ExampleTable\"\n      }), \" can store multi-label data without any modification. Now, we can add a special value – \", _jsx(_components.strong, {\n        children: \"label\"\n      }), \" into the \", _jsx(_components.strong, {\n        children: \"attributes\"\n      }), \" dictionary of the domain with value 1. In this way, if the attribute description has the keyword \", _jsx(_components.strong, {\n        children: \"label\"\n      }), \", then it is a label; otherwise, it is a normal feature.\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"What have been done in this project\"\n    }), \"\\n\", _jsx(_components.h4, {\n      children: \"Transformation methods\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"br – Binary Relevance Learner (Tsoumakas \u0026 Katakis, 2007)\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"lp – Label Powerset Classification (Tsoumakas \u0026 Katakis, 2007)\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h4, {\n      children: \"Algorithm Adaptation methods\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"mlknn – Multi-kNN Classification (Zhang \u0026 Zhou, 2007)\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"brknn – BR-kNN Classification (Spyromitros et al. 2008)\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h4, {\n      children: \"Evaluation methods\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"mlc_hamming_loss – Example-based Hamming Loss (Schapire and Singer 2000)\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"mlc_accuracy, mlc_precision, mlc_recall – Example-based accuracy, precision, recall (Godbole \u0026 Sarawagi, 2004)\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h4, {\n      children: \"Widgets\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"OWBR – Widget for Binary Relevance Learner\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"OWLP – Widget for Label Powerset Classification\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"OWMLkNN – Widget for Multi-kNN Classification\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"OWBRkNN – Widget for BR-kNN Classification\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"OWTestLearner – Widget for Evaluation\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h4, {\n      children: \"File Format Extension\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"extend the loadARFF function to support sparse Weka format\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"new support \", _jsx(_components.a, {\n          href: \"http://mulan.sourceforge.net/format.html\",\n          children: \"mulan xml and arff format\"\n        })]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Plan for the future\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"add more classification methods for multi-label, such as PT1 to PT6\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"add feature extraction method\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"add ranking-based evaluation methods\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"How to use\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Basically, the way to use multi-label classification and evaluation is nearly the same as the single-label ones. The only difference between them is the different types of input data.\"\n    }), \"\\n\", _jsx(_components.h4, {\n      children: \"Example for Classification\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    import Orange\\n\\n    data = Orange.data.Table(\\\"emotions.tab\\\")\\n\\n    classifier = Orange.multilabel.BinaryRelevanceLearner(data)\\n\\n    for e in data:\\n        c,p = classifier(e,Orange.classification.Classifier.GetBoth)\\n        print c,p\\n\\n    powerset_cliassifer = Orange.multilabel.LabelPowersetLearner(data)\\n    for e in data:\\n        c,p = powerset_cliassifer(e,Orange.classification.Classifier.GetBoth)\\n        print c,p\\n\\n    mlknn_cliassifer = Orange.multilabel.MLkNNLearner(data,k=1)\\n    for e in data:\\n        c,p = mlknn_cliassifer(e,Orange.classification.Classifier.GetBoth)\\n        print c,p\\n       \\n    br_cliassifer = Orange.multilabel.BRkNNLearner(data,k=1)\\n    for e in data:\\n        c,p = br_cliassifer(e,Orange.classification.Classifier.GetBoth)\\n        print c,p\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h4, {\n      children: \"Example for Evaluation\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        children: \"    import Orange\\n\\n    learners = [\\n        Orange.multilabel.BinaryRelevanceLearner(name=\\\"br\\\"),\\n        Orange.multilabel.BinaryRelevanceLearner(name=\\\"br\\\", \\\\\\n            base_learner=Orange.classification.knn.kNNLearner),\\n        Orange.multilabel.LabelPowersetLearner(name=\\\"lp\\\"),\\n        Orange.multilabel.LabelPowersetLearner(name=\\\"lp\\\", \\\\\\n            base_learner=Orange.classification.knn.kNNLearner),\\n        Orange.multilabel.MLkNNLearner(name=\\\"mlknn\\\",k=5),\\n        Orange.multilabel.BRkNNLearner(name=\\\"brknn\\\",k=5),\\n    ]\\n\\n    data = Orange.data.Table(\\\"emotions.xml\\\")\\n\\n    res = Orange.evaluation.testing.cross_validation(learners, data,2)\\n    loss = Orange.evaluation.scoring.mlc_hamming_loss(res)\\n    accuracy = Orange.evaluation.scoring.mlc_accuracy(res)\\n    precision = Orange.evaluation.scoring.mlc_precision(res)\\n    recall = Orange.evaluation.scoring.mlc_recall(res)\\n    print 'loss=', loss\\n    print 'accuracy=', accuracy\\n    print 'precision=', precision\\n    print 'recall=', recall\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"References\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"G. Tsoumakas and I. Katakis. \", _jsx(_components.em, {\n          children: \"Multi-label classification: An overview\\\". International Journal of Data Warehousing and Mining, 3(3):1-13, 2007.\"\n        })]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"E. Spyromitros, G. Tsoumakas, and I. Vlahavas, \", _jsx(_components.em, {\n          children: \"An Empirical Study of Lazy Multilabel Classification Algorithms\"\n        }), \". Proc. 5th Hellenic Conference on Artificial Intelligence (SETN 2008), Springer, Syros, Greece, 2008.\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"M. Zhang and Z. Zhou. \", _jsx(_components.em, {\n          children: \"ML-KNN: A lazy learning approach to multi-label learning\"\n        }), \". Pattern Recognition, 40, 7 (Jul. 2007), 2038-2048.\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"S. Godbole and S. Sarawagi. \", _jsx(_components.em, {\n          children: \"Discriminative Methods for Multi-labeled Classification\"\n        }), \", Proceedings of the 8th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2004.\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"R. E. Schapire and Y. Singer. \", _jsx(_components.em, {\n          children: \"Boostexter: a bossting-based system for text categorization\"\n        }), \", Machine Learning, vol.39, no.2/3, 2000, pp:135-68.\"]\n      }), \"\\n\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"gsoc-review-multi-label-classification-implementation"},"buildId":"Pq4MTEXwxi3akD3CFvrRB","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>