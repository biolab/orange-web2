<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Orange Data Mining</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/media/0ac14a3c407fb3c4-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/fc6fba7ce0876fef-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/3cc61a2a1d48cb85-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/b49f75c2c957040b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b49f75c2c957040b.css" data-n-g=""/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-880e48e2fc817058.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-321f842b3cd96ae0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-585f99e2415388ec.js" defer=""></script><script src="/_next/static/chunks/815-30d73934dc079aab.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-7cdbfe4296bdad76.js" defer=""></script><script src="/_next/static/Wk04WPtqS8KBBylzHTa3K/_buildManifest.js" defer=""></script><script src="/_next/static/Wk04WPtqS8KBBylzHTa3K/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.cuimeM{position:relative;max-width:1296px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;box-sizing:content-box;}/*!sc*/
@media (max-width:1130px){.cuimeM{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.cuimeM{padding-left:15px;padding-right:15px;}}/*!sc*/
.fZOHgH{position:relative;max-width:1296px;margin-right:auto;margin-left:auto;padding-left:72px;padding-right:72px;height:100%;box-sizing:content-box;max-width:714px;}/*!sc*/
@media (max-width:1130px){.fZOHgH{padding-left:30px;padding-right:30px;}}/*!sc*/
@media (max-width:720px){.fZOHgH{padding-left:15px;padding-right:15px;}}/*!sc*/
data-styled.g1[id="sc-36970a51-0"]{content:"cuimeM,fZOHgH,"}/*!sc*/
.fYoBKL{position:relative;display:inline-block;max-width:100%;font-size:20px;line-height:1.25;font-weight:600;-webkit-text-decoration:none;text-decoration:none;color:#fff;padding:10px 15px;border-radius:5px;background-image:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);background-size:100%;cursor:pointer;z-index:2;}/*!sc*/
.fYoBKL:before{content:"";display:block;position:absolute;top:0;left:0;width:100%;height:100%;border-radius:inherit;background-image:linear-gradient(180deg,#ffbc44 100%,#FE7A00 100%);opacity:0;z-index:-100;-webkit-transition:opacity 0.45s;transition:opacity 0.45s;}/*!sc*/
.fYoBKL:hover{color:#fff;}/*!sc*/
.fYoBKL:hover:before{opacity:1;}/*!sc*/
data-styled.g2[id="sc-e429b959-0"]{content:"fYoBKL,"}/*!sc*/
.ikuqzB{background:#1F1F1F;padding:38px 0 25px;color:#fff;}/*!sc*/
data-styled.g3[id="sc-7afe78da-0"]{content:"ikuqzB,"}/*!sc*/
.hrSlzr{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-column-gap:80px;column-gap:80px;row-gap:40px;margin-bottom:40px;}/*!sc*/
.hrSlzr h3{font-size:16px;font-weight:600;margin-bottom:12px;}/*!sc*/
.hrSlzr li + li{margin-top:12px;}/*!sc*/
data-styled.g4[id="sc-7afe78da-1"]{content:"hrSlzr,"}/*!sc*/
.eWdALT{display:none;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:44px;height:34px;padding:6px;border-radius:5px;border:none;background:linear-gradient(180deg,#FE7A00 74.93%,#F65D18 100%);box-shadow:0px 10px 10px rgba(0,0,0,0.03);cursor:pointer;margin-left:auto;}/*!sc*/
@media (max-width:920px){.eWdALT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.eWdALT div{width:22px;height:2px;background:#fff;-webkit-transform-origin:1px;-ms-transform-origin:1px;transform-origin:1px;-webkit-transition:all 0.3s linear;transition:all 0.3s linear;}/*!sc*/
data-styled.g5[id="sc-46d6b9d9-0"]{content:"eWdALT,"}/*!sc*/
.jTcDmc{-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;overflow:hidden;position:absolute;white-space:nowrap;width:1px;}/*!sc*/
data-styled.g6[id="sc-cdea7863-0"]{content:"jTcDmc,"}/*!sc*/
.gPgccM{position:fixed;top:0;left:0;width:100%;height:80px;z-index:5;background:#fff;box-shadow:0px 4px 10px 4px rgba(0,0,0,0.04);}/*!sc*/
data-styled.g7[id="sc-6852f5f6-0"]{content:"gPgccM,"}/*!sc*/
.jrLPNu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;}/*!sc*/
.jrLPNu .img-logo{width:115px;}/*!sc*/
data-styled.g8[id="sc-6852f5f6-1"]{content:"jrLPNu,"}/*!sc*/
.hzGhxs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.hzGhxs{display:block;position:absolute;top:80px;left:0;width:100%;z-index:1;padding:0 30px 30px;background-color:#fff;opacity:0;z-index:-9999;pointer-events:none;-webkit-transition:opacity 0.3s ease;transition:opacity 0.3s ease;box-shadow:0 4px 10px -1px rgba(0,0,0,0.04);}}/*!sc*/
@media (max-width:720px){.hzGhxs{padding:0 15px 15px;}}/*!sc*/
data-styled.g9[id="sc-6852f5f6-2"]{content:"hzGhxs,"}/*!sc*/
.chSgxF{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.chSgxF{display:block;margin-bottom:15px;}}/*!sc*/
.chSgxF li + li{margin-left:26px;}/*!sc*/
@media (max-width:920px){.chSgxF li + li{margin-left:0;}}/*!sc*/
.chSgxF a{display:inline-block;font-size:1.25rem;line-height:1;color:#000000;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:color 0.3s;transition:color 0.3s;}/*!sc*/
.chSgxF a:hover{color:#FE7A00;}/*!sc*/
@media (max-width:920px){.chSgxF a{padding:8px 0;}}/*!sc*/
data-styled.g10[id="sc-6852f5f6-3"]{content:"chSgxF,"}/*!sc*/
.hTbjmy{position:relative;width:160px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;margin-left:26px;}/*!sc*/
@media (max-width:920px){.hTbjmy{width:auto;margin-left:0;}}/*!sc*/
data-styled.g11[id="sc-6852f5f6-4"]{content:"hTbjmy,"}/*!sc*/
.kzOElI{display:inline-block;position:absolute;top:0;right:42px;width:calc(100% - 42px);height:100%;font-size:16px;line-height:1.25;padding:10px 13px;background:#fff;border-radius:5px 0px 0px 5px;border:1px solid #D9D9D9;border-right:none;-webkit-transition:width 0.3s ease-in-out;transition:width 0.3s ease-in-out;}/*!sc*/
@media (max-width:920px){.kzOElI{display:none;}}/*!sc*/
.kzOElI::-webkit-input-placeholder{color:#D9D9D9;}/*!sc*/
.kzOElI::-moz-placeholder{color:#D9D9D9;}/*!sc*/
.kzOElI:-ms-input-placeholder{color:#D9D9D9;}/*!sc*/
.kzOElI::placeholder{color:#D9D9D9;}/*!sc*/
data-styled.g12[id="sc-6852f5f6-5"]{content:"kzOElI,"}/*!sc*/
.dSfmcG{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;color:#fff;margin-left:auto;-webkit-flex:0 0 42px;-ms-flex:0 0 42px;flex:0 0 42px;height:41px;border:1px solid #474747;border-radius:0px 5px 5px 0px;background-color:#474747;}/*!sc*/
@media (max-width:920px){.dSfmcG{margin-left:0;}}/*!sc*/
data-styled.g13[id="sc-6852f5f6-6"]{content:"dSfmcG,"}/*!sc*/
*,*:before,*:after{box-sizing:border-box;-webkit-font-smoothing:antialiased;}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
html{font-family:'Source Sans Pro',sans-serif;font-weight:400;color:#000000;}/*!sc*/
body{background:#fff;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
main{padding-top:80px;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
figure{margin:0;}/*!sc*/
img,video{display:block;max-width:100%;height:auto;}/*!sc*/
a{color:unset;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
a:hover{color:unset;}/*!sc*/
strong{font-weight:600;}/*!sc*/
pre{display:block;padding:10px 14px;margin:0 0 10px;font-size:18px;line-height:1.42857143;word-break:break-all;word-wrap:break-word;color:#000;background-color:#f5f5f5;border-radius:5px;overflow-x:auto;word-wrap:normal;}/*!sc*/
pre code{padding:0;font-size:inherit;color:inherit;white-space:pre-wrap;background-color:transparent;border-radius:0;}/*!sc*/
code{font-family:Menlo,Monaco,Consolas,"Courier New",monospace;padding:2px 4px;font-size:90%;color:#c7254e;background-color:#f9f2f4;white-space:nowrap;border-radius:4px;white-space:pre-wrap;}/*!sc*/
::selection{background-color:#FE7A00;color:#fff;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g18[id="sc-global-exMkeD1"]{content:"sc-global-exMkeD1,"}/*!sc*/
.cXdfZy{font-size:62px;line-height:1.04;font-weight:700;color:#fff;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.cXdfZy{font-size:50px;}}/*!sc*/
@media (max-width:720px){.cXdfZy{font-size:42px;}}/*!sc*/
data-styled.g19[id="sc-4d34df46-0"]{content:"cXdfZy,"}/*!sc*/
.htQmXI h1{font-size:44px;line-height:1.13;font-weight:700;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.htQmXI h1{font-size:38px;}}/*!sc*/
@media (max-width:720px){.htQmXI h1{font-size:32px;}}/*!sc*/
.htQmXI h2{font-size:33px;line-height:1.13;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.htQmXI h2{font-size:30px;}}/*!sc*/
@media (max-width:720px){.htQmXI h2{font-size:26px;}}/*!sc*/
.htQmXI h3{font-size:28px;line-height:1.18;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.htQmXI h3{font-size:26px;}}/*!sc*/
@media (max-width:720px){.htQmXI h3{font-size:24px;}}/*!sc*/
.htQmXI h4{font-size:22px;line-height:1.18;font-weight:600;color:#1F1F1F;}/*!sc*/
@media (max-width:720px){.htQmXI h4{font-size:20px;}}/*!sc*/
.htQmXI p{font-size:22px;line-height:1.36;color:#1F1F1F;}/*!sc*/
@media (max-width:1130px){.htQmXI p{font-size:20px;}}/*!sc*/
@media (max-width:920px){.htQmXI p{font-size:18px;}}/*!sc*/
.htQmXI ul,.htQmXI ol{padding-left:40px;}/*!sc*/
.htQmXI ul li,.htQmXI ol li{font-size:22px;line-height:1.36;color:#1F1F1F;}/*!sc*/
@media (max-width:1130px){.htQmXI ul li,.htQmXI ol li{font-size:20px;}}/*!sc*/
@media (max-width:920px){.htQmXI ul li,.htQmXI ol li{font-size:18px;}}/*!sc*/
.htQmXI ul li + li,.htQmXI ol li + li{margin-top:4px;}/*!sc*/
.htQmXI ul{list-style:disc;}/*!sc*/
.htQmXI ol{list-style:decimal;}/*!sc*/
.htQmXI p a,.htQmXI li a{color:#FE7A00;}/*!sc*/
.htQmXI p a:hover,.htQmXI li a:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.htQmXI * + *:not(li,a){margin-top:15px;}/*!sc*/
.htQmXI * + a[data-gallery],.htQmXI * + video{margin-top:40px;}/*!sc*/
.htQmXI a[data-gallery]{display:block;margin-bottom:40px;}/*!sc*/
.htQmXI iframe,.htQmXI video{margin-bottom:40px;}/*!sc*/
data-styled.g22[id="sc-b0f3732d-0"]{content:"htQmXI,"}/*!sc*/
.fdCCNC{display:block;margin-left:auto;margin-right:auto;}/*!sc*/
data-styled.g23[id="sc-b0f3732d-1"]{content:"fdCCNC,"}/*!sc*/
.fzPvDo{padding:80px 0;}/*!sc*/
@media (max-width:920px){.fzPvDo{padding:60px 0;}}/*!sc*/
@media (max-width:720px){.fzPvDo{padding:40px 0;}}/*!sc*/
data-styled.g25[id="sc-afd0c27d-0"]{content:"fzPvDo,"}/*!sc*/
.hALlh{margin-bottom:30px;}/*!sc*/
data-styled.g26[id="sc-afd0c27d-1"]{content:"hALlh,"}/*!sc*/
.bDRvVo{position:relative;}/*!sc*/
data-styled.g27[id="sc-afd0c27d-2"]{content:"bDRvVo,"}/*!sc*/
.hoiIWE{position:absolute;top:0;right:100%;width:200px;margin-right:50px;text-align:right;}/*!sc*/
@media (max-width:1130px){.hoiIWE{position:unset;width:auto;text-align:left;margin:0 0 30px 0;}}/*!sc*/
data-styled.g28[id="sc-afd0c27d-3"]{content:"hoiIWE,"}/*!sc*/
.kcehaN{font-size:20px;line-height:1.25;color:#1F1F1F;text-transform:capitalize;color:#837FEB;}/*!sc*/
@media (max-width:920px){.kcehaN{font-size:18px;}}/*!sc*/
.byQmFB{font-size:20px;line-height:1.25;color:#1F1F1F;}/*!sc*/
@media (max-width:920px){.byQmFB{font-size:18px;}}/*!sc*/
data-styled.g29[id="sc-afd0c27d-4"]{content:"kcehaN,byQmFB,"}/*!sc*/
</style></head><body><div id="__next"><div class="__className_ac89ad"><nav class="sc-6852f5f6-0 gPgccM"><div class="sc-36970a51-0 cuimeM"><div class="sc-6852f5f6-1 jrLPNu"><a href="/"><img alt="Orange Logo" loading="lazy" width="120" height="35" decoding="async" data-nimg="1" class="img-logo" style="color:transparent" src="/_next/static/media/logo-orange.faff1861.svg"/></a><div><button aria-label="Toggle navigation" class="sc-46d6b9d9-0 eWdALT"><div></div><div></div><div></div></button><div class="sc-6852f5f6-2 hzGhxs"><ul class="sc-6852f5f6-3 chSgxF"><li><a href="/examples">Examples</a></li><li><a href="/download">Download</a></li><li><a href="/blog">Blog</a></li><li><a href="/docs">Docs</a></li><li><a href="/workshops">Workshops</a></li></ul><form class="sc-6852f5f6-4 hTbjmy"><div class="sc-6852f5f6-5 kzOElI">Search</div><button class="sc-6852f5f6-6 dSfmcG"><img alt="Icon for search" loading="lazy" width="18" height="17" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/icon-search.459b2665.svg"/><span class="sc-cdea7863-0 jTcDmc">Search through page</span></button></form></div></div></div></div></nav><main><div class="sc-afd0c27d-0 fzPvDo"><div class="sc-36970a51-0 fZOHgH"><div class="sc-afd0c27d-1 hALlh"><p class="sc-afd0c27d-4 kcehaN"><strong>archaeology, workshop, image analytics, amphorae</strong></p><h1 class="sc-4d34df46-0 cXdfZy">Data Mining for Archaeologists, part I</h1></div><div class="sc-afd0c27d-2 bDRvVo"><div class="sc-afd0c27d-3 hoiIWE"><p class="sc-afd0c27d-4 byQmFB"><strong>Ajda Pretnar</strong></p><p class="sc-afd0c27d-4 byQmFB">Apr 23, 2021</p></div><div class="sc-b0f3732d-0 htQmXI"><div class="lg-react-element "><p>Recently, we held a workshop for a group of archaeologists. While archaeologists are quite well-versed in quantitative analysis, data science was still quite new for most of the participants. Our aim was to introduce basic data science concepts through archaeological use cases. One such case that came to our mind was predicting a type of the artefact from the image.</p>
<p>Related: <a href="blog/2018/11/06/data-mining-for-anthropologists/" target="_blank" rel="noreferrer">Data Mining for Anthropologists</a></p>
<p>We took three best-documented amphora types (types with the highest number of images) from the <a href="https://archaeologydataservice.ac.uk/archives/view/amphora_ahrb_2005/index.cfm">Archaeology Data Service portal</a>. We also added some metadata describing each amphora subtype.</p>
<p>This is how our data looks like.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-data-table.webp" data-gallery="true"><img alt="" loading="lazy" width="2652" height="968" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-data-table.webp"/></a>
<p>Each row represents one amphora, with type, image URL, subtype, and metadata included. Let us observe the data in an <strong>Image Viewer</strong> from the <strong>Image Analytics</strong> add-on.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-image-viewer.webp" data-gallery="true"><img alt="" loading="lazy" width="1754" height="1278" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-image-viewer.webp"/></a>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow1.webp" data-gallery="true"><img alt="" loading="lazy" width="454" height="360" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow1.webp"/></a>
<p>Images now have to be converted to numbers, so that predictive models will know how to infer patterns from them. The procedure of describing an image with a vector is called embedding and in Orange, it can be found in <strong>Image Embedding</strong> widget. We will use a simple, pre-trained Inception v3 model, but it is possible to train custom models specifically for archaeology.</p>
<p>The result of embedding is a long line of numbers.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-embedding.webp" data-gallery="true"><img alt="" loading="lazy" width="1654" height="736" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-embedding.webp"/></a>
<p>For the predictive model to consider only image vectors, we need to move metadata to ... well, meta attributes. We will do this with <strong>Select Columns</strong>.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-select-columns.webp" data-gallery="true"><img alt="" loading="lazy" width="1138" height="1154" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-select-columns.webp"/></a>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow2.webp" data-gallery="true"><img alt="" loading="lazy" width="736" height="422" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow2.webp"/></a>
<p>Now, we can build our prediction model. Or a couple of them. We will use <strong>Logistic Regression</strong>, <strong>kNN</strong>, and <strong>SVM</strong>, as these are quite successful for working with images. We connect the data and the learners to <strong>Test and Score</strong>. Seems like all of our models are quite accurate, with logistic regression having the highest AUC score.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-test-and-score.webp" data-gallery="true"><img alt="" loading="lazy" width="1554" height="920" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-test-and-score.webp"/></a>
<p>Looking at the <strong>Confusion Matrix</strong>, logistic regression also best distinguishes between Dressels and Gauloises. It makes 13 mistakes, fairly equally confusing Dressels with Gauloises and vice versa. The other two classifiers more frequently confuse Gauloises for Dressels, so they are slightly biased in this sense.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-confusion-matrix.webp" data-gallery="true"><img alt="" loading="lazy" width="1422" height="722" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-confusion-matrix.webp"/></a>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow3.webp" data-gallery="true"><img alt="" loading="lazy" width="1470" height="906" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow3.webp"/></a>
<p>It always makes sense to check the distribution of misclassifications to determine the quality of the model. If the model just predicts the most frequent class, it is useless. Having more data would surely make this model distinguish between amphora type better.</p>
<p>We can use the model for predicting the type of amphora for unlabelled images. Go to the internet and find some Dressels, Gauloises, and Keays. I have three images here. I put them in a single folder and I will load them with <strong>Import Images</strong> widget. We have to pass the data through another <strong>Image Embedding</strong> widget, because this data too needs numbers. Finally, we pass the data and one of the models (say, logistic regression) to <strong>Predictions</strong>. Don&#x27;t forget, logistic regression needs the data input to word with Predictions (you need to pass the model, not the learner).</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-predictions.webp" data-gallery="true"><img alt="" loading="lazy" width="1530" height="484" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-predictions.webp"/></a>
<p>Seems like Dressel and Gauloise were successfully predicted, while Keay was mislabelled as a Gauloise. Not what we would have expected. Could archaeologists among you figure out, why this Keay amphora was mislabelled?</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow-final.webp" data-gallery="true"><img alt="" loading="lazy" width="1768" height="1054" decoding="async" data-nimg="1" class="sc-b0f3732d-1 fdCCNC" style="color:transparent" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow-final.webp"/></a>
<p>In the second part of Data Mining for Archaeologists, we will have a look at geo-tagged data and how to plot them on a map.</p></div></div></div></div></div></main><footer class="sc-7afe78da-0 ikuqzB"><div class="sc-36970a51-0 cuimeM"><div class="sc-7afe78da-1 hrSlzr"><div><h3>Orange</h3><ul><li><a href="/faq">FAQ</a></li><li><a href="/license">License</a></li><li><a href="/privacy">Privacy</a></li><li><a href="/citation">Citation</a></li><li><a href="/contact">Contact</a></li></ul></div><div><h3>Download</h3><ul><li><a href="/download#win">Windows</a></li><li><a href="/download#mac">Mac OS</a></li></ul></div><div><h3>Community</h3><ul><li><a href="https://twitter.com/OrangeDataMiner">Twitter</a></li><li><a href="https://www.facebook.com/orangedatamining">Facebook</a></li><li><a href="https://datascience.stackexchange.com/questions/tagged/orange">Stack Exchange</a></li><li><a href="https://www.youtube.com/channel/UClKKWBe2SCAEyv7ZNGhIe4g">YouTube</a></li><li><a href="https://discord.com/invite/FWrfeXV">Discord</a></li></ul></div><div><h3>Documentation</h3><ul><li><a href="/getting-started">Get started</a></li><li><a href="/widget-catalogue">Widgets</a></li><li><a href="https://orange3.readthedocs.io/projects/orange-data-mining-library/en/latest/">Scripting</a></li></ul></div><div><h3>Developers</h3><ul><li><a href="https://github.com/biolab/orange3">GitHub</a></li><li><a href="http://docs.biolab.si/3/development/">Getting started</a></li></ul></div><div><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=A76TAX87ZVR3J" target="_blank" rel="noreferrer" class="sc-e429b959-0 fYoBKL">Donate to Orange</a></div></div><p>Copyright © University of Ljubljana</p></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"Ajda Pretnar","date":"2021-04-23","draft":false,"title":"Data Mining for Archaeologists, part I","type":"blog","thumbImage":"2021-04-23-archaeology-small.png","frontPageImage":"2021-04-23-archaeology-small.png","blog":["archaeology","workshop","image analytics","amphorae"],"shortExcerpt":"The many things archaeologists can do in Orange.","longExcerpt":"A workshop about different kinds of analyses archaeologists can do in Orange.","x2images":true},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    strong: \"strong\"\n  }, _provideComponents(), props.components), {LinkNew, WindowScreenshot, WorkflowScreenshot} = _components;\n  if (!LinkNew) _missingMdxReference(\"LinkNew\", true);\n  if (!WindowScreenshot) _missingMdxReference(\"WindowScreenshot\", true);\n  if (!WorkflowScreenshot) _missingMdxReference(\"WorkflowScreenshot\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Recently, we held a workshop for a group of archaeologists. While archaeologists are quite well-versed in quantitative analysis, data science was still quite new for most of the participants. Our aim was to introduce basic data science concepts through archaeological use cases. One such case that came to our mind was predicting a type of the artefact from the image.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Related: \", _jsx(LinkNew, {\n        url: \"blog/2018/11/06/data-mining-for-anthropologists/\",\n        name: \"Data Mining for Anthropologists\"\n      })]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We took three best-documented amphora types (types with the highest number of images) from the \", _jsx(_components.a, {\n        href: \"https://archaeologydataservice.ac.uk/archives/view/amphora_ahrb_2005/index.cfm\",\n        children: \"Archaeology Data Service portal\"\n      }), \". We also added some metadata describing each amphora subtype.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This is how our data looks like.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-data-table.png\",\n      width: \"2652\",\n      height: \"968\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-data-table.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Each row represents one amphora, with type, image URL, subtype, and metadata included. Let us observe the data in an \", _jsx(_components.strong, {\n        children: \"Image Viewer\"\n      }), \" from the \", _jsx(_components.strong, {\n        children: \"Image Analytics\"\n      }), \" add-on.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-image-viewer.png\",\n      width: \"1754\",\n      height: \"1278\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-image-viewer.webp\"\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-workflow1.png\",\n      width: \"454\",\n      height: \"360\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow1.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Images now have to be converted to numbers, so that predictive models will know how to infer patterns from them. The procedure of describing an image with a vector is called embedding and in Orange, it can be found in \", _jsx(_components.strong, {\n        children: \"Image Embedding\"\n      }), \" widget. We will use a simple, pre-trained Inception v3 model, but it is possible to train custom models specifically for archaeology.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The result of embedding is a long line of numbers.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-embedding.png\",\n      width: \"1654\",\n      height: \"736\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-embedding.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"For the predictive model to consider only image vectors, we need to move metadata to ... well, meta attributes. We will do this with \", _jsx(_components.strong, {\n        children: \"Select Columns\"\n      }), \".\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-select-columns.png\",\n      width: \"1138\",\n      height: \"1154\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-select-columns.webp\"\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-workflow2.png\",\n      width: \"736\",\n      height: \"422\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow2.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Now, we can build our prediction model. Or a couple of them. We will use \", _jsx(_components.strong, {\n        children: \"Logistic Regression\"\n      }), \", \", _jsx(_components.strong, {\n        children: \"kNN\"\n      }), \", and \", _jsx(_components.strong, {\n        children: \"SVM\"\n      }), \", as these are quite successful for working with images. We connect the data and the learners to \", _jsx(_components.strong, {\n        children: \"Test and Score\"\n      }), \". Seems like all of our models are quite accurate, with logistic regression having the highest AUC score.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-test-and-score.png\",\n      width: \"1554\",\n      height: \"920\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-test-and-score.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Looking at the \", _jsx(_components.strong, {\n        children: \"Confusion Matrix\"\n      }), \", logistic regression also best distinguishes between Dressels and Gauloises. It makes 13 mistakes, fairly equally confusing Dressels with Gauloises and vice versa. The other two classifiers more frequently confuse Gauloises for Dressels, so they are slightly biased in this sense.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-confusion-matrix.png\",\n      width: \"1422\",\n      height: \"722\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-confusion-matrix.webp\"\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-workflow3.png\",\n      width: \"1470\",\n      height: \"906\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow3.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"It always makes sense to check the distribution of misclassifications to determine the quality of the model. If the model just predicts the most frequent class, it is useless. Having more data would surely make this model distinguish between amphora type better.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We can use the model for predicting the type of amphora for unlabelled images. Go to the internet and find some Dressels, Gauloises, and Keays. I have three images here. I put them in a single folder and I will load them with \", _jsx(_components.strong, {\n        children: \"Import Images\"\n      }), \" widget. We have to pass the data through another \", _jsx(_components.strong, {\n        children: \"Image Embedding\"\n      }), \" widget, because this data too needs numbers. Finally, we pass the data and one of the models (say, logistic regression) to \", _jsx(_components.strong, {\n        children: \"Predictions\"\n      }), \". Don't forget, logistic regression needs the data input to word with Predictions (you need to pass the model, not the learner).\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-predictions.png\",\n      width: \"1530\",\n      height: \"484\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-predictions.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Seems like Dressel and Gauloise were successfully predicted, while Keay was mislabelled as a Gauloise. Not what we would have expected. Could archaeologists among you figure out, why this Keay amphora was mislabelled?\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-workflow-final.png\",\n      width: \"1768\",\n      height: \"1054\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow-final.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In the second part of Data Mining for Archaeologists, we will have a look at geo-tagged data and how to plot them on a map.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"data-mining-for-archaeologists-part-i"},"buildId":"Wk04WPtqS8KBBylzHTa3K","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>