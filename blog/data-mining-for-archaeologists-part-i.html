<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-efcb3c938269e030.js" defer=""></script><script src="/_next/static/chunks/pages/_app-db1a1ff3d39ec3be.js" defer=""></script><script src="/_next/static/chunks/675-c15136c5f78ee272.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-2c5e8dab0b72dcef.js" defer=""></script><script src="/_next/static/O3RXT8CjJZMlhqyniz60z/_buildManifest.js" defer=""></script><script src="/_next/static/O3RXT8CjJZMlhqyniz60z/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.jRlxkR{background:#FE7A00;height:60px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.jRlxkR ul{display:none;}}/*!sc*/
data-styled.g1[id="sc-db501655-0"]{content:"jRlxkR,"}/*!sc*/
.fzyFyI{display:none;font-size:22px;margin-left:auto;}/*!sc*/
@media (max-width:920px){.fzyFyI{display:block;}}/*!sc*/
data-styled.g2[id="sc-db501655-1"]{content:"fzyFyI,"}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
html{font-family:'Source Sans Pro',sans-serif;color:#000000;}/*!sc*/
body{background:#fff;}/*!sc*/
*,*:before,*:after{box-sizing:border-box;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
img,video{display:block;max-width:100%;height:auto;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g3[id="sc-global-fBblxv1"]{content:"sc-global-fBblxv1,"}/*!sc*/
.gyEUdO{display:block;margin-left:auto;margin-right:auto;}/*!sc*/
data-styled.g4[id="sc-ffd18126-0"]{content:"gyEUdO,"}/*!sc*/
.hToqnf{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g6[id="sc-233f3b9d-0"]{content:"hToqnf,"}/*!sc*/
</style><style data-href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@400;600;700&display=swap">@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3aPA.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rAkw.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vAkw.woff) format('woff')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNa7lujVj9_mf.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qPK7lujVj9_mf.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNK7lujVj9_mf.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qO67lujVj9_mf.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qN67lujVj9_mf.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNq7lujVj9_mf.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7lujVj9w.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmhdu3cOWxy40.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwkxdu3cOWxy40.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmxdu3cOWxy40.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmRdu3cOWxy40.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlxdu3cOWxw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmhdu3cOWxy40.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwkxdu3cOWxy40.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmxdu3cOWxy40.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmBdu3cOWxy40.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwmRdu3cOWxy40.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/sourcesanspro/v21/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlxdu3cOWxw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><nav class="sc-db501655-0 jRlxkR"><ul><li><a href="/blog">Blog</a></li><li><a href="/workflows">Workflows</a></li></ul><button class="sc-db501655-1 fzyFyI">X</button></nav><main><div class="sc-233f3b9d-0 hToqnf"><h1>Data Mining for Archaeologists, part I</h1><div class="lg-react-element "><p>Recently, we held a workshop for a group of archaeologists. While archaeologists are quite well-versed in quantitative analysis, data science was still quite new for most of the participants. Our aim was to introduce basic data science concepts through archaeological use cases. One such case that came to our mind was predicting a type of the artefact from the image.</p>
<p>Related: <a href="blog/2018/11/06/data-mining-for-anthropologists/" target="_blank">Data Mining for Anthropologists</a></p>
<p>We took three best-documented amphora types (types with the highest number of images) from the <a href="https://archaeologydataservice.ac.uk/archives/view/amphora_ahrb_2005/index.cfm">Archaeology Data Service portal</a>. We also added some metadata describing each amphora subtype.</p>
<p>This is how our data looks like.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-data-table.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-data-table.webp" width="2652" height="968" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<p>Each row represents one amphora, with type, image URL, subtype, and metadata included. Let us observe the data in an <strong>Image Viewer</strong> from the <strong>Image Analytics</strong> add-on.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-image-viewer.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-image-viewer.webp" width="1754" height="1278" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow1.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow1.webp" width="454" height="360" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<p>Images now have to be converted to numbers, so that predictive models will know how to infer patterns from them. The procedure of describing an image with a vector is called embedding and in Orange, it can be found in <strong>Image Embedding</strong> widget. We will use a simple, pre-trained Inception v3 model, but it is possible to train custom models specifically for archaeology.</p>
<p>The result of embedding is a long line of numbers.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-embedding.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-embedding.webp" width="1654" height="736" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<p>For the predictive model to consider only image vectors, we need to move metadata to ... well, meta attributes. We will do this with <strong>Select Columns</strong>.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-select-columns.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-select-columns.webp" width="1138" height="1154" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow2.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow2.webp" width="736" height="422" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<p>Now, we can build our prediction model. Or a couple of them. We will use <strong>Logistic Regression</strong>, <strong>kNN</strong>, and <strong>SVM</strong>, as these are quite successful for working with images. We connect the data and the learners to <strong>Test and Score</strong>. Seems like all of our models are quite accurate, with logistic regression having the highest AUC score.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-test-and-score.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-test-and-score.webp" width="1554" height="920" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<p>Looking at the <strong>Confusion Matrix</strong>, logistic regression also best distinguishes between Dressels and Gauloises. It makes 13 mistakes, fairly equally confusing Dressels with Gauloises and vice versa. The other two classifiers more frequently confuse Gauloises for Dressels, so they are slightly biased in this sense.</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-confusion-matrix.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-confusion-matrix.webp" width="1422" height="722" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow3.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow3.webp" width="1470" height="906" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<p>It always makes sense to check the distribution of misclassifications to determine the quality of the model. If the model just predicts the most frequent class, it is useless. Having more data would surely make this model distinguish between amphora type better.</p>
<p>We can use the model for predicting the type of amphora for unlabelled images. Go to the internet and find some Dressels, Gauloises, and Keays. I have three images here. I put them in a single folder and I will load them with <strong>Import Images</strong> widget. We have to pass the data through another <strong>Image Embedding</strong> widget, because this data too needs numbers. Finally, we pass the data and one of the models (say, logistic regression) to <strong>Predictions</strong>. Don&#x27;t forget, logistic regression needs the data input to word with Predictions (you need to pass the model, not the learner).</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-predictions.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-predictions.webp" width="1530" height="484" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<p>Seems like Dressel and Gauloise were successfully predicted, while Keay was mislabelled as a Gauloise. Not what we would have expected. Could archaeologists among you figure out, why this Keay amphora was mislabelled?</p>
<a href="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow-final.webp" data-gallery="true"><img alt="" src="/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow-final.webp" width="1768" height="1054" decoding="async" data-nimg="1" class="sc-ffd18126-0 gyEUdO" loading="lazy" style="color:transparent"/></a>
<p>In the second part of Data Mining for Archaeologists, we will have a look at geo-tagged data and how to plot them on a map.</p></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"Ajda Pretnar","date":"2021-04-23","draft":false,"title":"Data Mining for Archaeologists, part I","type":"blog","thumbImage":"2021-04-23-archaeology-small.png","frontPageImage":"2021-04-23-archaeology-small.png","blog":["archaeology","workshop","image analytics","amphorae"],"shortExcerpt":"The many things archaeologists can do in Orange.","longExcerpt":"A workshop about different kinds of analyses archaeologists can do in Orange.","x2images":true},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    strong: \"strong\"\n  }, _provideComponents(), props.components), {LinkNew, WindowScreenshot, WorkflowScreenshot} = _components;\n  if (!LinkNew) _missingMdxReference(\"LinkNew\", true);\n  if (!WindowScreenshot) _missingMdxReference(\"WindowScreenshot\", true);\n  if (!WorkflowScreenshot) _missingMdxReference(\"WorkflowScreenshot\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Recently, we held a workshop for a group of archaeologists. While archaeologists are quite well-versed in quantitative analysis, data science was still quite new for most of the participants. Our aim was to introduce basic data science concepts through archaeological use cases. One such case that came to our mind was predicting a type of the artefact from the image.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Related: \", _jsx(LinkNew, {\n        url: \"blog/2018/11/06/data-mining-for-anthropologists/\",\n        name: \"Data Mining for Anthropologists\"\n      })]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We took three best-documented amphora types (types with the highest number of images) from the \", _jsx(_components.a, {\n        href: \"https://archaeologydataservice.ac.uk/archives/view/amphora_ahrb_2005/index.cfm\",\n        children: \"Archaeology Data Service portal\"\n      }), \". We also added some metadata describing each amphora subtype.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This is how our data looks like.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-data-table.png\",\n      width: \"2652\",\n      height: \"968\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-data-table.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Each row represents one amphora, with type, image URL, subtype, and metadata included. Let us observe the data in an \", _jsx(_components.strong, {\n        children: \"Image Viewer\"\n      }), \" from the \", _jsx(_components.strong, {\n        children: \"Image Analytics\"\n      }), \" add-on.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-image-viewer.png\",\n      width: \"1754\",\n      height: \"1278\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-image-viewer.webp\"\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-workflow1.png\",\n      width: \"454\",\n      height: \"360\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow1.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Images now have to be converted to numbers, so that predictive models will know how to infer patterns from them. The procedure of describing an image with a vector is called embedding and in Orange, it can be found in \", _jsx(_components.strong, {\n        children: \"Image Embedding\"\n      }), \" widget. We will use a simple, pre-trained Inception v3 model, but it is possible to train custom models specifically for archaeology.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The result of embedding is a long line of numbers.\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-embedding.png\",\n      width: \"1654\",\n      height: \"736\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-embedding.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"For the predictive model to consider only image vectors, we need to move metadata to ... well, meta attributes. We will do this with \", _jsx(_components.strong, {\n        children: \"Select Columns\"\n      }), \".\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-select-columns.png\",\n      width: \"1138\",\n      height: \"1154\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-select-columns.webp\"\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-workflow2.png\",\n      width: \"736\",\n      height: \"422\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow2.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Now, we can build our prediction model. Or a couple of them. We will use \", _jsx(_components.strong, {\n        children: \"Logistic Regression\"\n      }), \", \", _jsx(_components.strong, {\n        children: \"kNN\"\n      }), \", and \", _jsx(_components.strong, {\n        children: \"SVM\"\n      }), \", as these are quite successful for working with images. We connect the data and the learners to \", _jsx(_components.strong, {\n        children: \"Test and Score\"\n      }), \". Seems like all of our models are quite accurate, with logistic regression having the highest AUC score.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-test-and-score.png\",\n      width: \"1554\",\n      height: \"920\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-test-and-score.webp\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Looking at the \", _jsx(_components.strong, {\n        children: \"Confusion Matrix\"\n      }), \", logistic regression also best distinguishes between Dressels and Gauloises. It makes 13 mistakes, fairly equally confusing Dressels with Gauloises and vice versa. The other two classifiers more frequently confuse Gauloises for Dressels, so they are slightly biased in this sense.\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-confusion-matrix.png\",\n      width: \"1422\",\n      height: \"722\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-confusion-matrix.webp\"\n    }), \"\\n\", _jsx(WorkflowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-workflow3.png\",\n      width: \"1470\",\n      height: \"906\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow3.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"It always makes sense to check the distribution of misclassifications to determine the quality of the model. If the model just predicts the most frequent class, it is useless. Having more data would surely make this model distinguish between amphora type better.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We can use the model for predicting the type of amphora for unlabelled images. Go to the internet and find some Dressels, Gauloises, and Keays. I have three images here. I put them in a single folder and I will load them with \", _jsx(_components.strong, {\n        children: \"Import Images\"\n      }), \" widget. We have to pass the data through another \", _jsx(_components.strong, {\n        children: \"Image Embedding\"\n      }), \" widget, because this data too needs numbers. Finally, we pass the data and one of the models (say, logistic regression) to \", _jsx(_components.strong, {\n        children: \"Predictions\"\n      }), \". Don't forget, logistic regression needs the data input to word with Predictions (you need to pass the model, not the learner).\"]\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-predictions.png\",\n      width: \"1530\",\n      height: \"484\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-predictions.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Seems like Dressel and Gauloise were successfully predicted, while Keay was mislabelled as a Gauloise. Not what we would have expected. Could archaeologists among you figure out, why this Keay amphora was mislabelled?\"\n    }), \"\\n\", _jsx(WindowScreenshot, {\n      src: \"/blog/2021-04-archaeology-workshop/2021-04-23-workflow-final.png\",\n      width: \"1768\",\n      height: \"1054\",\n      src: \"/blog/2021-04-archaeology-workshop/__webp-images__/2021-04-23-workflow-final.webp\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In the second part of Data Mining for Archaeologists, we will have a look at geo-tagged data and how to plot them on a map.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"data-mining-for-archaeologists-part-i"},"buildId":"O3RXT8CjJZMlhqyniz60z","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>