<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-9f90a364d66949ce.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8cfbd06f8ddd0b49.js" defer=""></script><script src="/_next/static/chunks/675-262430aa11afdf01.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-ba4a3f289f8ef3c5.js" defer=""></script><script src="/_next/static/GwUsIp3okGZ01glTrQqIW/_buildManifest.js" defer=""></script><script src="/_next/static/GwUsIp3okGZ01glTrQqIW/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.iBQlkL{background:coral;height:60px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.iBQlkL ul{display:none;}}/*!sc*/
data-styled.g1[id="sc-7295e4c-0"]{content:"iBQlkL,"}/*!sc*/
.bDMZDz{display:none;font-size:22px;margin-left:auto;}/*!sc*/
@media (max-width:920px){.bDMZDz{display:block;}}/*!sc*/
data-styled.g2[id="sc-7295e4c-1"]{content:"bDMZDz,"}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
body{background:#fff;}/*!sc*/
html{box-sizing:border-box;font-size:16px;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
img,video{max-width:100%;height:auto;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g3[id="sc-global-cqyaiF1"]{content:"sc-global-cqyaiF1,"}/*!sc*/
.cGDPDa{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g6[id="sc-f0e62130-0"]{content:"cGDPDa,"}/*!sc*/
</style></head><body><div id="__next"><nav class="sc-7295e4c-0 iBQlkL"><ul><a href="/blog">Blog</a></ul><button class="sc-7295e4c-1 bDMZDz">X</button></nav><main><div class="sc-f0e62130-0 cGDPDa"><h1>Stack Everything!</h1><div class="lg-react-element "><p>We all know that sometimes many is better than few. Therefore we are happy to introduce the Stack widget. It is available in <a href="https://github.com/biolab/orange3-prototypes">Prototypes add-on</a> for now.</p>
<p><a href="https://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html">Stacking</a> enables you to combine several trained models into one meta model and use it in Test&amp;Score just like any other model. This comes in handy with complex problems, where one classifier might fail, but many could come up with something that works. Let&#x27;s see an example.</p>
<p>We start with something as complex as this. We used Paint Data to create a complex data set, where classes somewhat overlap. This is naturally an artificial example, but you can try the same on your own, real life data.</p>
<a href="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.19.58.webp" data-gallery="true"><img alt="" srcSet="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.19.58.webp 1x, /blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.19.58.webp 2x" src="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.19.58.webp" width="1600" height="1271" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>We used 4 classes and painted a complex, 2-dimensional data set.</p>
<p>Then we add several kNN models with different parameters, say 5, 10 and 15 neighbors. We connect them to Test&amp;Score and use cross validation to evaluate their performance. Not bad, but can we do even better?</p>
<a href="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.23.08.webp" data-gallery="true"><img alt="" srcSet="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.23.08.webp 1x, /blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.23.08.webp 2x" src="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.23.08.webp" width="1314" height="870" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>Scores without staking, using only 3 different kNN classifiers.</p>
<p>Let us try stacking. We will connect all three classifiers to the Stacking widget and use Logistic Regression as an aggregate, a method that aggregates the three models into a single meta model. Then we connect connect the stacked model into Test&amp;Score and see whether our scores improved.</p>
<a href="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.29.03.webp" data-gallery="true"><img alt="" srcSet="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.29.03.webp 1x, /blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.29.03.webp 2x" src="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.29.03.webp" width="1314" height="870" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>Scores with stacking. Stack reports on improved performance.</p>
<p>And indeed they have. It might not be anything dramatic, but in real life, say medical context, even small improvements count. Now go and try the procedure on your own data. In Orange, this requires only a couple of minutes.</p>
<a href="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.31.01.webp" data-gallery="true"><img alt="" srcSet="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.31.01.webp 1x, /blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.31.01.webp 2x" src="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.31.01.webp" width="1074" height="994" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>Final workflow with channel names. Notice that Logistic Regression is used as Aggregate, not a Learner.</p></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"AJDA","date":"2018-01-05 15:37:34+00:00","draft":false,"title":"Stack Everything!","type":"blog","blog":["classification","examples","widget"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    img: \"img\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"We all know that sometimes many is better than few. Therefore we are happy to introduce the Stack widget. It is available in \", _jsx(_components.a, {\n        href: \"https://github.com/biolab/orange3-prototypes\",\n        children: \"Prototypes add-on\"\n      }), \" for now.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.a, {\n        href: \"https://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html\",\n        children: \"Stacking\"\n      }), \" enables you to combine several trained models into one meta model and use it in Test\u0026Score just like any other model. This comes in handy with complex problems, where one classifier might fail, but many could come up with something that works. Let's see an example.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We start with something as complex as this. We used Paint Data to create a complex data set, where classes somewhat overlap. This is naturally an artificial example, but you can try the same on your own, real life data.\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.19.58.webp\",\n      alt: \"\",\n      width: \"1600\",\n      height: \"1271\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We used 4 classes and painted a complex, 2-dimensional data set.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Then we add several kNN models with different parameters, say 5, 10 and 15 neighbors. We connect them to Test\u0026Score and use cross validation to evaluate their performance. Not bad, but can we do even better?\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.23.08.webp\",\n      alt: \"\",\n      width: \"1314\",\n      height: \"870\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Scores without staking, using only 3 different kNN classifiers.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let us try stacking. We will connect all three classifiers to the Stacking widget and use Logistic Regression as an aggregate, a method that aggregates the three models into a single meta model. Then we connect connect the stacked model into Test\u0026Score and see whether our scores improved.\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.29.03.webp\",\n      alt: \"\",\n      width: \"1314\",\n      height: \"870\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Scores with stacking. Stack reports on improved performance.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"And indeed they have. It might not be anything dramatic, but in real life, say medical context, even small improvements count. Now go and try the procedure on your own data. In Orange, this requires only a couple of minutes.\"\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.31.01.webp\",\n      alt: \"\",\n      width: \"1074\",\n      height: \"994\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Final workflow with channel names. Notice that Logistic Regression is used as Aggregate, not a Learner.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"stack-everything"},"buildId":"GwUsIp3okGZ01glTrQqIW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>