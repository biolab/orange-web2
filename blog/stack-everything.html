<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-45fae5f2ec2ec297.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-abafce5311b78c60.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c273b30b44d14e75.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-1f63d3b3c40f1c93.js" defer=""></script><script src="/_next/static/ltl2MNmHYj7YPBtRwizDd/_buildManifest.js" defer=""></script><script src="/_next/static/ltl2MNmHYj7YPBtRwizDd/_ssgManifest.js" defer=""></script></head><body><div id="__next"><nav class="navbar__Nav-eBQOKL ibrywS"><ul><a href="/blog">Blog</a></ul><button class="navbar__Burger-iSJTJn hhJHuh">X</button></nav><main><div class="slug__Wrapper-COBE fVNjNN"><h1>Stack Everything!</h1><p>We all know that sometimes many is better than few. Therefore we are happy to introduce the Stack widget. It is available in <a href="https://github.com/biolab/orange3-prototypes">Prototypes add-on</a> for now.</p>
<p><a href="https://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html">Stacking</a> enables you to combine several trained models into one meta model and use it in Test&amp;Score just like any other model. This comes in handy with complex problems, where one classifier might fail, but many could come up with something that works. Let&#x27;s see an example.</p>
<p>We start with something as complex as this. We used Paint Data to create a complex data set, where classes somewhat overlap. This is naturally an artificial example, but you can try the same on your own, real life data.</p>
<p><img src="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.19.58.png" alt=""/></p>
<p>We used 4 classes and painted a complex, 2-dimensional data set.</p>
<p>Then we add several kNN models with different parameters, say 5, 10 and 15 neighbors. We connect them to Test&amp;Score and use cross validation to evaluate their performance. Not bad, but can we do even better?</p>
<p><img src="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.23.08.png" alt=""/></p>
<p>Scores without staking, using only 3 different kNN classifiers.</p>
<p>Let us try stacking. We will connect all three classifiers to the Stacking widget and use Logistic Regression as an aggregate, a method that aggregates the three models into a single meta model. Then we connect connect the stacked model into Test&amp;Score and see whether our scores improved.</p>
<p><img src="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.29.03.png" alt=""/></p>
<p>Scores with stacking. Stack reports on improved performance.</p>
<p>And indeed they have. It might not be anything dramatic, but in real life, say medical context, even small improvements count. Now go and try the procedure on your own data. In Orange, this requires only a couple of minutes.</p>
<p><img src="/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.31.01.png" alt=""/></p>
<p>Final workflow with channel names. Notice that Logistic Regression is used as Aggregate, not a Learner.</p></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"AJDA","date":"2018-01-05 15:37:34+00:00","draft":false,"title":"Stack Everything!","type":"blog","blog":["classification","examples","widget"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    img: \"img\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"We all know that sometimes many is better than few. Therefore we are happy to introduce the Stack widget. It is available in \", _jsx(_components.a, {\n        href: \"https://github.com/biolab/orange3-prototypes\",\n        children: \"Prototypes add-on\"\n      }), \" for now.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.a, {\n        href: \"https://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html\",\n        children: \"Stacking\"\n      }), \" enables you to combine several trained models into one meta model and use it in Test\u0026Score just like any other model. This comes in handy with complex problems, where one classifier might fail, but many could come up with something that works. Let's see an example.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We start with something as complex as this. We used Paint Data to create a complex data set, where classes somewhat overlap. This is naturally an artificial example, but you can try the same on your own, real life data.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.19.58.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We used 4 classes and painted a complex, 2-dimensional data set.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Then we add several kNN models with different parameters, say 5, 10 and 15 neighbors. We connect them to Test\u0026Score and use cross validation to evaluate their performance. Not bad, but can we do even better?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.23.08.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Scores without staking, using only 3 different kNN classifiers.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let us try stacking. We will connect all three classifiers to the Stacking widget and use Logistic Regression as an aggregate, a method that aggregates the three models into a single meta model. Then we connect connect the stacked model into Test\u0026Score and see whether our scores improved.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.29.03.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Scores with stacking. Stack reports on improved performance.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"And indeed they have. It might not be anything dramatic, but in real life, say medical context, even small improvements count. Now go and try the procedure on your own data. In Orange, this requires only a couple of minutes.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/blog/2018-01-stack-everything/Screen-Shot-2018-01-05-at-16.31.01.png\",\n        alt: \"\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Final workflow with channel names. Notice that Logistic Regression is used as Aggregate, not a Learner.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"stack-everything"},"buildId":"ltl2MNmHYj7YPBtRwizDd","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>