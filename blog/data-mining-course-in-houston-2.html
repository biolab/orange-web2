<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>My new cool app</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/4ac7ed34d61ef456.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4ac7ed34d61ef456.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d38be8d96a62f950.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-9f90a364d66949ce.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8cfbd06f8ddd0b49.js" defer=""></script><script src="/_next/static/chunks/675-262430aa11afdf01.js" defer=""></script><script src="/_next/static/chunks/9-9d15d34c7affe00b.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-ba4a3f289f8ef3c5.js" defer=""></script><script src="/_next/static/GAVvi42gDEHMzYTCLyMnv/_buildManifest.js" defer=""></script><script src="/_next/static/GAVvi42gDEHMzYTCLyMnv/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.6">.iBQlkL{background:coral;height:60px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media (max-width:920px){.iBQlkL ul{display:none;}}/*!sc*/
data-styled.g1[id="sc-7295e4c-0"]{content:"iBQlkL,"}/*!sc*/
.bDMZDz{display:none;font-size:22px;margin-left:auto;}/*!sc*/
@media (max-width:920px){.bDMZDz{display:block;}}/*!sc*/
data-styled.g2[id="sc-7295e4c-1"]{content:"bDMZDz,"}/*!sc*/
html,body{height:100%;margin:0;}/*!sc*/
body{background:#fff;}/*!sc*/
html{box-sizing:border-box;font-size:16px;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;}/*!sc*/
body,h1,h2,h3,h4,h5,h6,p,ol,ul{margin:0;padding:0;font-weight:normal;}/*!sc*/
ol,ul{list-style:none;}/*!sc*/
img,video{max-width:100%;height:auto;}/*!sc*/
.lg-container .lg-backdrop.in{opacity:0.75;}/*!sc*/
.lg-container .lg-toolbar.lg-group,.lg-container .lg-outer .lg-thumb-outer{background:rgba(0,0,0,0.45);}/*!sc*/
data-styled.g3[id="sc-global-cqyaiF1"]{content:"sc-global-cqyaiF1,"}/*!sc*/
.cGDPDa{max-width:800px;margin:0 auto;}/*!sc*/
data-styled.g6[id="sc-f0e62130-0"]{content:"cGDPDa,"}/*!sc*/
</style></head><body><div id="__next"><nav class="sc-7295e4c-0 iBQlkL"><ul><a href="/blog">Blog</a></ul><button class="sc-7295e4c-1 bDMZDz">X</button></nav><main><div class="sc-f0e62130-0 cGDPDa"><h1>Data Mining Course in Houston #2</h1><div class="lg-react-element "><p>This was already the second installment of Introduction to Data Mining Course at <a href="https://www.bcm.edu">Baylor College of Medicine in Houston, Texas</a>. Just <a href="/blog/2015/10/09/data-mining-course-in-houston/">like the last year</a>, the course was packed. About 50 graduate students, post-docs and a few faculty attended, making the course one of the largest elective PhD courses from over a hundred offered at this prestigious medical school.</p>
<a href="/blog/2016-09-data-mining-in-houston-2/__webp-images__/houston-class-2016.webp" data-gallery="true"><img alt="" srcSet="/blog/2016-09-data-mining-in-houston-2/__webp-images__/houston-class-2016.webp 1x, /blog/2016-09-data-mining-in-houston-2/__webp-images__/houston-class-2016.webp 2x" src="/blog/2016-09-data-mining-in-houston-2/__webp-images__/houston-class-2016.webp" width="960" height="720" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a>
<p>The course was designed for students with little or no experience in data science. It consisted of seven two-hour lectures, each followed by a homework assignment. We (Blaz and Janez) lectured on data visualization, classification, regression, clustering, data projection and image analytics. We paid special attention to the problems of overfitting, use of regularization, and proper ways of testing and scoring of modeling methods.</p>
<p>The course was hands-on. The lectures were practical. They typically started with some data set and explained data mining techniques through designing data analysis workflows in Orange. Besides some standard machine learning and bioinformatics data sets, we have also <a href="/blog/2013/12/20/paint-your-data/">painted the data</a> to explore, say, the benefits of different classification techniques or design data sets where k-means clustering would fail.</p>
<p>This year, the course benefited from several new Orange widgets. The recently published <a href="/blog/2016/08/12/interactive-k-means/">interactive k-means</a> widget was used to explain the inner working of this clustering algorithm, and polynomial classification widget was helpful in discussion of <a href="/blog/2016/08/16/polynomial-classification/">decision boundaries of classification algorithms</a>. <a href="/blog/2016/03/23/all-i-see-is-silhouette/">Silhouette plot</a> was used to show how to evaluate and explore the results of clustering. And finally, we explained concepts from deep learning using image embedding to show how already trained networks can be used for clustering and classification of images.</p>
<a href="/blog/2016-09-data-mining-in-houston-2/__webp-images__/image-analytics-cows.webp" data-gallery="true"><img alt="" srcSet="/blog/2016-09-data-mining-in-houston-2/__webp-images__/image-analytics-cows.webp 1x, /blog/2016-09-data-mining-in-houston-2/__webp-images__/image-analytics-cows.webp 2x" src="/blog/2016-09-data-mining-in-houston-2/__webp-images__/image-analytics-cows.webp" width="1027" height="859" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"author":"BLAZ","date":"2016-09-15 13:38:30+00:00","draft":false,"title":"Data Mining Course in Houston #2","type":"blog","blog":["orange3","tutorial","workshop"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    img: \"img\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"This was already the second installment of Introduction to Data Mining Course at \", _jsx(_components.a, {\n        href: \"https://www.bcm.edu\",\n        children: \"Baylor College of Medicine in Houston, Texas\"\n      }), \". Just \", _jsx(_components.a, {\n        href: \"/blog/2015/10/09/data-mining-course-in-houston/\",\n        children: \"like the last year\"\n      }), \", the course was packed. About 50 graduate students, post-docs and a few faculty attended, making the course one of the largest elective PhD courses from over a hundred offered at this prestigious medical school.\"]\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2016-09-data-mining-in-houston-2/__webp-images__/houston-class-2016.webp\",\n      alt: \"\",\n      width: \"960\",\n      height: \"720\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The course was designed for students with little or no experience in data science. It consisted of seven two-hour lectures, each followed by a homework assignment. We (Blaz and Janez) lectured on data visualization, classification, regression, clustering, data projection and image analytics. We paid special attention to the problems of overfitting, use of regularization, and proper ways of testing and scoring of modeling methods.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The course was hands-on. The lectures were practical. They typically started with some data set and explained data mining techniques through designing data analysis workflows in Orange. Besides some standard machine learning and bioinformatics data sets, we have also \", _jsx(_components.a, {\n        href: \"/blog/2013/12/20/paint-your-data/\",\n        children: \"painted the data\"\n      }), \" to explore, say, the benefits of different classification techniques or design data sets where k-means clustering would fail.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This year, the course benefited from several new Orange widgets. The recently published \", _jsx(_components.a, {\n        href: \"/blog/2016/08/12/interactive-k-means/\",\n        children: \"interactive k-means\"\n      }), \" widget was used to explain the inner working of this clustering algorithm, and polynomial classification widget was helpful in discussion of \", _jsx(_components.a, {\n        href: \"/blog/2016/08/16/polynomial-classification/\",\n        children: \"decision boundaries of classification algorithms\"\n      }), \". \", _jsx(_components.a, {\n        href: \"/blog/2016/03/23/all-i-see-is-silhouette/\",\n        children: \"Silhouette plot\"\n      }), \" was used to show how to evaluate and explore the results of clustering. And finally, we explained concepts from deep learning using image embedding to show how already trained networks can be used for clustering and classification of images.\"]\n    }), \"\\n\", _jsx(_components.img, {\n      src: \"/blog/2016-09-data-mining-in-houston-2/__webp-images__/image-analytics-cows.webp\",\n      alt: \"\",\n      width: \"1027\",\n      height: \"859\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"data-mining-course-in-houston-2"},"buildId":"GAVvi42gDEHMzYTCLyMnv","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>